{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-31 12:04:46.306118: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-31 12:04:46.306169: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-31 12:04:46.307659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-31 12:04:47.017906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import evaluate\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass \n",
    "from time import perf_counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, disable_progress_bar\n",
    "from transformers import (AutoConfig,AutoTokenizer,AutoModelForSeq2SeqLM,DataCollatorForSeq2Seq,Seq2SeqTrainingArguments,Seq2SeqTrainer,EarlyStoppingCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    cache_dir: str = \"./2c\" \n",
    "    data_dir: str = os.path.join(cache_dir, \"wmt16\")\n",
    "    source_lang: str = \"de\"\n",
    "    target_lang: str = \"en\"    \n",
    "    \n",
    "    batch_size: int = 16\n",
    "    num_workers: int = 4\n",
    "    seed: int = 42\n",
    "    max_source_length: int = 128\n",
    "    max_target_length: int = 128\n",
    "\n",
    "    lr: float = 0.0005\n",
    "    weight_decay: float = 0.01\n",
    "    epochs: int = 3\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_checkpoint: str = \"google-t5/t5-small\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        torch.manual_seed(self.seed)\n",
    "        torch.cuda.manual_seed_all(self.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainl = []\n",
    "with open(\"train.de\",\"r\") as f:\n",
    "    with open(\"train.en\",\"r\") as g:\n",
    "        de = f.readlines()\n",
    "        en = g.readlines()\n",
    "        for i in range(len(de)):\n",
    "            d = {}\n",
    "            d[\"de\"] = de[i].strip()\n",
    "            d[\"en\"] = en[i].strip()\n",
    "            trainl.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vall = []\n",
    "with open(\"val.de\",\"r\") as f:\n",
    "    with open(\"val.en\",\"r\") as g:\n",
    "        de = f.readlines()\n",
    "        en = g.readlines()\n",
    "        for i in range(len(de)):\n",
    "            d = {}\n",
    "            d[\"de\"] = de[i].strip()\n",
    "            d[\"en\"] = en[i].strip()\n",
    "            vall.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testl = []\n",
    "with open(\"test.de\",\"r\") as f:\n",
    "    with open(\"test.en\",\"r\") as g:\n",
    "        de = f.readlines()\n",
    "        en = g.readlines()\n",
    "        for i in range(len(de)):\n",
    "            d = {}\n",
    "            d[\"de\"] = de[i].strip()\n",
    "            d[\"en\"] = en[i].strip()\n",
    "            testl.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset as DDDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainl = trainl[:1000]\n",
    "# testl = testl[:1000]\n",
    "# vall = vall[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = DDDD.from_list(trainl)\n",
    "testdataset = DDDD.from_list(testl)\n",
    "valdataset = DDDD.from_list(vall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    \"train\": traindataset,\n",
    "    \"val\": valdataset,\n",
    "    \"test\": testdataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['de', 'en'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['de', 'en'],\n",
      "        num_rows: 2169\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['de', 'en'],\n",
      "        num_rows: 2999\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score = evaluate.load(\"rouge\", cache_dir=config.cache_dir)\n",
    "bleu_score = evaluate.load(\"bleu\", cache_dir=config.cache_dir)\n",
    "sacrebleu_score = evaluate.load(\"sacrebleu\", cache_dir=config.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 2.32k/2.32k [00:00<00:00, 243kB/s]\n",
      "spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 939kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.39M/1.39M [00:01<00:00, 1.32MB/s]\n",
      "config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 161kB/s]\n",
      "model.safetensors: 100%|██████████| 242M/242M [00:02<00:00, 111MB/s]  \n",
      "generation_config.json: 100%|██████████| 147/147 [00:00<00:00, 19.3kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 60506624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model_checkpoint, cache_dir=config.cache_dir)\n",
    "\n",
    "model_name = config.model_checkpoint.split(\"/\")[-1]\n",
    "fine_tuned_model_checkpoint = os.path.join(\n",
    "    config.cache_dir,\n",
    "    f\"{model_name}_{config.source_lang}-{config.target_lang}\",\n",
    "    \"checkpoint-4500\"\n",
    ")\n",
    "if os.path.isdir(fine_tuned_model_checkpoint):\n",
    "    do_train = False\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(fine_tuned_model_checkpoint, cache_dir=config.cache_dir)\n",
    "else:\n",
    "    do_train = True\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(config.model_checkpoint, cache_dir=config.cache_dir)\n",
    "\n",
    "print(\"number of parameters:\", model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize_fn(examples):\n",
    "    \"\"\"\n",
    "    Generate the input_ids and labels field for huggingface dataset/dataset dict.\n",
    "\n",
    "    Truncation is enabled where we cap the sentence to the max length. Padding will be done later\n",
    "    in a data collator, so we pad examples to the longest length within a mini-batch and not\n",
    "    the whole dataset.\n",
    "    \"\"\"\n",
    "    sources = examples[config.source_lang]\n",
    "    targets = examples[config.target_lang]\n",
    "    model_inputs = tokenizer(sources, max_length=config.max_source_length, truncation=True)\n",
    "\n",
    "    # setup the tokenizer for targets,\n",
    "    # huggingface expects the target tokenized ids to be stored in the labels field\n",
    "    # note, newer version of tokenizer supports a text_target argument, where we can create\n",
    "    # source and target sentences in one go\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=config.max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3619: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "                                                                    \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2169\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict_tokenized = dataset_dict.map(\n",
    "    batch_tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=dataset_dict[\"train\"].column_names\n",
    ")\n",
    "dataset_dict_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15158, 24860,    74, 11216,   425,     7,  4267,    32,   221,     1,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [ 1674,     3,    49, 20635,    15,    67,   183, 17874,     6,   340,\n",
       "         11030, 17900,  1199,  5702,  1559,    15, 11216,   425,     7,  4267,\n",
       "            32,   221,    93,     3, 30604,    29, 13636,     7,   218,  1403,\n",
       "          3019,  7026,     6,     3, 25084,  2587, 18794,     7,  3532,  7756,\n",
       "            15,   674,  9242, 11621,    64,     3, 11950,    15,     6,     3,\n",
       "            26,  7118,   292, 11878, 16849,  8827,     5,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  419,  4078,   102,  1575,    13,     8,  2363,     1,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
       "        [   27, 15884,  4258,    26,     8,  2363,    13,     8,  1611, 12876,\n",
       "         19181,  1211,    29,    15,    26,    30,  1701,  1003,  1882,  5247,\n",
       "             6,    11,    27,   133,   114,   728,   541,    12,  1663,    25,\n",
       "             3,     9,  1095,   126,   215,    16,     8,   897,    24,    25,\n",
       "          2994,     3,     9,  8714, 15723,  1059,     5,     1]]), 'decoder_input_ids': tensor([[    0,   419,  4078,   102,  1575,    13,     8,  2363,     1,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,    27, 15884,  4258,    26,     8,  2363,    13,     8,  1611,\n",
       "         12876, 19181,  1211,    29,    15,    26,    30,  1701,  1003,  1882,\n",
       "          5247,     6,    11,    27,   133,   114,   728,   541,    12,  1663,\n",
       "            25,     3,     9,  1095,   126,   215,    16,     8,   897,    24,\n",
       "            25,  2994,     3,     9,  8714, 15723,  1059,     5]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "features = [dataset_dict_tokenized[\"train\"][i] for i in range(2)]\n",
    "output = data_collator(features)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "model_name = config.model_checkpoint.split(\"/\")[-1]\n",
    "output_dir = os.path.join(config.cache_dir, f\"{model_name}_{config.source_lang}-{config.target_lang}\")\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    #save_strategy=\"epoch\",\n",
    "    learning_rate=config.lr,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    weight_decay=config.weight_decay,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=config.epochs,\n",
    "    predict_with_generate=True,\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    gradient_accumulation_steps=8,\n",
    "    do_train=do_train,\n",
    "    report_to = \"none\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps = 1,\n",
    "    # careful when attempting to train t5 models on fp16 mixed precision,\n",
    "    # the model was trained on bfloat16 mixed precision, and mixing different mixed precision\n",
    "    # type might result in nan loss\n",
    "    # https://discuss.huggingface.co/t/mixed-precision-for-bfloat16-pretrained-models/5315\n",
    "    fp16=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute rouge and bleu metrics for seq2seq model generated prediction.\n",
    "    tip: we can run trainer.predict on our eval/test dataset to see what a sample\n",
    "    eval_pred object would look like when implementing custom compute metrics function\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries, which is in ids into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode labels, a.k.a. reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "    )\n",
    "    score = sacrebleu_score.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels\n",
    "    )\n",
    "    result[\"sacrebleu\"] = score[\"score\"]\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dataset_dict_tokenized[\"train\"],\n",
    "    eval_dataset=dataset_dict_tokenized[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/585 1:49:02 < 18:21, 0.08 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Sacrebleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.732400</td>\n",
       "      <td>2.732646</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>1.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.348000</td>\n",
       "      <td>2.597449</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>1.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.077100</td>\n",
       "      <td>2.513496</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>1.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.053700</td>\n",
       "      <td>2.442006</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>1.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.998600</td>\n",
       "      <td>2.401659</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>2.699400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.845200</td>\n",
       "      <td>2.371405</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>3.824400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.766900</td>\n",
       "      <td>2.348754</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>4.669700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.730200</td>\n",
       "      <td>2.332909</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>5.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.765600</td>\n",
       "      <td>2.321006</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>5.986400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.693800</td>\n",
       "      <td>2.309531</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>6.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.679700</td>\n",
       "      <td>2.297619</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.307900</td>\n",
       "      <td>6.560100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.689500</td>\n",
       "      <td>2.287619</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>6.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.639100</td>\n",
       "      <td>2.278974</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>6.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.577100</td>\n",
       "      <td>2.271112</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>7.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.589400</td>\n",
       "      <td>2.265275</td>\n",
       "      <td>0.359200</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>7.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.647400</td>\n",
       "      <td>2.259181</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>7.146100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.595400</td>\n",
       "      <td>2.253570</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>7.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.585800</td>\n",
       "      <td>2.247728</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>0.143400</td>\n",
       "      <td>0.323100</td>\n",
       "      <td>7.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.434100</td>\n",
       "      <td>2.242384</td>\n",
       "      <td>0.364400</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>7.323600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.564900</td>\n",
       "      <td>2.237035</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>7.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.582800</td>\n",
       "      <td>2.232073</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>7.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.556100</td>\n",
       "      <td>2.227712</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>7.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.497100</td>\n",
       "      <td>2.223183</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>7.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.579600</td>\n",
       "      <td>2.217998</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.331300</td>\n",
       "      <td>7.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.417800</td>\n",
       "      <td>2.212477</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>7.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.481600</td>\n",
       "      <td>2.206444</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>7.409300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.506300</td>\n",
       "      <td>2.200920</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>7.465900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.483300</td>\n",
       "      <td>2.195153</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>7.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.509500</td>\n",
       "      <td>2.190290</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>7.639600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.538300</td>\n",
       "      <td>2.185700</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.151300</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>7.634500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.426800</td>\n",
       "      <td>2.181635</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>7.678900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.417800</td>\n",
       "      <td>2.178682</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.335200</td>\n",
       "      <td>7.722600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.482200</td>\n",
       "      <td>2.175584</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.153600</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>7.760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.448400</td>\n",
       "      <td>2.173252</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.336600</td>\n",
       "      <td>7.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.514200</td>\n",
       "      <td>2.171035</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>7.898500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.417100</td>\n",
       "      <td>2.170021</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>7.901200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.386000</td>\n",
       "      <td>2.169815</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.156700</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>7.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.402500</td>\n",
       "      <td>2.170051</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>7.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.406800</td>\n",
       "      <td>2.170798</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>7.913800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.443500</td>\n",
       "      <td>2.171293</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>0.157300</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>7.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.371000</td>\n",
       "      <td>2.171319</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.341400</td>\n",
       "      <td>7.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>2.170740</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>7.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.170011</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>7.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.393100</td>\n",
       "      <td>2.168702</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>8.076800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.425200</td>\n",
       "      <td>2.166770</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>8.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.441600</td>\n",
       "      <td>2.164281</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>8.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.426200</td>\n",
       "      <td>2.161580</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.342300</td>\n",
       "      <td>8.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.337700</td>\n",
       "      <td>2.158001</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>8.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>2.154743</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.343800</td>\n",
       "      <td>8.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.151438</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>8.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.336300</td>\n",
       "      <td>2.148636</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>8.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.430500</td>\n",
       "      <td>2.145594</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.345700</td>\n",
       "      <td>8.296800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.338100</td>\n",
       "      <td>2.142708</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>8.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.375300</td>\n",
       "      <td>2.140141</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>8.313800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.362900</td>\n",
       "      <td>2.138032</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.346300</td>\n",
       "      <td>8.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.337300</td>\n",
       "      <td>2.136167</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.163900</td>\n",
       "      <td>0.347500</td>\n",
       "      <td>8.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.407800</td>\n",
       "      <td>2.134328</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.348600</td>\n",
       "      <td>8.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.373000</td>\n",
       "      <td>2.132980</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.348400</td>\n",
       "      <td>8.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.240700</td>\n",
       "      <td>2.132283</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.348600</td>\n",
       "      <td>8.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.329000</td>\n",
       "      <td>2.131504</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>8.390800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>2.378000</td>\n",
       "      <td>2.131299</td>\n",
       "      <td>0.387400</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.348500</td>\n",
       "      <td>8.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.386400</td>\n",
       "      <td>2.130805</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>8.466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>2.272100</td>\n",
       "      <td>2.130313</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.348800</td>\n",
       "      <td>8.473700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2.316200</td>\n",
       "      <td>2.129561</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.165300</td>\n",
       "      <td>0.349100</td>\n",
       "      <td>8.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.389400</td>\n",
       "      <td>2.128460</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>8.582700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2.283100</td>\n",
       "      <td>2.126869</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>8.597100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>2.250100</td>\n",
       "      <td>2.125271</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>8.601900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>2.303800</td>\n",
       "      <td>2.124218</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>8.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>2.380900</td>\n",
       "      <td>2.123069</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>8.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.311400</td>\n",
       "      <td>2.122156</td>\n",
       "      <td>0.390500</td>\n",
       "      <td>0.166900</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>8.524800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>2.257700</td>\n",
       "      <td>2.121633</td>\n",
       "      <td>0.391900</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>8.595900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>2.373800</td>\n",
       "      <td>2.120861</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>8.508600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>2.357700</td>\n",
       "      <td>2.120603</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>8.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>2.379900</td>\n",
       "      <td>2.120598</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>8.440500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.266700</td>\n",
       "      <td>2.120230</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>8.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>2.311400</td>\n",
       "      <td>2.118943</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>8.431200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>2.116982</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>8.465700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>2.316400</td>\n",
       "      <td>2.114281</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>8.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>2.271300</td>\n",
       "      <td>2.111852</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>8.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.273900</td>\n",
       "      <td>2.110401</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>8.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>2.303500</td>\n",
       "      <td>2.109279</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.350200</td>\n",
       "      <td>8.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>2.316500</td>\n",
       "      <td>2.108433</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>8.570700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>2.332100</td>\n",
       "      <td>2.107379</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>8.619300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>2.271200</td>\n",
       "      <td>2.105947</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>8.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.243500</td>\n",
       "      <td>2.105434</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>8.701400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>2.289000</td>\n",
       "      <td>2.105162</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>8.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>2.189100</td>\n",
       "      <td>2.105150</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>8.651400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>2.300400</td>\n",
       "      <td>2.104482</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>8.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>2.249800</td>\n",
       "      <td>2.103328</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>8.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.277500</td>\n",
       "      <td>2.101754</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>8.752400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>2.174400</td>\n",
       "      <td>2.100167</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>8.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>2.306100</td>\n",
       "      <td>2.099098</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.353900</td>\n",
       "      <td>8.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>2.306800</td>\n",
       "      <td>2.097612</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>8.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>2.228300</td>\n",
       "      <td>2.095959</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>8.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.302000</td>\n",
       "      <td>2.093988</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>8.813000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>2.310200</td>\n",
       "      <td>2.092303</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.352800</td>\n",
       "      <td>8.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>2.291200</td>\n",
       "      <td>2.091160</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>8.765700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>2.425600</td>\n",
       "      <td>2.089736</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>8.735900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>2.285300</td>\n",
       "      <td>2.088540</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.352200</td>\n",
       "      <td>8.681400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.155700</td>\n",
       "      <td>2.087286</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>8.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>2.208600</td>\n",
       "      <td>2.085841</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>8.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>2.304200</td>\n",
       "      <td>2.084795</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>8.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>2.188700</td>\n",
       "      <td>2.084100</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>8.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.297900</td>\n",
       "      <td>2.083903</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>8.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.291300</td>\n",
       "      <td>2.083573</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>8.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2.291500</td>\n",
       "      <td>2.083379</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>8.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>2.243600</td>\n",
       "      <td>2.083474</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.170900</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>8.746700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.229100</td>\n",
       "      <td>2.083780</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>8.761700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2.230100</td>\n",
       "      <td>2.083658</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>8.741300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.197900</td>\n",
       "      <td>2.084105</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>8.748300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>2.152200</td>\n",
       "      <td>2.084482</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>8.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.248600</td>\n",
       "      <td>2.084478</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>8.752800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>2.336100</td>\n",
       "      <td>2.083683</td>\n",
       "      <td>0.392100</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>8.763900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>2.212700</td>\n",
       "      <td>2.082097</td>\n",
       "      <td>0.392600</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.353700</td>\n",
       "      <td>8.779400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.223200</td>\n",
       "      <td>2.080203</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>8.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.173700</td>\n",
       "      <td>2.078720</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>8.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>2.283300</td>\n",
       "      <td>2.077621</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>8.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>2.285600</td>\n",
       "      <td>2.076449</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>8.855700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>2.228000</td>\n",
       "      <td>2.075586</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>8.822300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.191700</td>\n",
       "      <td>2.074656</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.358400</td>\n",
       "      <td>8.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>2.289300</td>\n",
       "      <td>2.073617</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>0.359300</td>\n",
       "      <td>8.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>2.304100</td>\n",
       "      <td>2.072678</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.359200</td>\n",
       "      <td>8.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>2.235600</td>\n",
       "      <td>2.071470</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.359100</td>\n",
       "      <td>8.766600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>2.240400</td>\n",
       "      <td>2.070098</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>8.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.161400</td>\n",
       "      <td>2.069071</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.359900</td>\n",
       "      <td>8.811000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>2.244600</td>\n",
       "      <td>2.068727</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>8.869300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>2.279800</td>\n",
       "      <td>2.069191</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.359900</td>\n",
       "      <td>8.860300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.149700</td>\n",
       "      <td>2.069586</td>\n",
       "      <td>0.398100</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.360300</td>\n",
       "      <td>8.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>2.236500</td>\n",
       "      <td>2.070507</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>8.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.174200</td>\n",
       "      <td>2.071398</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>8.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>2.275800</td>\n",
       "      <td>2.072356</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>8.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>2.150600</td>\n",
       "      <td>2.073158</td>\n",
       "      <td>0.397500</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>8.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>2.169300</td>\n",
       "      <td>2.073934</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.358400</td>\n",
       "      <td>8.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>2.184700</td>\n",
       "      <td>2.074390</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>8.882300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.240700</td>\n",
       "      <td>2.074832</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>8.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>2.217800</td>\n",
       "      <td>2.074592</td>\n",
       "      <td>0.397600</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.358500</td>\n",
       "      <td>8.881100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>2.205200</td>\n",
       "      <td>2.073959</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>8.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.246100</td>\n",
       "      <td>2.073140</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.358500</td>\n",
       "      <td>8.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>2.124900</td>\n",
       "      <td>2.071717</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>8.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.158400</td>\n",
       "      <td>2.069640</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.174100</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>8.985700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2.210400</td>\n",
       "      <td>2.066922</td>\n",
       "      <td>0.398500</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>8.899600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.197300</td>\n",
       "      <td>2.064926</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>8.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>2.188500</td>\n",
       "      <td>2.063452</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>8.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>2.328900</td>\n",
       "      <td>2.061694</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>8.961400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.170400</td>\n",
       "      <td>2.060084</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>8.997800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2.234200</td>\n",
       "      <td>2.059126</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>9.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>2.232400</td>\n",
       "      <td>2.058688</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.363100</td>\n",
       "      <td>9.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2.134300</td>\n",
       "      <td>2.058739</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>9.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2.142800</td>\n",
       "      <td>2.058228</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>9.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.228600</td>\n",
       "      <td>2.057246</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>9.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>2.232600</td>\n",
       "      <td>2.055998</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>9.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>2.149900</td>\n",
       "      <td>2.054871</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.363100</td>\n",
       "      <td>9.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>2.154600</td>\n",
       "      <td>2.054380</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>9.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>2.253300</td>\n",
       "      <td>2.054189</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>9.151700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>2.186100</td>\n",
       "      <td>2.053808</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>9.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>2.144600</td>\n",
       "      <td>2.053479</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.362400</td>\n",
       "      <td>9.168900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>2.188500</td>\n",
       "      <td>2.052896</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.362700</td>\n",
       "      <td>9.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>2.247100</td>\n",
       "      <td>2.052012</td>\n",
       "      <td>0.400800</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>9.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>2.074600</td>\n",
       "      <td>2.050998</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>9.205700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.196700</td>\n",
       "      <td>2.049679</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>9.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>2.178200</td>\n",
       "      <td>2.048605</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>9.219100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>2.120200</td>\n",
       "      <td>2.047656</td>\n",
       "      <td>0.401100</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>9.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>2.170800</td>\n",
       "      <td>2.046917</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>9.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>2.188500</td>\n",
       "      <td>2.046449</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>9.198600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>2.130900</td>\n",
       "      <td>2.046390</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>9.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>2.077200</td>\n",
       "      <td>2.046434</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>9.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>2.123200</td>\n",
       "      <td>2.047128</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>9.210600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>2.114100</td>\n",
       "      <td>2.048282</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>9.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>2.206800</td>\n",
       "      <td>2.049317</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>9.218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.155600</td>\n",
       "      <td>2.050004</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>9.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>2.209200</td>\n",
       "      <td>2.050594</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>9.167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>2.160500</td>\n",
       "      <td>2.050748</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>9.120300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>2.085300</td>\n",
       "      <td>2.050647</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>9.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>2.175600</td>\n",
       "      <td>2.050156</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>9.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.206000</td>\n",
       "      <td>2.049135</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.363300</td>\n",
       "      <td>9.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>2.212800</td>\n",
       "      <td>2.047877</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>9.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>2.093900</td>\n",
       "      <td>2.046726</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>9.147000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>2.150600</td>\n",
       "      <td>2.045494</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>9.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>2.193300</td>\n",
       "      <td>2.044316</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>9.182200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.186400</td>\n",
       "      <td>2.043663</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>9.182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>2.264900</td>\n",
       "      <td>2.043035</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>9.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>2.160700</td>\n",
       "      <td>2.042116</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>9.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>2.041490</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>9.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>2.129500</td>\n",
       "      <td>2.040740</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>9.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>2.180200</td>\n",
       "      <td>2.040106</td>\n",
       "      <td>0.401700</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>9.212800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>2.126200</td>\n",
       "      <td>2.039727</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.178200</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>9.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>2.136700</td>\n",
       "      <td>2.039219</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>9.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>2.126600</td>\n",
       "      <td>2.038724</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.364700</td>\n",
       "      <td>9.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>2.186000</td>\n",
       "      <td>2.038075</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>9.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.128600</td>\n",
       "      <td>2.037460</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.178700</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>9.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>2.166500</td>\n",
       "      <td>2.036847</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>9.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>2.212600</td>\n",
       "      <td>2.036389</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.364300</td>\n",
       "      <td>9.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>2.181100</td>\n",
       "      <td>2.035916</td>\n",
       "      <td>0.403700</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.365700</td>\n",
       "      <td>9.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>2.138800</td>\n",
       "      <td>2.035717</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>9.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>2.097900</td>\n",
       "      <td>2.035960</td>\n",
       "      <td>0.405300</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>9.435300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>2.114900</td>\n",
       "      <td>2.036464</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.368700</td>\n",
       "      <td>9.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>2.110900</td>\n",
       "      <td>2.036883</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>9.513100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>2.095000</td>\n",
       "      <td>2.036891</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>9.499700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>2.077800</td>\n",
       "      <td>2.036708</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>9.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.018200</td>\n",
       "      <td>2.036700</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>9.513900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>2.126100</td>\n",
       "      <td>2.036936</td>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>9.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>2.187000</td>\n",
       "      <td>2.037023</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>9.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>2.142400</td>\n",
       "      <td>2.037189</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>9.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>2.089100</td>\n",
       "      <td>2.037008</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>9.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>2.160300</td>\n",
       "      <td>2.037258</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>9.450700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>2.025200</td>\n",
       "      <td>2.037357</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.367500</td>\n",
       "      <td>9.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>2.114700</td>\n",
       "      <td>2.037403</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>9.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>2.057900</td>\n",
       "      <td>2.037224</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>9.474900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>2.145600</td>\n",
       "      <td>2.036934</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>9.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.098500</td>\n",
       "      <td>2.036131</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.368300</td>\n",
       "      <td>9.505600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>2.205800</td>\n",
       "      <td>2.035009</td>\n",
       "      <td>0.406800</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>9.503500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>2.112600</td>\n",
       "      <td>2.033856</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>2.030400</td>\n",
       "      <td>2.032890</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>9.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>2.031898</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>9.521100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.995200</td>\n",
       "      <td>2.031150</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>9.516300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>2.074500</td>\n",
       "      <td>2.030401</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.553300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>2.072300</td>\n",
       "      <td>2.030086</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.181800</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>2.126700</td>\n",
       "      <td>2.029772</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.566500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>2.021000</td>\n",
       "      <td>2.029775</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.572500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.105900</td>\n",
       "      <td>2.029478</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>9.585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>2.077100</td>\n",
       "      <td>2.029164</td>\n",
       "      <td>0.406900</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>9.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>2.080500</td>\n",
       "      <td>2.029109</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>9.536800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>2.079000</td>\n",
       "      <td>2.028862</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>9.537100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>2.099800</td>\n",
       "      <td>2.028687</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>9.552700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.094100</td>\n",
       "      <td>2.028394</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>9.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>2.043300</td>\n",
       "      <td>2.028141</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>9.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>2.117000</td>\n",
       "      <td>2.027913</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.570200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>2.041700</td>\n",
       "      <td>2.027880</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>9.525100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>2.075500</td>\n",
       "      <td>2.028309</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>9.530100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.144100</td>\n",
       "      <td>2.028682</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>9.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>2.115600</td>\n",
       "      <td>2.029101</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>9.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>2.087200</td>\n",
       "      <td>2.029468</td>\n",
       "      <td>0.406200</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>9.481800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>2.118100</td>\n",
       "      <td>2.029318</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>9.463600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>2.053300</td>\n",
       "      <td>2.029427</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.366900</td>\n",
       "      <td>9.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>2.076300</td>\n",
       "      <td>2.029639</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.181100</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>9.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>2.129700</td>\n",
       "      <td>2.029762</td>\n",
       "      <td>0.406400</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>9.475600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>2.020100</td>\n",
       "      <td>2.028923</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>9.518100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>2.078300</td>\n",
       "      <td>2.027999</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>9.507800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>1.995800</td>\n",
       "      <td>2.027332</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>9.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.076900</td>\n",
       "      <td>2.026770</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>9.418900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>2.072700</td>\n",
       "      <td>2.026446</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>9.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>2.042200</td>\n",
       "      <td>2.026394</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.181900</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.421800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>2.131400</td>\n",
       "      <td>2.026326</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>2.097400</td>\n",
       "      <td>2.025863</td>\n",
       "      <td>0.408200</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>9.429400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>2.066500</td>\n",
       "      <td>2.025599</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>2.012800</td>\n",
       "      <td>2.025320</td>\n",
       "      <td>0.408200</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>2.139000</td>\n",
       "      <td>2.024745</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>9.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>2.111700</td>\n",
       "      <td>2.024467</td>\n",
       "      <td>0.408300</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>9.516300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>2.118900</td>\n",
       "      <td>2.024348</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.534800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.071900</td>\n",
       "      <td>2.023933</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.537800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>2.029600</td>\n",
       "      <td>2.023708</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.494200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>2.062800</td>\n",
       "      <td>2.024016</td>\n",
       "      <td>0.408100</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>9.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>1.979200</td>\n",
       "      <td>2.023857</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>9.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>2.043600</td>\n",
       "      <td>2.023696</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>9.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>2.096600</td>\n",
       "      <td>2.023650</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>9.525500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>2.070200</td>\n",
       "      <td>2.023255</td>\n",
       "      <td>0.408200</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>9.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>2.124700</td>\n",
       "      <td>2.022792</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>9.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>2.081200</td>\n",
       "      <td>2.022233</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>9.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>2.053500</td>\n",
       "      <td>2.021427</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>9.502700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.070300</td>\n",
       "      <td>2.020680</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>9.531700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>2.127700</td>\n",
       "      <td>2.020221</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>9.537400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>2.080900</td>\n",
       "      <td>2.019981</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>9.560300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>2.090800</td>\n",
       "      <td>2.019811</td>\n",
       "      <td>0.408300</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>9.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>2.043400</td>\n",
       "      <td>2.019777</td>\n",
       "      <td>0.408300</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>9.577800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>2.059600</td>\n",
       "      <td>2.020262</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>9.566300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>2.009600</td>\n",
       "      <td>2.020848</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>9.547200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>2.027900</td>\n",
       "      <td>2.021410</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.542200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>2.116000</td>\n",
       "      <td>2.021606</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>9.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>2.099100</td>\n",
       "      <td>2.021893</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>9.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.082600</td>\n",
       "      <td>2.021955</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.502200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>2.064500</td>\n",
       "      <td>2.022108</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>9.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>2.129300</td>\n",
       "      <td>2.021877</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>9.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>2.090700</td>\n",
       "      <td>2.021602</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.369600</td>\n",
       "      <td>9.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>2.088300</td>\n",
       "      <td>2.021152</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>9.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.121800</td>\n",
       "      <td>2.020311</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.369800</td>\n",
       "      <td>9.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>2.090300</td>\n",
       "      <td>2.019711</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>9.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>2.093300</td>\n",
       "      <td>2.018984</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>9.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>2.037100</td>\n",
       "      <td>2.018450</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>9.532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>2.050500</td>\n",
       "      <td>2.018030</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.183800</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>9.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.073600</td>\n",
       "      <td>2.017695</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>9.607300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>2.114100</td>\n",
       "      <td>2.017357</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>9.602300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>2.052800</td>\n",
       "      <td>2.016923</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>9.638100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>2.067400</td>\n",
       "      <td>2.016194</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.372100</td>\n",
       "      <td>9.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>2.061300</td>\n",
       "      <td>2.015599</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>9.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>2.072700</td>\n",
       "      <td>2.015446</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>9.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>2.065300</td>\n",
       "      <td>2.015300</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>9.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>2.043300</td>\n",
       "      <td>2.015208</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>9.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>2.106100</td>\n",
       "      <td>2.015489</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>9.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>1.963300</td>\n",
       "      <td>2.016180</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>9.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.006700</td>\n",
       "      <td>2.016795</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>9.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>2.017269</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>2.111000</td>\n",
       "      <td>2.017523</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>9.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>2.084000</td>\n",
       "      <td>2.017577</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>9.627400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>2.058900</td>\n",
       "      <td>2.017248</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>2.025500</td>\n",
       "      <td>2.016846</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>9.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>2.058300</td>\n",
       "      <td>2.016643</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>9.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>2.097800</td>\n",
       "      <td>2.016540</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.373000</td>\n",
       "      <td>9.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>2.090100</td>\n",
       "      <td>2.016413</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>9.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>2.016500</td>\n",
       "      <td>2.016062</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.184900</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>9.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.103900</td>\n",
       "      <td>2.016095</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>9.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>2.093200</td>\n",
       "      <td>2.016283</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>9.648300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>2.071300</td>\n",
       "      <td>2.016477</td>\n",
       "      <td>0.411100</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>9.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>2.101700</td>\n",
       "      <td>2.017040</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>9.625300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>2.055500</td>\n",
       "      <td>2.017565</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>9.608900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>2.065700</td>\n",
       "      <td>2.017790</td>\n",
       "      <td>0.412300</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>9.646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>2.014300</td>\n",
       "      <td>2.017729</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>9.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>2.094200</td>\n",
       "      <td>2.017020</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>1.968900</td>\n",
       "      <td>2.016382</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.374700</td>\n",
       "      <td>9.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>2.113300</td>\n",
       "      <td>2.015537</td>\n",
       "      <td>0.413200</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>9.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.997200</td>\n",
       "      <td>2.014754</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>2.083600</td>\n",
       "      <td>2.014028</td>\n",
       "      <td>0.413200</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>9.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>2.098500</td>\n",
       "      <td>2.013451</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>9.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>2.069400</td>\n",
       "      <td>2.013052</td>\n",
       "      <td>0.412400</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.716100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>2.069800</td>\n",
       "      <td>2.013153</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>9.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>2.103200</td>\n",
       "      <td>2.013264</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>9.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>1.991600</td>\n",
       "      <td>2.013466</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>9.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>2.098300</td>\n",
       "      <td>2.013479</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>9.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>2.031000</td>\n",
       "      <td>2.013121</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.589700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>2.041100</td>\n",
       "      <td>2.012702</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.003900</td>\n",
       "      <td>2.012372</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>9.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>2.034200</td>\n",
       "      <td>2.011702</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>9.608700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>2.003100</td>\n",
       "      <td>2.010919</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>9.607300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>2.060100</td>\n",
       "      <td>2.010085</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>9.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>2.073700</td>\n",
       "      <td>2.009193</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.611800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.018200</td>\n",
       "      <td>2.008637</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>9.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>2.070700</td>\n",
       "      <td>2.008369</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>1.987600</td>\n",
       "      <td>2.008144</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>9.653600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>2.012900</td>\n",
       "      <td>2.008262</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>9.664700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>2.030200</td>\n",
       "      <td>2.008333</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>9.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.034300</td>\n",
       "      <td>2.008606</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.698500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>2.051600</td>\n",
       "      <td>2.008949</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>2.023600</td>\n",
       "      <td>2.009320</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>9.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>2.024700</td>\n",
       "      <td>2.009676</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>9.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>2.100500</td>\n",
       "      <td>2.010133</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.717100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>2.083800</td>\n",
       "      <td>2.010854</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>9.690300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>2.033900</td>\n",
       "      <td>2.011315</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>9.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>2.069200</td>\n",
       "      <td>2.011523</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>9.716500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>2.053100</td>\n",
       "      <td>2.011225</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>9.717200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>2.010684</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>9.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.078400</td>\n",
       "      <td>2.010176</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>9.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>2.053600</td>\n",
       "      <td>2.009561</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>9.698300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>2.101500</td>\n",
       "      <td>2.008718</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.374700</td>\n",
       "      <td>9.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>1.975400</td>\n",
       "      <td>2.008083</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>9.784800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>1.964300</td>\n",
       "      <td>2.007500</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>9.794700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>2.071200</td>\n",
       "      <td>2.007045</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>9.810800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>2.062300</td>\n",
       "      <td>2.006714</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>9.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>2.029900</td>\n",
       "      <td>2.006792</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>9.768900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>2.007123</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>9.762600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>2.025000</td>\n",
       "      <td>2.007274</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>9.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.018500</td>\n",
       "      <td>2.007208</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.374800</td>\n",
       "      <td>9.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>2.017000</td>\n",
       "      <td>2.006641</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>9.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>2.015800</td>\n",
       "      <td>2.005813</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>9.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>1.967800</td>\n",
       "      <td>2.005180</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>9.828400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>1.978500</td>\n",
       "      <td>2.004651</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>9.844600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>2.079100</td>\n",
       "      <td>2.003989</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>9.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>1.939700</td>\n",
       "      <td>2.003210</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>9.883800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>2.011800</td>\n",
       "      <td>2.002649</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>9.910800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>2.090300</td>\n",
       "      <td>2.002162</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>9.871100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>2.102100</td>\n",
       "      <td>2.001985</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>9.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.050200</td>\n",
       "      <td>2.001756</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>9.904700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>2.021800</td>\n",
       "      <td>2.001688</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>9.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>2.005900</td>\n",
       "      <td>2.001878</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>9.913300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>1.960500</td>\n",
       "      <td>2.002270</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>9.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>2.084000</td>\n",
       "      <td>2.002723</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>9.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>2.011600</td>\n",
       "      <td>2.003316</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>9.884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>2.013000</td>\n",
       "      <td>2.003716</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>9.874400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>2.010100</td>\n",
       "      <td>2.003833</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>9.843300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>2.131800</td>\n",
       "      <td>2.003970</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>9.864400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>2.012400</td>\n",
       "      <td>2.003637</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>9.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.105900</td>\n",
       "      <td>2.003405</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>9.821200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>2.083200</td>\n",
       "      <td>2.003118</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>9.825700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>2.024300</td>\n",
       "      <td>2.002898</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>2.009600</td>\n",
       "      <td>2.002717</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>9.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>2.008800</td>\n",
       "      <td>2.002564</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>9.839300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.990300</td>\n",
       "      <td>2.002329</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>9.853700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>2.083800</td>\n",
       "      <td>2.002405</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>9.836100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>2.086600</td>\n",
       "      <td>2.002420</td>\n",
       "      <td>0.410900</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>9.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>2.001000</td>\n",
       "      <td>2.002437</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.373400</td>\n",
       "      <td>9.827400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>2.032200</td>\n",
       "      <td>2.002444</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>9.852600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.030800</td>\n",
       "      <td>2.002581</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>9.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>2.035800</td>\n",
       "      <td>2.002528</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>9.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>1.999600</td>\n",
       "      <td>2.002723</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>9.837300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>2.077200</td>\n",
       "      <td>2.002806</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.188300</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>9.840300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>2.062700</td>\n",
       "      <td>2.002990</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>0.374700</td>\n",
       "      <td>9.856600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>2.073700</td>\n",
       "      <td>2.003089</td>\n",
       "      <td>0.413200</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.374800</td>\n",
       "      <td>9.876300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>2.046300</td>\n",
       "      <td>2.003303</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>9.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>2.045500</td>\n",
       "      <td>2.003265</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>9.841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>2.009000</td>\n",
       "      <td>2.002660</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>9.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>1.973800</td>\n",
       "      <td>2.001736</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>9.913400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.045800</td>\n",
       "      <td>2.000886</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>9.949600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>2.048600</td>\n",
       "      <td>1.999873</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>9.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>2.029100</td>\n",
       "      <td>1.999086</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>9.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>1.980700</td>\n",
       "      <td>1.998587</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>9.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>1.952900</td>\n",
       "      <td>1.998406</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>9.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>1.990900</td>\n",
       "      <td>1.998230</td>\n",
       "      <td>0.415100</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>9.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>1.988700</td>\n",
       "      <td>1.998307</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>9.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>2.072100</td>\n",
       "      <td>1.998510</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>9.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>1.998200</td>\n",
       "      <td>1.998874</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>9.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>1.982300</td>\n",
       "      <td>1.999295</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>9.952600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.020900</td>\n",
       "      <td>1.999683</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>9.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>2.000294</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>9.906400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>1.914000</td>\n",
       "      <td>2.000850</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>9.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>2.058500</td>\n",
       "      <td>2.001377</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>9.887800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>1.947400</td>\n",
       "      <td>2.001888</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>9.893800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>1.965000</td>\n",
       "      <td>2.002163</td>\n",
       "      <td>0.415100</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>9.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>2.031700</td>\n",
       "      <td>2.002594</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>9.896700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>1.947400</td>\n",
       "      <td>2.002957</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.376300</td>\n",
       "      <td>9.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>2.031900</td>\n",
       "      <td>2.002953</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>9.892200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>1.936500</td>\n",
       "      <td>2.003011</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>9.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.961600</td>\n",
       "      <td>2.003002</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>9.902800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>1.985500</td>\n",
       "      <td>2.002771</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>9.898200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>1.984000</td>\n",
       "      <td>2.002665</td>\n",
       "      <td>0.414300</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>9.870200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>2.048800</td>\n",
       "      <td>2.002395</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>9.915100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>2.038800</td>\n",
       "      <td>2.002147</td>\n",
       "      <td>0.414100</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>9.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>2.070100</td>\n",
       "      <td>2.001776</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>9.903500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>1.942800</td>\n",
       "      <td>2.001734</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.376300</td>\n",
       "      <td>9.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>1.978600</td>\n",
       "      <td>2.001697</td>\n",
       "      <td>0.415100</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>9.986200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>1.958200</td>\n",
       "      <td>2.001854</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>9.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>1.984700</td>\n",
       "      <td>2.002105</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>9.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.998300</td>\n",
       "      <td>2.002245</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>10.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>2.015000</td>\n",
       "      <td>2.002275</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>10.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>1.931100</td>\n",
       "      <td>2.002200</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>10.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>2.018500</td>\n",
       "      <td>2.001939</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>10.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>2.029600</td>\n",
       "      <td>2.001657</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>9.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.984600</td>\n",
       "      <td>2.001151</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>9.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>1.945300</td>\n",
       "      <td>2.000330</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>9.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>1.975500</td>\n",
       "      <td>1.999593</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>10.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>1.971800</td>\n",
       "      <td>1.998899</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>10.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>1.953700</td>\n",
       "      <td>1.998231</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>10.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.879300</td>\n",
       "      <td>1.997730</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>9.991200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>1.981100</td>\n",
       "      <td>1.996922</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>9.951500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>1.985100</td>\n",
       "      <td>1.996226</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>9.963400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>2.024700</td>\n",
       "      <td>1.995516</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>9.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>1.978500</td>\n",
       "      <td>1.994965</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>9.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>1.982000</td>\n",
       "      <td>1.994560</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>9.995700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>1.959300</td>\n",
       "      <td>1.994292</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>10.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>1.963300</td>\n",
       "      <td>1.994082</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>10.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>2.006600</td>\n",
       "      <td>1.993942</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>10.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>1.989200</td>\n",
       "      <td>1.993793</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>10.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.004500</td>\n",
       "      <td>1.993657</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>10.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>2.039900</td>\n",
       "      <td>1.993554</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>10.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>2.019600</td>\n",
       "      <td>1.993469</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>10.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>1.946700</td>\n",
       "      <td>1.993446</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>10.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>2.022900</td>\n",
       "      <td>1.993478</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>9.979400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>1.982300</td>\n",
       "      <td>1.993465</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>9.982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>1.952100</td>\n",
       "      <td>1.993388</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>9.981500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>1.973200</td>\n",
       "      <td>1.993304</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>10.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>2.019900</td>\n",
       "      <td>1.993316</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>10.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>1.985500</td>\n",
       "      <td>1.993351</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>10.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.005300</td>\n",
       "      <td>1.993373</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>10.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>1.971700</td>\n",
       "      <td>1.993331</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>10.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>2.031500</td>\n",
       "      <td>1.993329</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>10.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>1.920400</td>\n",
       "      <td>1.993595</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>10.082900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>2.001400</td>\n",
       "      <td>1.993816</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>10.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>2.030500</td>\n",
       "      <td>1.994209</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>10.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>2.025400</td>\n",
       "      <td>1.994409</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>10.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>2.029800</td>\n",
       "      <td>1.994564</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>10.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>1.971900</td>\n",
       "      <td>1.994740</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>10.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>2.002200</td>\n",
       "      <td>1.994983</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>10.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.939100</td>\n",
       "      <td>1.995212</td>\n",
       "      <td>0.415100</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>10.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>1.954500</td>\n",
       "      <td>1.995400</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>10.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>2.062500</td>\n",
       "      <td>1.995405</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>10.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>1.993200</td>\n",
       "      <td>1.995461</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>10.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>1.994000</td>\n",
       "      <td>1.995516</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>10.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>2.022900</td>\n",
       "      <td>1.995481</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>10.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>1.986400</td>\n",
       "      <td>1.995416</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>10.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>2.082800</td>\n",
       "      <td>1.995320</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>10.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>2.006100</td>\n",
       "      <td>1.995340</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>10.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>2.008500</td>\n",
       "      <td>1.995550</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>10.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.009900</td>\n",
       "      <td>1.995678</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>10.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>2.048300</td>\n",
       "      <td>1.995636</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>9.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>1.964500</td>\n",
       "      <td>1.995524</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>10.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>1.984600</td>\n",
       "      <td>1.995569</td>\n",
       "      <td>0.415400</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>9.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>1.992900</td>\n",
       "      <td>1.995569</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>10.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.960400</td>\n",
       "      <td>1.995340</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>9.995100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>2.027300</td>\n",
       "      <td>1.994955</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>10.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>1.945400</td>\n",
       "      <td>1.994662</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>10.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>1.968200</td>\n",
       "      <td>1.994377</td>\n",
       "      <td>0.416000</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>10.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>2.053400</td>\n",
       "      <td>1.994062</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>10.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.027400</td>\n",
       "      <td>1.993772</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>10.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>1.942500</td>\n",
       "      <td>1.993453</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>10.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>2.041300</td>\n",
       "      <td>1.993151</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>10.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>1.982800</td>\n",
       "      <td>1.992905</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.378500</td>\n",
       "      <td>10.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>2.008600</td>\n",
       "      <td>1.992704</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>10.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>1.952400</td>\n",
       "      <td>1.992543</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>10.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>1.987400</td>\n",
       "      <td>1.992368</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>10.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>1.990700</td>\n",
       "      <td>1.992352</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>10.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>1.974200</td>\n",
       "      <td>1.992351</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.379300</td>\n",
       "      <td>10.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>1.958400</td>\n",
       "      <td>1.992385</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>10.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.997500</td>\n",
       "      <td>1.992425</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>10.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>1.989500</td>\n",
       "      <td>1.992407</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>10.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>2.014600</td>\n",
       "      <td>1.992348</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>10.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>1.884700</td>\n",
       "      <td>1.992319</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>10.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>1.946500</td>\n",
       "      <td>1.992250</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>10.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>2.007800</td>\n",
       "      <td>1.992245</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.192100</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>10.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1.997300</td>\n",
       "      <td>1.992349</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.379800</td>\n",
       "      <td>10.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>2.017200</td>\n",
       "      <td>1.992332</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.379400</td>\n",
       "      <td>10.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>1.958200</td>\n",
       "      <td>1.992279</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.379500</td>\n",
       "      <td>10.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>1.966800</td>\n",
       "      <td>1.992342</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>10.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.001400</td>\n",
       "      <td>1.992336</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>10.046400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>1.959500</td>\n",
       "      <td>1.992303</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>10.041900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training elapsed time: 6545.4099350939505\n"
     ]
    }
   ],
   "source": [
    "if trainer.args.do_train:\n",
    "    os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\"\n",
    "    t1_start = perf_counter()\n",
    "    train_output = trainer.train()\n",
    "    t1_stop = perf_counter()\n",
    "    print(\"Training elapsed time:\", t1_stop - t1_start)\n",
    "\n",
    "    # saving the model which allows us to leverage\n",
    "    # .from_pretrained(model_path)\n",
    "    trainer.save_model(fine_tuned_model_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='68' max='68' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [68/68 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9923362731933594,\n",
       " 'eval_rouge1': 0.4169,\n",
       " 'eval_rouge2': 0.1919,\n",
       " 'eval_rougeL': 0.379,\n",
       " 'eval_sacrebleu': 10.0464,\n",
       " 'eval_runtime': 11.8494,\n",
       " 'eval_samples_per_second': 183.048,\n",
       " 'eval_steps_per_second': 5.739,\n",
       " 'epoch': 2.56}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': 3.7324, 'learning_rate': 0.0004991452991452991, 'epoch': 0.01, 'step': 1}, {'eval_loss': 2.7326464653015137, 'eval_rouge1': 0.0873, 'eval_rouge2': 0.0261, 'eval_rougeL': 0.083, 'eval_sacrebleu': 1.3178, 'eval_runtime': 11.8766, 'eval_samples_per_second': 182.629, 'eval_steps_per_second': 5.726, 'epoch': 0.01, 'step': 1}, {'loss': 3.348, 'learning_rate': 0.0004982905982905984, 'epoch': 0.01, 'step': 2}, {'eval_loss': 2.5974490642547607, 'eval_rouge1': 0.0837, 'eval_rouge2': 0.0247, 'eval_rougeL': 0.0799, 'eval_sacrebleu': 1.2673, 'eval_runtime': 12.0441, 'eval_samples_per_second': 180.088, 'eval_steps_per_second': 5.646, 'epoch': 0.01, 'step': 2}, {'loss': 3.0771, 'learning_rate': 0.0004974358974358975, 'epoch': 0.02, 'step': 3}, {'eval_loss': 2.513495922088623, 'eval_rouge1': 0.1004, 'eval_rouge2': 0.0325, 'eval_rougeL': 0.0943, 'eval_sacrebleu': 1.5881, 'eval_runtime': 11.9318, 'eval_samples_per_second': 181.783, 'eval_steps_per_second': 5.699, 'epoch': 0.02, 'step': 3}, {'loss': 3.0537, 'learning_rate': 0.0004965811965811966, 'epoch': 0.02, 'step': 4}, {'eval_loss': 2.4420058727264404, 'eval_rouge1': 0.124, 'eval_rouge2': 0.0423, 'eval_rougeL': 0.1131, 'eval_sacrebleu': 1.9555, 'eval_runtime': 12.2391, 'eval_samples_per_second': 177.219, 'eval_steps_per_second': 5.556, 'epoch': 0.02, 'step': 4}, {'loss': 2.9986, 'learning_rate': 0.0004957264957264957, 'epoch': 0.03, 'step': 5}, {'eval_loss': 2.4016590118408203, 'eval_rouge1': 0.1693, 'eval_rouge2': 0.0597, 'eval_rougeL': 0.1513, 'eval_sacrebleu': 2.6994, 'eval_runtime': 11.8537, 'eval_samples_per_second': 182.982, 'eval_steps_per_second': 5.737, 'epoch': 0.03, 'step': 5}, {'loss': 2.8452, 'learning_rate': 0.0004948717948717949, 'epoch': 0.03, 'step': 6}, {'eval_loss': 2.3714046478271484, 'eval_rouge1': 0.222, 'eval_rouge2': 0.0828, 'eval_rougeL': 0.197, 'eval_sacrebleu': 3.8244, 'eval_runtime': 12.0739, 'eval_samples_per_second': 179.644, 'eval_steps_per_second': 5.632, 'epoch': 0.03, 'step': 6}, {'loss': 2.7669, 'learning_rate': 0.000494017094017094, 'epoch': 0.04, 'step': 7}, {'eval_loss': 2.3487539291381836, 'eval_rouge1': 0.2606, 'eval_rouge2': 0.0989, 'eval_rougeL': 0.2328, 'eval_sacrebleu': 4.6697, 'eval_runtime': 11.906, 'eval_samples_per_second': 182.177, 'eval_steps_per_second': 5.711, 'epoch': 0.04, 'step': 7}, {'loss': 2.7302, 'learning_rate': 0.0004931623931623932, 'epoch': 0.04, 'step': 8}, {'eval_loss': 2.332908868789673, 'eval_rouge1': 0.2928, 'eval_rouge2': 0.1102, 'eval_rougeL': 0.2612, 'eval_sacrebleu': 5.3461, 'eval_runtime': 12.1257, 'eval_samples_per_second': 178.876, 'eval_steps_per_second': 5.608, 'epoch': 0.04, 'step': 8}, {'loss': 2.7656, 'learning_rate': 0.0004923076923076924, 'epoch': 0.05, 'step': 9}, {'eval_loss': 2.3210055828094482, 'eval_rouge1': 0.3184, 'eval_rouge2': 0.1212, 'eval_rougeL': 0.284, 'eval_sacrebleu': 5.9864, 'eval_runtime': 11.8817, 'eval_samples_per_second': 182.55, 'eval_steps_per_second': 5.723, 'epoch': 0.05, 'step': 9}, {'loss': 2.6938, 'learning_rate': 0.0004914529914529914, 'epoch': 0.05, 'step': 10}, {'eval_loss': 2.309530735015869, 'eval_rouge1': 0.334, 'eval_rouge2': 0.1275, 'eval_rougeL': 0.299, 'eval_sacrebleu': 6.276, 'eval_runtime': 12.0536, 'eval_samples_per_second': 179.946, 'eval_steps_per_second': 5.641, 'epoch': 0.05, 'step': 10}, {'loss': 2.6797, 'learning_rate': 0.0004905982905982906, 'epoch': 0.06, 'step': 11}, {'eval_loss': 2.2976186275482178, 'eval_rouge1': 0.344, 'eval_rouge2': 0.1328, 'eval_rougeL': 0.3079, 'eval_sacrebleu': 6.5601, 'eval_runtime': 11.8483, 'eval_samples_per_second': 183.064, 'eval_steps_per_second': 5.739, 'epoch': 0.06, 'step': 11}, {'loss': 2.6895, 'learning_rate': 0.0004897435897435897, 'epoch': 0.06, 'step': 12}, {'eval_loss': 2.287619113922119, 'eval_rouge1': 0.3516, 'eval_rouge2': 0.1367, 'eval_rougeL': 0.315, 'eval_sacrebleu': 6.823, 'eval_runtime': 12.072, 'eval_samples_per_second': 179.673, 'eval_steps_per_second': 5.633, 'epoch': 0.06, 'step': 12}, {'loss': 2.6391, 'learning_rate': 0.0004888888888888889, 'epoch': 0.07, 'step': 13}, {'eval_loss': 2.2789738178253174, 'eval_rouge1': 0.3549, 'eval_rouge2': 0.1394, 'eval_rougeL': 0.3171, 'eval_sacrebleu': 6.982, 'eval_runtime': 11.8658, 'eval_samples_per_second': 182.795, 'eval_steps_per_second': 5.731, 'epoch': 0.07, 'step': 13}, {'loss': 2.5771, 'learning_rate': 0.00048803418803418803, 'epoch': 0.07, 'step': 14}, {'eval_loss': 2.2711119651794434, 'eval_rouge1': 0.3596, 'eval_rouge2': 0.1417, 'eval_rougeL': 0.3205, 'eval_sacrebleu': 7.1508, 'eval_runtime': 11.7843, 'eval_samples_per_second': 184.058, 'eval_steps_per_second': 5.77, 'epoch': 0.07, 'step': 14}, {'loss': 2.5894, 'learning_rate': 0.0004871794871794872, 'epoch': 0.08, 'step': 15}, {'eval_loss': 2.2652745246887207, 'eval_rouge1': 0.3592, 'eval_rouge2': 0.1406, 'eval_rougeL': 0.3194, 'eval_sacrebleu': 7.142, 'eval_runtime': 11.8572, 'eval_samples_per_second': 182.927, 'eval_steps_per_second': 5.735, 'epoch': 0.08, 'step': 15}, {'loss': 2.6474, 'learning_rate': 0.0004863247863247863, 'epoch': 0.08, 'step': 16}, {'eval_loss': 2.2591805458068848, 'eval_rouge1': 0.3606, 'eval_rouge2': 0.1423, 'eval_rougeL': 0.3211, 'eval_sacrebleu': 7.1461, 'eval_runtime': 11.8632, 'eval_samples_per_second': 182.835, 'eval_steps_per_second': 5.732, 'epoch': 0.08, 'step': 16}, {'loss': 2.5954, 'learning_rate': 0.0004854700854700855, 'epoch': 0.09, 'step': 17}, {'eval_loss': 2.253570318222046, 'eval_rouge1': 0.3618, 'eval_rouge2': 0.1432, 'eval_rougeL': 0.3217, 'eval_sacrebleu': 7.2269, 'eval_runtime': 12.1075, 'eval_samples_per_second': 179.146, 'eval_steps_per_second': 5.616, 'epoch': 0.09, 'step': 17}, {'loss': 2.5858, 'learning_rate': 0.0004846153846153846, 'epoch': 0.09, 'step': 18}, {'eval_loss': 2.247728109359741, 'eval_rouge1': 0.3634, 'eval_rouge2': 0.1434, 'eval_rougeL': 0.3231, 'eval_sacrebleu': 7.2731, 'eval_runtime': 11.8598, 'eval_samples_per_second': 182.886, 'eval_steps_per_second': 5.734, 'epoch': 0.09, 'step': 18}, {'loss': 2.4341, 'learning_rate': 0.0004837606837606838, 'epoch': 0.1, 'step': 19}, {'eval_loss': 2.242384433746338, 'eval_rouge1': 0.3644, 'eval_rouge2': 0.1443, 'eval_rougeL': 0.3245, 'eval_sacrebleu': 7.3236, 'eval_runtime': 12.0705, 'eval_samples_per_second': 179.695, 'eval_steps_per_second': 5.634, 'epoch': 0.1, 'step': 19}, {'loss': 2.5649, 'learning_rate': 0.0004829059829059829, 'epoch': 0.1, 'step': 20}, {'eval_loss': 2.2370352745056152, 'eval_rouge1': 0.3661, 'eval_rouge2': 0.1462, 'eval_rougeL': 0.3262, 'eval_sacrebleu': 7.4316, 'eval_runtime': 11.9734, 'eval_samples_per_second': 181.152, 'eval_steps_per_second': 5.679, 'epoch': 0.1, 'step': 20}, {'loss': 2.5828, 'learning_rate': 0.00048205128205128207, 'epoch': 0.11, 'step': 21}, {'eval_loss': 2.2320730686187744, 'eval_rouge1': 0.3683, 'eval_rouge2': 0.1477, 'eval_rougeL': 0.328, 'eval_sacrebleu': 7.4658, 'eval_runtime': 12.1448, 'eval_samples_per_second': 178.595, 'eval_steps_per_second': 5.599, 'epoch': 0.11, 'step': 21}, {'loss': 2.5561, 'learning_rate': 0.00048119658119658124, 'epoch': 0.11, 'step': 22}, {'eval_loss': 2.2277121543884277, 'eval_rouge1': 0.3698, 'eval_rouge2': 0.1485, 'eval_rougeL': 0.33, 'eval_sacrebleu': 7.5289, 'eval_runtime': 11.8457, 'eval_samples_per_second': 183.104, 'eval_steps_per_second': 5.74, 'epoch': 0.11, 'step': 22}, {'loss': 2.4971, 'learning_rate': 0.00048034188034188035, 'epoch': 0.12, 'step': 23}, {'eval_loss': 2.2231829166412354, 'eval_rouge1': 0.3699, 'eval_rouge2': 0.1479, 'eval_rougeL': 0.3298, 'eval_sacrebleu': 7.4373, 'eval_runtime': 11.8004, 'eval_samples_per_second': 183.807, 'eval_steps_per_second': 5.762, 'epoch': 0.12, 'step': 23}, {'loss': 2.5796, 'learning_rate': 0.0004794871794871795, 'epoch': 0.12, 'step': 24}, {'eval_loss': 2.2179975509643555, 'eval_rouge1': 0.3709, 'eval_rouge2': 0.1494, 'eval_rougeL': 0.3313, 'eval_sacrebleu': 7.5087, 'eval_runtime': 11.8885, 'eval_samples_per_second': 182.445, 'eval_steps_per_second': 5.72, 'epoch': 0.12, 'step': 24}, {'loss': 2.4178, 'learning_rate': 0.00047863247863247864, 'epoch': 0.13, 'step': 25}, {'eval_loss': 2.212477207183838, 'eval_rouge1': 0.3709, 'eval_rouge2': 0.1489, 'eval_rougeL': 0.3311, 'eval_sacrebleu': 7.4546, 'eval_runtime': 12.0517, 'eval_samples_per_second': 179.974, 'eval_steps_per_second': 5.642, 'epoch': 0.13, 'step': 25}, {'loss': 2.4816, 'learning_rate': 0.0004777777777777778, 'epoch': 0.13, 'step': 26}, {'eval_loss': 2.206444025039673, 'eval_rouge1': 0.3713, 'eval_rouge2': 0.1482, 'eval_rougeL': 0.3309, 'eval_sacrebleu': 7.4093, 'eval_runtime': 12.2138, 'eval_samples_per_second': 177.586, 'eval_steps_per_second': 5.567, 'epoch': 0.13, 'step': 26}, {'loss': 2.5063, 'learning_rate': 0.000476923076923077, 'epoch': 0.14, 'step': 27}, {'eval_loss': 2.2009196281433105, 'eval_rouge1': 0.3711, 'eval_rouge2': 0.1485, 'eval_rougeL': 0.3307, 'eval_sacrebleu': 7.4659, 'eval_runtime': 11.8582, 'eval_samples_per_second': 182.911, 'eval_steps_per_second': 5.734, 'epoch': 0.14, 'step': 27}, {'loss': 2.4833, 'learning_rate': 0.00047606837606837605, 'epoch': 0.14, 'step': 28}, {'eval_loss': 2.195152521133423, 'eval_rouge1': 0.3729, 'eval_rouge2': 0.1495, 'eval_rougeL': 0.3327, 'eval_sacrebleu': 7.5461, 'eval_runtime': 12.0811, 'eval_samples_per_second': 179.536, 'eval_steps_per_second': 5.629, 'epoch': 0.14, 'step': 28}, {'loss': 2.5095, 'learning_rate': 0.0004752136752136752, 'epoch': 0.15, 'step': 29}, {'eval_loss': 2.1902899742126465, 'eval_rouge1': 0.374, 'eval_rouge2': 0.1512, 'eval_rougeL': 0.3341, 'eval_sacrebleu': 7.6396, 'eval_runtime': 12.0039, 'eval_samples_per_second': 180.691, 'eval_steps_per_second': 5.665, 'epoch': 0.15, 'step': 29}, {'loss': 2.5383, 'learning_rate': 0.00047435897435897434, 'epoch': 0.15, 'step': 30}, {'eval_loss': 2.1857004165649414, 'eval_rouge1': 0.3744, 'eval_rouge2': 0.1513, 'eval_rougeL': 0.3342, 'eval_sacrebleu': 7.6345, 'eval_runtime': 12.1279, 'eval_samples_per_second': 178.844, 'eval_steps_per_second': 5.607, 'epoch': 0.15, 'step': 30}, {'loss': 2.4268, 'learning_rate': 0.0004735042735042735, 'epoch': 0.16, 'step': 31}, {'eval_loss': 2.1816346645355225, 'eval_rouge1': 0.3744, 'eval_rouge2': 0.1523, 'eval_rougeL': 0.3345, 'eval_sacrebleu': 7.6789, 'eval_runtime': 11.9086, 'eval_samples_per_second': 182.137, 'eval_steps_per_second': 5.71, 'epoch': 0.16, 'step': 31}, {'loss': 2.4178, 'learning_rate': 0.0004726495726495726, 'epoch': 0.16, 'step': 32}, {'eval_loss': 2.1786818504333496, 'eval_rouge1': 0.3754, 'eval_rouge2': 0.1528, 'eval_rougeL': 0.3352, 'eval_sacrebleu': 7.7226, 'eval_runtime': 11.9803, 'eval_samples_per_second': 181.046, 'eval_steps_per_second': 5.676, 'epoch': 0.16, 'step': 32}, {'loss': 2.4822, 'learning_rate': 0.0004717948717948718, 'epoch': 0.17, 'step': 33}, {'eval_loss': 2.175583600997925, 'eval_rouge1': 0.3762, 'eval_rouge2': 0.1536, 'eval_rougeL': 0.3363, 'eval_sacrebleu': 7.7606, 'eval_runtime': 12.1842, 'eval_samples_per_second': 178.017, 'eval_steps_per_second': 5.581, 'epoch': 0.17, 'step': 33}, {'loss': 2.4484, 'learning_rate': 0.00047094017094017097, 'epoch': 0.17, 'step': 34}, {'eval_loss': 2.1732523441314697, 'eval_rouge1': 0.376, 'eval_rouge2': 0.1543, 'eval_rougeL': 0.3366, 'eval_sacrebleu': 7.7933, 'eval_runtime': 11.8117, 'eval_samples_per_second': 183.632, 'eval_steps_per_second': 5.757, 'epoch': 0.17, 'step': 34}, {'loss': 2.5142, 'learning_rate': 0.0004700854700854701, 'epoch': 0.18, 'step': 35}, {'eval_loss': 2.1710352897644043, 'eval_rouge1': 0.3771, 'eval_rouge2': 0.1555, 'eval_rougeL': 0.3373, 'eval_sacrebleu': 7.8985, 'eval_runtime': 12.2548, 'eval_samples_per_second': 176.992, 'eval_steps_per_second': 5.549, 'epoch': 0.18, 'step': 35}, {'loss': 2.4171, 'learning_rate': 0.00046923076923076926, 'epoch': 0.18, 'step': 36}, {'eval_loss': 2.170020818710327, 'eval_rouge1': 0.3781, 'eval_rouge2': 0.1562, 'eval_rougeL': 0.3383, 'eval_sacrebleu': 7.9012, 'eval_runtime': 11.7917, 'eval_samples_per_second': 183.943, 'eval_steps_per_second': 5.767, 'epoch': 0.18, 'step': 36}, {'loss': 2.386, 'learning_rate': 0.0004683760683760684, 'epoch': 0.19, 'step': 37}, {'eval_loss': 2.1698145866394043, 'eval_rouge1': 0.3785, 'eval_rouge2': 0.1567, 'eval_rougeL': 0.3394, 'eval_sacrebleu': 7.8988, 'eval_runtime': 12.171, 'eval_samples_per_second': 178.21, 'eval_steps_per_second': 5.587, 'epoch': 0.19, 'step': 37}, {'loss': 2.4025, 'learning_rate': 0.00046752136752136754, 'epoch': 0.19, 'step': 38}, {'eval_loss': 2.170050621032715, 'eval_rouge1': 0.3785, 'eval_rouge2': 0.1572, 'eval_rougeL': 0.3396, 'eval_sacrebleu': 7.8921, 'eval_runtime': 11.6106, 'eval_samples_per_second': 186.813, 'eval_steps_per_second': 5.857, 'epoch': 0.19, 'step': 38}, {'loss': 2.4068, 'learning_rate': 0.00046666666666666666, 'epoch': 0.2, 'step': 39}, {'eval_loss': 2.1707983016967773, 'eval_rouge1': 0.3789, 'eval_rouge2': 0.1571, 'eval_rougeL': 0.3397, 'eval_sacrebleu': 7.9138, 'eval_runtime': 11.6305, 'eval_samples_per_second': 186.493, 'eval_steps_per_second': 5.847, 'epoch': 0.2, 'step': 39}, {'loss': 2.4435, 'learning_rate': 0.00046581196581196583, 'epoch': 0.2, 'step': 40}, {'eval_loss': 2.1712934970855713, 'eval_rouge1': 0.3797, 'eval_rouge2': 0.1573, 'eval_rougeL': 0.3404, 'eval_sacrebleu': 7.9436, 'eval_runtime': 11.6433, 'eval_samples_per_second': 186.287, 'eval_steps_per_second': 5.84, 'epoch': 0.2, 'step': 40}, {'loss': 2.371, 'learning_rate': 0.000464957264957265, 'epoch': 0.21, 'step': 41}, {'eval_loss': 2.171318769454956, 'eval_rouge1': 0.38, 'eval_rouge2': 0.1577, 'eval_rougeL': 0.3414, 'eval_sacrebleu': 7.9468, 'eval_runtime': 11.7417, 'eval_samples_per_second': 184.727, 'eval_steps_per_second': 5.791, 'epoch': 0.21, 'step': 41}, {'loss': 2.42, 'learning_rate': 0.0004641025641025641, 'epoch': 0.21, 'step': 42}, {'eval_loss': 2.1707401275634766, 'eval_rouge1': 0.3795, 'eval_rouge2': 0.1579, 'eval_rougeL': 0.3412, 'eval_sacrebleu': 7.9553, 'eval_runtime': 12.1423, 'eval_samples_per_second': 178.632, 'eval_steps_per_second': 5.6, 'epoch': 0.21, 'step': 42}, {'loss': 2.4, 'learning_rate': 0.0004632478632478633, 'epoch': 0.22, 'step': 43}, {'eval_loss': 2.170011043548584, 'eval_rouge1': 0.3794, 'eval_rouge2': 0.1581, 'eval_rougeL': 0.3413, 'eval_sacrebleu': 7.9365, 'eval_runtime': 11.8567, 'eval_samples_per_second': 182.934, 'eval_steps_per_second': 5.735, 'epoch': 0.22, 'step': 43}, {'loss': 2.3931, 'learning_rate': 0.0004623931623931624, 'epoch': 0.23, 'step': 44}, {'eval_loss': 2.168701648712158, 'eval_rouge1': 0.381, 'eval_rouge2': 0.1593, 'eval_rougeL': 0.3426, 'eval_sacrebleu': 8.0768, 'eval_runtime': 12.2317, 'eval_samples_per_second': 177.325, 'eval_steps_per_second': 5.559, 'epoch': 0.23, 'step': 44}, {'loss': 2.4252, 'learning_rate': 0.0004615384615384616, 'epoch': 0.23, 'step': 45}, {'eval_loss': 2.1667704582214355, 'eval_rouge1': 0.3814, 'eval_rouge2': 0.1595, 'eval_rougeL': 0.3428, 'eval_sacrebleu': 8.1338, 'eval_runtime': 12.0217, 'eval_samples_per_second': 180.424, 'eval_steps_per_second': 5.656, 'epoch': 0.23, 'step': 45}, {'loss': 2.4416, 'learning_rate': 0.00046068376068376064, 'epoch': 0.24, 'step': 46}, {'eval_loss': 2.164280652999878, 'eval_rouge1': 0.3804, 'eval_rouge2': 0.1594, 'eval_rougeL': 0.3424, 'eval_sacrebleu': 8.1484, 'eval_runtime': 11.9276, 'eval_samples_per_second': 181.847, 'eval_steps_per_second': 5.701, 'epoch': 0.24, 'step': 46}, {'loss': 2.4262, 'learning_rate': 0.0004598290598290598, 'epoch': 0.24, 'step': 47}, {'eval_loss': 2.1615803241729736, 'eval_rouge1': 0.3805, 'eval_rouge2': 0.1598, 'eval_rougeL': 0.3423, 'eval_sacrebleu': 8.1424, 'eval_runtime': 11.65, 'eval_samples_per_second': 186.181, 'eval_steps_per_second': 5.837, 'epoch': 0.24, 'step': 47}, {'loss': 2.3377, 'learning_rate': 0.000458974358974359, 'epoch': 0.25, 'step': 48}, {'eval_loss': 2.158000946044922, 'eval_rouge1': 0.3821, 'eval_rouge2': 0.1606, 'eval_rougeL': 0.3435, 'eval_sacrebleu': 8.1518, 'eval_runtime': 11.6296, 'eval_samples_per_second': 186.507, 'eval_steps_per_second': 5.847, 'epoch': 0.25, 'step': 48}, {'loss': 2.354, 'learning_rate': 0.0004581196581196581, 'epoch': 0.25, 'step': 49}, {'eval_loss': 2.1547434329986572, 'eval_rouge1': 0.3826, 'eval_rouge2': 0.1616, 'eval_rougeL': 0.3438, 'eval_sacrebleu': 8.1819, 'eval_runtime': 11.9218, 'eval_samples_per_second': 181.936, 'eval_steps_per_second': 5.704, 'epoch': 0.25, 'step': 49}, {'loss': 2.355, 'learning_rate': 0.0004572649572649573, 'epoch': 0.26, 'step': 50}, {'eval_loss': 2.151437759399414, 'eval_rouge1': 0.3821, 'eval_rouge2': 0.1604, 'eval_rougeL': 0.3435, 'eval_sacrebleu': 8.1477, 'eval_runtime': 11.6083, 'eval_samples_per_second': 186.849, 'eval_steps_per_second': 5.858, 'epoch': 0.26, 'step': 50}, {'loss': 2.3363, 'learning_rate': 0.0004564102564102564, 'epoch': 0.26, 'step': 51}, {'eval_loss': 2.1486356258392334, 'eval_rouge1': 0.3833, 'eval_rouge2': 0.1611, 'eval_rougeL': 0.3446, 'eval_sacrebleu': 8.2107, 'eval_runtime': 11.8877, 'eval_samples_per_second': 182.457, 'eval_steps_per_second': 5.72, 'epoch': 0.26, 'step': 51}, {'loss': 2.4305, 'learning_rate': 0.00045555555555555556, 'epoch': 0.27, 'step': 52}, {'eval_loss': 2.1455936431884766, 'eval_rouge1': 0.3841, 'eval_rouge2': 0.1628, 'eval_rougeL': 0.3457, 'eval_sacrebleu': 8.2968, 'eval_runtime': 11.7977, 'eval_samples_per_second': 183.849, 'eval_steps_per_second': 5.764, 'epoch': 0.27, 'step': 52}, {'loss': 2.3381, 'learning_rate': 0.0004547008547008547, 'epoch': 0.27, 'step': 53}, {'eval_loss': 2.1427078247070312, 'eval_rouge1': 0.3849, 'eval_rouge2': 0.1625, 'eval_rougeL': 0.3464, 'eval_sacrebleu': 8.3188, 'eval_runtime': 12.1447, 'eval_samples_per_second': 178.597, 'eval_steps_per_second': 5.599, 'epoch': 0.27, 'step': 53}, {'loss': 2.3753, 'learning_rate': 0.00045384615384615385, 'epoch': 0.28, 'step': 54}, {'eval_loss': 2.140141248703003, 'eval_rouge1': 0.3854, 'eval_rouge2': 0.1633, 'eval_rougeL': 0.3465, 'eval_sacrebleu': 8.3138, 'eval_runtime': 11.8436, 'eval_samples_per_second': 183.137, 'eval_steps_per_second': 5.741, 'epoch': 0.28, 'step': 54}, {'loss': 2.3629, 'learning_rate': 0.000452991452991453, 'epoch': 0.28, 'step': 55}, {'eval_loss': 2.1380321979522705, 'eval_rouge1': 0.3858, 'eval_rouge2': 0.1633, 'eval_rougeL': 0.3463, 'eval_sacrebleu': 8.3242, 'eval_runtime': 12.1672, 'eval_samples_per_second': 178.266, 'eval_steps_per_second': 5.589, 'epoch': 0.28, 'step': 55}, {'loss': 2.3373, 'learning_rate': 0.00045213675213675214, 'epoch': 0.29, 'step': 56}, {'eval_loss': 2.136167287826538, 'eval_rouge1': 0.3867, 'eval_rouge2': 0.1639, 'eval_rougeL': 0.3475, 'eval_sacrebleu': 8.3345, 'eval_runtime': 11.8662, 'eval_samples_per_second': 182.788, 'eval_steps_per_second': 5.731, 'epoch': 0.29, 'step': 56}, {'loss': 2.4078, 'learning_rate': 0.0004512820512820513, 'epoch': 0.29, 'step': 57}, {'eval_loss': 2.1343278884887695, 'eval_rouge1': 0.3879, 'eval_rouge2': 0.1643, 'eval_rougeL': 0.3486, 'eval_sacrebleu': 8.3392, 'eval_runtime': 11.8996, 'eval_samples_per_second': 182.275, 'eval_steps_per_second': 5.714, 'epoch': 0.29, 'step': 57}, {'loss': 2.373, 'learning_rate': 0.00045042735042735043, 'epoch': 0.3, 'step': 58}, {'eval_loss': 2.13297963142395, 'eval_rouge1': 0.3883, 'eval_rouge2': 0.1643, 'eval_rougeL': 0.3484, 'eval_sacrebleu': 8.4197, 'eval_runtime': 12.1314, 'eval_samples_per_second': 178.792, 'eval_steps_per_second': 5.605, 'epoch': 0.3, 'step': 58}, {'loss': 2.2407, 'learning_rate': 0.0004495726495726496, 'epoch': 0.3, 'step': 59}, {'eval_loss': 2.1322829723358154, 'eval_rouge1': 0.388, 'eval_rouge2': 0.1636, 'eval_rougeL': 0.3486, 'eval_sacrebleu': 8.4191, 'eval_runtime': 11.829, 'eval_samples_per_second': 183.363, 'eval_steps_per_second': 5.749, 'epoch': 0.3, 'step': 59}, {'loss': 2.329, 'learning_rate': 0.0004487179487179487, 'epoch': 0.31, 'step': 60}, {'eval_loss': 2.1315035820007324, 'eval_rouge1': 0.3868, 'eval_rouge2': 0.1626, 'eval_rougeL': 0.3481, 'eval_sacrebleu': 8.3908, 'eval_runtime': 12.1107, 'eval_samples_per_second': 179.097, 'eval_steps_per_second': 5.615, 'epoch': 0.31, 'step': 60}, {'loss': 2.378, 'learning_rate': 0.0004478632478632479, 'epoch': 0.31, 'step': 61}, {'eval_loss': 2.1312992572784424, 'eval_rouge1': 0.3874, 'eval_rouge2': 0.1632, 'eval_rougeL': 0.3485, 'eval_sacrebleu': 8.4338, 'eval_runtime': 11.8528, 'eval_samples_per_second': 182.995, 'eval_steps_per_second': 5.737, 'epoch': 0.31, 'step': 61}, {'loss': 2.3864, 'learning_rate': 0.00044700854700854706, 'epoch': 0.32, 'step': 62}, {'eval_loss': 2.1308045387268066, 'eval_rouge1': 0.3877, 'eval_rouge2': 0.1634, 'eval_rougeL': 0.3483, 'eval_sacrebleu': 8.4665, 'eval_runtime': 12.1282, 'eval_samples_per_second': 178.84, 'eval_steps_per_second': 5.607, 'epoch': 0.32, 'step': 62}, {'loss': 2.2721, 'learning_rate': 0.0004461538461538462, 'epoch': 0.32, 'step': 63}, {'eval_loss': 2.1303133964538574, 'eval_rouge1': 0.388, 'eval_rouge2': 0.1638, 'eval_rougeL': 0.3488, 'eval_sacrebleu': 8.4737, 'eval_runtime': 11.8303, 'eval_samples_per_second': 183.343, 'eval_steps_per_second': 5.748, 'epoch': 0.32, 'step': 63}, {'loss': 2.3162, 'learning_rate': 0.0004452991452991453, 'epoch': 0.33, 'step': 64}, {'eval_loss': 2.129561424255371, 'eval_rouge1': 0.3883, 'eval_rouge2': 0.1653, 'eval_rougeL': 0.3491, 'eval_sacrebleu': 8.5559, 'eval_runtime': 11.8556, 'eval_samples_per_second': 182.951, 'eval_steps_per_second': 5.736, 'epoch': 0.33, 'step': 64}, {'loss': 2.3894, 'learning_rate': 0.0004444444444444444, 'epoch': 0.33, 'step': 65}, {'eval_loss': 2.1284596920013428, 'eval_rouge1': 0.3887, 'eval_rouge2': 0.1656, 'eval_rougeL': 0.3499, 'eval_sacrebleu': 8.5827, 'eval_runtime': 12.0139, 'eval_samples_per_second': 180.54, 'eval_steps_per_second': 5.66, 'epoch': 0.33, 'step': 65}, {'loss': 2.2831, 'learning_rate': 0.0004435897435897436, 'epoch': 0.34, 'step': 66}, {'eval_loss': 2.126868963241577, 'eval_rouge1': 0.3899, 'eval_rouge2': 0.1665, 'eval_rougeL': 0.3511, 'eval_sacrebleu': 8.5971, 'eval_runtime': 11.6367, 'eval_samples_per_second': 186.392, 'eval_steps_per_second': 5.844, 'epoch': 0.34, 'step': 66}, {'loss': 2.2501, 'learning_rate': 0.0004427350427350427, 'epoch': 0.34, 'step': 67}, {'eval_loss': 2.1252706050872803, 'eval_rouge1': 0.3908, 'eval_rouge2': 0.1674, 'eval_rougeL': 0.3521, 'eval_sacrebleu': 8.6019, 'eval_runtime': 12.0749, 'eval_samples_per_second': 179.629, 'eval_steps_per_second': 5.632, 'epoch': 0.34, 'step': 67}, {'loss': 2.3038, 'learning_rate': 0.00044188034188034187, 'epoch': 0.35, 'step': 68}, {'eval_loss': 2.124218463897705, 'eval_rouge1': 0.3917, 'eval_rouge2': 0.1678, 'eval_rougeL': 0.3531, 'eval_sacrebleu': 8.6047, 'eval_runtime': 11.8872, 'eval_samples_per_second': 182.466, 'eval_steps_per_second': 5.72, 'epoch': 0.35, 'step': 68}, {'loss': 2.3809, 'learning_rate': 0.00044102564102564104, 'epoch': 0.35, 'step': 69}, {'eval_loss': 2.1230688095092773, 'eval_rouge1': 0.391, 'eval_rouge2': 0.1669, 'eval_rougeL': 0.3521, 'eval_sacrebleu': 8.562, 'eval_runtime': 12.146, 'eval_samples_per_second': 178.577, 'eval_steps_per_second': 5.599, 'epoch': 0.35, 'step': 69}, {'loss': 2.3114, 'learning_rate': 0.00044017094017094016, 'epoch': 0.36, 'step': 70}, {'eval_loss': 2.1221559047698975, 'eval_rouge1': 0.3905, 'eval_rouge2': 0.1669, 'eval_rougeL': 0.3516, 'eval_sacrebleu': 8.5248, 'eval_runtime': 11.8624, 'eval_samples_per_second': 182.847, 'eval_steps_per_second': 5.732, 'epoch': 0.36, 'step': 70}, {'loss': 2.2577, 'learning_rate': 0.00043931623931623933, 'epoch': 0.36, 'step': 71}, {'eval_loss': 2.1216325759887695, 'eval_rouge1': 0.3919, 'eval_rouge2': 0.168, 'eval_rougeL': 0.3527, 'eval_sacrebleu': 8.5959, 'eval_runtime': 11.835, 'eval_samples_per_second': 183.27, 'eval_steps_per_second': 5.746, 'epoch': 0.36, 'step': 71}, {'loss': 2.3738, 'learning_rate': 0.00043846153846153845, 'epoch': 0.37, 'step': 72}, {'eval_loss': 2.1208605766296387, 'eval_rouge1': 0.3903, 'eval_rouge2': 0.1667, 'eval_rougeL': 0.3517, 'eval_sacrebleu': 8.5086, 'eval_runtime': 11.8698, 'eval_samples_per_second': 182.733, 'eval_steps_per_second': 5.729, 'epoch': 0.37, 'step': 72}, {'loss': 2.3577, 'learning_rate': 0.0004376068376068376, 'epoch': 0.37, 'step': 73}, {'eval_loss': 2.12060284614563, 'eval_rouge1': 0.3899, 'eval_rouge2': 0.1666, 'eval_rougeL': 0.3512, 'eval_sacrebleu': 8.4772, 'eval_runtime': 11.8436, 'eval_samples_per_second': 183.137, 'eval_steps_per_second': 5.742, 'epoch': 0.37, 'step': 73}, {'loss': 2.3799, 'learning_rate': 0.0004367521367521368, 'epoch': 0.38, 'step': 74}, {'eval_loss': 2.1205976009368896, 'eval_rouge1': 0.3889, 'eval_rouge2': 0.1661, 'eval_rougeL': 0.35, 'eval_sacrebleu': 8.4405, 'eval_runtime': 12.1312, 'eval_samples_per_second': 178.795, 'eval_steps_per_second': 5.605, 'epoch': 0.38, 'step': 74}, {'loss': 2.2667, 'learning_rate': 0.0004358974358974359, 'epoch': 0.38, 'step': 75}, {'eval_loss': 2.120230197906494, 'eval_rouge1': 0.3881, 'eval_rouge2': 0.1662, 'eval_rougeL': 0.3495, 'eval_sacrebleu': 8.422, 'eval_runtime': 11.8627, 'eval_samples_per_second': 182.843, 'eval_steps_per_second': 5.732, 'epoch': 0.38, 'step': 75}, {'loss': 2.3114, 'learning_rate': 0.0004350427350427351, 'epoch': 0.39, 'step': 76}, {'eval_loss': 2.118942975997925, 'eval_rouge1': 0.3882, 'eval_rouge2': 0.166, 'eval_rougeL': 0.3495, 'eval_sacrebleu': 8.4312, 'eval_runtime': 12.1133, 'eval_samples_per_second': 179.06, 'eval_steps_per_second': 5.614, 'epoch': 0.39, 'step': 76}, {'loss': 2.34, 'learning_rate': 0.0004341880341880342, 'epoch': 0.39, 'step': 77}, {'eval_loss': 2.1169815063476562, 'eval_rouge1': 0.3888, 'eval_rouge2': 0.1662, 'eval_rougeL': 0.35, 'eval_sacrebleu': 8.4657, 'eval_runtime': 11.8432, 'eval_samples_per_second': 183.143, 'eval_steps_per_second': 5.742, 'epoch': 0.39, 'step': 77}, {'loss': 2.3164, 'learning_rate': 0.00043333333333333337, 'epoch': 0.4, 'step': 78}, {'eval_loss': 2.1142807006835938, 'eval_rouge1': 0.3901, 'eval_rouge2': 0.1665, 'eval_rougeL': 0.3505, 'eval_sacrebleu': 8.4675, 'eval_runtime': 11.9941, 'eval_samples_per_second': 180.839, 'eval_steps_per_second': 5.669, 'epoch': 0.4, 'step': 78}, {'loss': 2.2713, 'learning_rate': 0.0004324786324786325, 'epoch': 0.4, 'step': 79}, {'eval_loss': 2.111851930618286, 'eval_rouge1': 0.3902, 'eval_rouge2': 0.166, 'eval_rougeL': 0.3501, 'eval_sacrebleu': 8.512, 'eval_runtime': 11.6789, 'eval_samples_per_second': 185.719, 'eval_steps_per_second': 5.822, 'epoch': 0.4, 'step': 79}, {'loss': 2.2739, 'learning_rate': 0.00043162393162393166, 'epoch': 0.41, 'step': 80}, {'eval_loss': 2.110401153564453, 'eval_rouge1': 0.3908, 'eval_rouge2': 0.167, 'eval_rougeL': 0.3511, 'eval_sacrebleu': 8.5887, 'eval_runtime': 12.0879, 'eval_samples_per_second': 179.436, 'eval_steps_per_second': 5.625, 'epoch': 0.41, 'step': 80}, {'loss': 2.3035, 'learning_rate': 0.00043076923076923083, 'epoch': 0.41, 'step': 81}, {'eval_loss': 2.109278678894043, 'eval_rouge1': 0.3903, 'eval_rouge2': 0.1667, 'eval_rougeL': 0.3502, 'eval_sacrebleu': 8.5629, 'eval_runtime': 11.7247, 'eval_samples_per_second': 184.994, 'eval_steps_per_second': 5.8, 'epoch': 0.41, 'step': 81}, {'loss': 2.3165, 'learning_rate': 0.00042991452991452994, 'epoch': 0.42, 'step': 82}, {'eval_loss': 2.108433485031128, 'eval_rouge1': 0.3901, 'eval_rouge2': 0.1664, 'eval_rougeL': 0.3501, 'eval_sacrebleu': 8.5707, 'eval_runtime': 11.8185, 'eval_samples_per_second': 183.526, 'eval_steps_per_second': 5.754, 'epoch': 0.42, 'step': 82}, {'loss': 2.3321, 'learning_rate': 0.00042905982905982906, 'epoch': 0.42, 'step': 83}, {'eval_loss': 2.1073787212371826, 'eval_rouge1': 0.3908, 'eval_rouge2': 0.1672, 'eval_rougeL': 0.3506, 'eval_sacrebleu': 8.6193, 'eval_runtime': 12.1707, 'eval_samples_per_second': 178.214, 'eval_steps_per_second': 5.587, 'epoch': 0.42, 'step': 83}, {'loss': 2.2712, 'learning_rate': 0.0004282051282051282, 'epoch': 0.43, 'step': 84}, {'eval_loss': 2.1059465408325195, 'eval_rouge1': 0.3922, 'eval_rouge2': 0.1682, 'eval_rougeL': 0.3525, 'eval_sacrebleu': 8.6845, 'eval_runtime': 11.8472, 'eval_samples_per_second': 183.082, 'eval_steps_per_second': 5.74, 'epoch': 0.43, 'step': 84}, {'loss': 2.2435, 'learning_rate': 0.00042735042735042735, 'epoch': 0.44, 'step': 85}, {'eval_loss': 2.105433702468872, 'eval_rouge1': 0.3918, 'eval_rouge2': 0.1679, 'eval_rougeL': 0.3525, 'eval_sacrebleu': 8.7014, 'eval_runtime': 12.1573, 'eval_samples_per_second': 178.411, 'eval_steps_per_second': 5.593, 'epoch': 0.44, 'step': 85}, {'loss': 2.289, 'learning_rate': 0.00042649572649572647, 'epoch': 0.44, 'step': 86}, {'eval_loss': 2.1051621437072754, 'eval_rouge1': 0.3929, 'eval_rouge2': 0.1688, 'eval_rougeL': 0.3539, 'eval_sacrebleu': 8.6825, 'eval_runtime': 11.868, 'eval_samples_per_second': 182.761, 'eval_steps_per_second': 5.73, 'epoch': 0.44, 'step': 86}, {'loss': 2.1891, 'learning_rate': 0.00042564102564102564, 'epoch': 0.45, 'step': 87}, {'eval_loss': 2.1051504611968994, 'eval_rouge1': 0.393, 'eval_rouge2': 0.1691, 'eval_rougeL': 0.354, 'eval_sacrebleu': 8.6514, 'eval_runtime': 11.8651, 'eval_samples_per_second': 182.805, 'eval_steps_per_second': 5.731, 'epoch': 0.45, 'step': 87}, {'loss': 2.3004, 'learning_rate': 0.0004247863247863248, 'epoch': 0.45, 'step': 88}, {'eval_loss': 2.1044821739196777, 'eval_rouge1': 0.3932, 'eval_rouge2': 0.1692, 'eval_rougeL': 0.354, 'eval_sacrebleu': 8.6847, 'eval_runtime': 11.8268, 'eval_samples_per_second': 183.397, 'eval_steps_per_second': 5.75, 'epoch': 0.45, 'step': 88}, {'loss': 2.2498, 'learning_rate': 0.0004239316239316239, 'epoch': 0.46, 'step': 89}, {'eval_loss': 2.103327512741089, 'eval_rouge1': 0.3938, 'eval_rouge2': 0.1691, 'eval_rougeL': 0.3544, 'eval_sacrebleu': 8.6805, 'eval_runtime': 11.8394, 'eval_samples_per_second': 183.202, 'eval_steps_per_second': 5.744, 'epoch': 0.46, 'step': 89}, {'loss': 2.2775, 'learning_rate': 0.0004230769230769231, 'epoch': 0.46, 'step': 90}, {'eval_loss': 2.1017541885375977, 'eval_rouge1': 0.3945, 'eval_rouge2': 0.1701, 'eval_rougeL': 0.3552, 'eval_sacrebleu': 8.7524, 'eval_runtime': 12.2542, 'eval_samples_per_second': 177.001, 'eval_steps_per_second': 5.549, 'epoch': 0.46, 'step': 90}, {'loss': 2.1744, 'learning_rate': 0.0004222222222222222, 'epoch': 0.47, 'step': 91}, {'eval_loss': 2.1001665592193604, 'eval_rouge1': 0.3937, 'eval_rouge2': 0.1695, 'eval_rougeL': 0.3538, 'eval_sacrebleu': 8.7863, 'eval_runtime': 11.8435, 'eval_samples_per_second': 183.139, 'eval_steps_per_second': 5.742, 'epoch': 0.47, 'step': 91}, {'loss': 2.3061, 'learning_rate': 0.0004213675213675214, 'epoch': 0.47, 'step': 92}, {'eval_loss': 2.099097967147827, 'eval_rouge1': 0.3938, 'eval_rouge2': 0.1693, 'eval_rougeL': 0.3539, 'eval_sacrebleu': 8.783, 'eval_runtime': 12.2016, 'eval_samples_per_second': 177.764, 'eval_steps_per_second': 5.573, 'epoch': 0.47, 'step': 92}, {'loss': 2.3068, 'learning_rate': 0.0004205128205128205, 'epoch': 0.48, 'step': 93}, {'eval_loss': 2.097611904144287, 'eval_rouge1': 0.3931, 'eval_rouge2': 0.1685, 'eval_rougeL': 0.3531, 'eval_sacrebleu': 8.775, 'eval_runtime': 11.9036, 'eval_samples_per_second': 182.214, 'eval_steps_per_second': 5.713, 'epoch': 0.48, 'step': 93}, {'loss': 2.2283, 'learning_rate': 0.0004196581196581197, 'epoch': 0.48, 'step': 94}, {'eval_loss': 2.095958948135376, 'eval_rouge1': 0.3926, 'eval_rouge2': 0.1691, 'eval_rougeL': 0.3534, 'eval_sacrebleu': 8.7892, 'eval_runtime': 12.1657, 'eval_samples_per_second': 178.288, 'eval_steps_per_second': 5.589, 'epoch': 0.48, 'step': 94}, {'loss': 2.302, 'learning_rate': 0.00041880341880341885, 'epoch': 0.49, 'step': 95}, {'eval_loss': 2.0939877033233643, 'eval_rouge1': 0.3927, 'eval_rouge2': 0.169, 'eval_rougeL': 0.3529, 'eval_sacrebleu': 8.813, 'eval_runtime': 12.0089, 'eval_samples_per_second': 180.616, 'eval_steps_per_second': 5.662, 'epoch': 0.49, 'step': 95}, {'loss': 2.3102, 'learning_rate': 0.00041794871794871796, 'epoch': 0.49, 'step': 96}, {'eval_loss': 2.0923032760620117, 'eval_rouge1': 0.3926, 'eval_rouge2': 0.1692, 'eval_rougeL': 0.3528, 'eval_sacrebleu': 8.7882, 'eval_runtime': 11.9821, 'eval_samples_per_second': 181.019, 'eval_steps_per_second': 5.675, 'epoch': 0.49, 'step': 96}, {'loss': 2.2912, 'learning_rate': 0.00041709401709401713, 'epoch': 0.5, 'step': 97}, {'eval_loss': 2.0911598205566406, 'eval_rouge1': 0.3925, 'eval_rouge2': 0.169, 'eval_rougeL': 0.3527, 'eval_sacrebleu': 8.7657, 'eval_runtime': 11.8101, 'eval_samples_per_second': 183.656, 'eval_steps_per_second': 5.758, 'epoch': 0.5, 'step': 97}, {'loss': 2.4256, 'learning_rate': 0.00041623931623931625, 'epoch': 0.5, 'step': 98}, {'eval_loss': 2.089735507965088, 'eval_rouge1': 0.3924, 'eval_rouge2': 0.1687, 'eval_rougeL': 0.3524, 'eval_sacrebleu': 8.7359, 'eval_runtime': 11.8123, 'eval_samples_per_second': 183.622, 'eval_steps_per_second': 5.757, 'epoch': 0.5, 'step': 98}, {'loss': 2.2853, 'learning_rate': 0.0004153846153846154, 'epoch': 0.51, 'step': 99}, {'eval_loss': 2.0885400772094727, 'eval_rouge1': 0.3923, 'eval_rouge2': 0.1682, 'eval_rougeL': 0.3522, 'eval_sacrebleu': 8.6814, 'eval_runtime': 12.1332, 'eval_samples_per_second': 178.765, 'eval_steps_per_second': 5.604, 'epoch': 0.51, 'step': 99}, {'loss': 2.1557, 'learning_rate': 0.00041452991452991454, 'epoch': 0.51, 'step': 100}, {'eval_loss': 2.0872855186462402, 'eval_rouge1': 0.3933, 'eval_rouge2': 0.1695, 'eval_rougeL': 0.3541, 'eval_sacrebleu': 8.7332, 'eval_runtime': 11.8356, 'eval_samples_per_second': 183.26, 'eval_steps_per_second': 5.745, 'epoch': 0.51, 'step': 100}, {'loss': 2.2086, 'learning_rate': 0.00041367521367521366, 'epoch': 0.52, 'step': 101}, {'eval_loss': 2.085841417312622, 'eval_rouge1': 0.3934, 'eval_rouge2': 0.1694, 'eval_rougeL': 0.354, 'eval_sacrebleu': 8.6992, 'eval_runtime': 12.1128, 'eval_samples_per_second': 179.067, 'eval_steps_per_second': 5.614, 'epoch': 0.52, 'step': 101}, {'loss': 2.3042, 'learning_rate': 0.00041282051282051283, 'epoch': 0.52, 'step': 102}, {'eval_loss': 2.084794759750366, 'eval_rouge1': 0.394, 'eval_rouge2': 0.1695, 'eval_rougeL': 0.3552, 'eval_sacrebleu': 8.7108, 'eval_runtime': 11.8373, 'eval_samples_per_second': 183.234, 'eval_steps_per_second': 5.745, 'epoch': 0.52, 'step': 102}, {'loss': 2.1887, 'learning_rate': 0.00041196581196581195, 'epoch': 0.53, 'step': 103}, {'eval_loss': 2.084099531173706, 'eval_rouge1': 0.394, 'eval_rouge2': 0.1691, 'eval_rougeL': 0.3548, 'eval_sacrebleu': 8.7436, 'eval_runtime': 12.1052, 'eval_samples_per_second': 179.179, 'eval_steps_per_second': 5.617, 'epoch': 0.53, 'step': 103}, {'loss': 2.2979, 'learning_rate': 0.0004111111111111111, 'epoch': 0.53, 'step': 104}, {'eval_loss': 2.0839028358459473, 'eval_rouge1': 0.3945, 'eval_rouge2': 0.1698, 'eval_rougeL': 0.3557, 'eval_sacrebleu': 8.7335, 'eval_runtime': 11.837, 'eval_samples_per_second': 183.239, 'eval_steps_per_second': 5.745, 'epoch': 0.53, 'step': 104}, {'loss': 2.2913, 'learning_rate': 0.00041025641025641023, 'epoch': 0.54, 'step': 105}, {'eval_loss': 2.0835728645324707, 'eval_rouge1': 0.3947, 'eval_rouge2': 0.1709, 'eval_rougeL': 0.3561, 'eval_sacrebleu': 8.7397, 'eval_runtime': 11.8345, 'eval_samples_per_second': 183.278, 'eval_steps_per_second': 5.746, 'epoch': 0.54, 'step': 105}, {'loss': 2.2915, 'learning_rate': 0.0004094017094017094, 'epoch': 0.54, 'step': 106}, {'eval_loss': 2.083378553390503, 'eval_rouge1': 0.3957, 'eval_rouge2': 0.1715, 'eval_rougeL': 0.3571, 'eval_sacrebleu': 8.789, 'eval_runtime': 12.145, 'eval_samples_per_second': 178.592, 'eval_steps_per_second': 5.599, 'epoch': 0.54, 'step': 106}, {'loss': 2.2436, 'learning_rate': 0.0004085470085470085, 'epoch': 0.55, 'step': 107}, {'eval_loss': 2.0834739208221436, 'eval_rouge1': 0.395, 'eval_rouge2': 0.1709, 'eval_rougeL': 0.3563, 'eval_sacrebleu': 8.7467, 'eval_runtime': 11.8708, 'eval_samples_per_second': 182.717, 'eval_steps_per_second': 5.728, 'epoch': 0.55, 'step': 107}, {'loss': 2.2291, 'learning_rate': 0.0004076923076923077, 'epoch': 0.55, 'step': 108}, {'eval_loss': 2.08378005027771, 'eval_rouge1': 0.3947, 'eval_rouge2': 0.1706, 'eval_rougeL': 0.356, 'eval_sacrebleu': 8.7617, 'eval_runtime': 12.1526, 'eval_samples_per_second': 178.48, 'eval_steps_per_second': 5.595, 'epoch': 0.55, 'step': 108}, {'loss': 2.2301, 'learning_rate': 0.00040683760683760687, 'epoch': 0.56, 'step': 109}, {'eval_loss': 2.083658218383789, 'eval_rouge1': 0.3954, 'eval_rouge2': 0.1712, 'eval_rougeL': 0.3566, 'eval_sacrebleu': 8.7413, 'eval_runtime': 11.8828, 'eval_samples_per_second': 182.533, 'eval_steps_per_second': 5.723, 'epoch': 0.56, 'step': 109}, {'loss': 2.1979, 'learning_rate': 0.000405982905982906, 'epoch': 0.56, 'step': 110}, {'eval_loss': 2.084104537963867, 'eval_rouge1': 0.3952, 'eval_rouge2': 0.171, 'eval_rougeL': 0.3563, 'eval_sacrebleu': 8.7483, 'eval_runtime': 12.1707, 'eval_samples_per_second': 178.215, 'eval_steps_per_second': 5.587, 'epoch': 0.56, 'step': 110}, {'loss': 2.1522, 'learning_rate': 0.00040512820512820515, 'epoch': 0.57, 'step': 111}, {'eval_loss': 2.084482431411743, 'eval_rouge1': 0.3944, 'eval_rouge2': 0.1708, 'eval_rougeL': 0.3557, 'eval_sacrebleu': 8.7929, 'eval_runtime': 11.7718, 'eval_samples_per_second': 184.254, 'eval_steps_per_second': 5.777, 'epoch': 0.57, 'step': 111}, {'loss': 2.2486, 'learning_rate': 0.00040427350427350427, 'epoch': 0.57, 'step': 112}, {'eval_loss': 2.0844779014587402, 'eval_rouge1': 0.3934, 'eval_rouge2': 0.1703, 'eval_rougeL': 0.3547, 'eval_sacrebleu': 8.7528, 'eval_runtime': 11.7499, 'eval_samples_per_second': 184.598, 'eval_steps_per_second': 5.787, 'epoch': 0.57, 'step': 112}, {'loss': 2.3361, 'learning_rate': 0.00040341880341880344, 'epoch': 0.58, 'step': 113}, {'eval_loss': 2.0836832523345947, 'eval_rouge1': 0.3921, 'eval_rouge2': 0.1698, 'eval_rougeL': 0.3534, 'eval_sacrebleu': 8.7639, 'eval_runtime': 12.2098, 'eval_samples_per_second': 177.644, 'eval_steps_per_second': 5.569, 'epoch': 0.58, 'step': 113}, {'loss': 2.2127, 'learning_rate': 0.00040256410256410256, 'epoch': 0.58, 'step': 114}, {'eval_loss': 2.082097053527832, 'eval_rouge1': 0.3926, 'eval_rouge2': 0.1703, 'eval_rougeL': 0.3537, 'eval_sacrebleu': 8.7794, 'eval_runtime': 11.9038, 'eval_samples_per_second': 182.21, 'eval_steps_per_second': 5.712, 'epoch': 0.58, 'step': 114}, {'loss': 2.2232, 'learning_rate': 0.00040170940170940173, 'epoch': 0.59, 'step': 115}, {'eval_loss': 2.08020281791687, 'eval_rouge1': 0.3927, 'eval_rouge2': 0.1701, 'eval_rougeL': 0.354, 'eval_sacrebleu': 8.7933, 'eval_runtime': 12.1598, 'eval_samples_per_second': 178.375, 'eval_steps_per_second': 5.592, 'epoch': 0.59, 'step': 115}, {'loss': 2.1737, 'learning_rate': 0.0004008547008547009, 'epoch': 0.59, 'step': 116}, {'eval_loss': 2.0787203311920166, 'eval_rouge1': 0.3931, 'eval_rouge2': 0.1707, 'eval_rougeL': 0.355, 'eval_sacrebleu': 8.8081, 'eval_runtime': 11.9245, 'eval_samples_per_second': 181.895, 'eval_steps_per_second': 5.703, 'epoch': 0.59, 'step': 116}, {'loss': 2.2833, 'learning_rate': 0.0004, 'epoch': 0.6, 'step': 117}, {'eval_loss': 2.0776212215423584, 'eval_rouge1': 0.3945, 'eval_rouge2': 0.1713, 'eval_rougeL': 0.3556, 'eval_sacrebleu': 8.8677, 'eval_runtime': 12.2438, 'eval_samples_per_second': 177.151, 'eval_steps_per_second': 5.554, 'epoch': 0.6, 'step': 117}, {'loss': 2.2856, 'learning_rate': 0.0003991452991452992, 'epoch': 0.6, 'step': 118}, {'eval_loss': 2.076449155807495, 'eval_rouge1': 0.3954, 'eval_rouge2': 0.1725, 'eval_rougeL': 0.3572, 'eval_sacrebleu': 8.8557, 'eval_runtime': 11.9268, 'eval_samples_per_second': 181.859, 'eval_steps_per_second': 5.701, 'epoch': 0.6, 'step': 118}, {'loss': 2.228, 'learning_rate': 0.00039829059829059825, 'epoch': 0.61, 'step': 119}, {'eval_loss': 2.0755860805511475, 'eval_rouge1': 0.3953, 'eval_rouge2': 0.1724, 'eval_rougeL': 0.3575, 'eval_sacrebleu': 8.8223, 'eval_runtime': 11.9604, 'eval_samples_per_second': 181.348, 'eval_steps_per_second': 5.685, 'epoch': 0.61, 'step': 119}, {'loss': 2.1917, 'learning_rate': 0.0003974358974358974, 'epoch': 0.61, 'step': 120}, {'eval_loss': 2.0746564865112305, 'eval_rouge1': 0.3961, 'eval_rouge2': 0.1732, 'eval_rougeL': 0.3584, 'eval_sacrebleu': 8.8591, 'eval_runtime': 11.8131, 'eval_samples_per_second': 183.61, 'eval_steps_per_second': 5.756, 'epoch': 0.61, 'step': 120}, {'loss': 2.2893, 'learning_rate': 0.00039658119658119654, 'epoch': 0.62, 'step': 121}, {'eval_loss': 2.0736167430877686, 'eval_rouge1': 0.3967, 'eval_rouge2': 0.1733, 'eval_rougeL': 0.3593, 'eval_sacrebleu': 8.8304, 'eval_runtime': 11.8707, 'eval_samples_per_second': 182.719, 'eval_steps_per_second': 5.728, 'epoch': 0.62, 'step': 121}, {'loss': 2.3041, 'learning_rate': 0.0003957264957264957, 'epoch': 0.62, 'step': 122}, {'eval_loss': 2.072678327560425, 'eval_rouge1': 0.3965, 'eval_rouge2': 0.173, 'eval_rougeL': 0.3592, 'eval_sacrebleu': 8.7975, 'eval_runtime': 12.1198, 'eval_samples_per_second': 178.964, 'eval_steps_per_second': 5.611, 'epoch': 0.62, 'step': 122}, {'loss': 2.2356, 'learning_rate': 0.0003948717948717949, 'epoch': 0.63, 'step': 123}, {'eval_loss': 2.071470022201538, 'eval_rouge1': 0.3966, 'eval_rouge2': 0.1728, 'eval_rougeL': 0.3591, 'eval_sacrebleu': 8.7666, 'eval_runtime': 11.9714, 'eval_samples_per_second': 181.181, 'eval_steps_per_second': 5.68, 'epoch': 0.63, 'step': 123}, {'loss': 2.2404, 'learning_rate': 0.000394017094017094, 'epoch': 0.63, 'step': 124}, {'eval_loss': 2.0700979232788086, 'eval_rouge1': 0.3972, 'eval_rouge2': 0.1731, 'eval_rougeL': 0.3598, 'eval_sacrebleu': 8.8188, 'eval_runtime': 12.0667, 'eval_samples_per_second': 179.75, 'eval_steps_per_second': 5.635, 'epoch': 0.63, 'step': 124}, {'loss': 2.1614, 'learning_rate': 0.00039316239316239317, 'epoch': 0.64, 'step': 125}, {'eval_loss': 2.0690712928771973, 'eval_rouge1': 0.3977, 'eval_rouge2': 0.1734, 'eval_rougeL': 0.3599, 'eval_sacrebleu': 8.811, 'eval_runtime': 11.8731, 'eval_samples_per_second': 182.681, 'eval_steps_per_second': 5.727, 'epoch': 0.64, 'step': 125}, {'loss': 2.2446, 'learning_rate': 0.0003923076923076923, 'epoch': 0.64, 'step': 126}, {'eval_loss': 2.0687265396118164, 'eval_rouge1': 0.398, 'eval_rouge2': 0.1742, 'eval_rougeL': 0.3606, 'eval_sacrebleu': 8.8693, 'eval_runtime': 11.9195, 'eval_samples_per_second': 181.971, 'eval_steps_per_second': 5.705, 'epoch': 0.64, 'step': 126}, {'loss': 2.2798, 'learning_rate': 0.00039145299145299146, 'epoch': 0.65, 'step': 127}, {'eval_loss': 2.0691914558410645, 'eval_rouge1': 0.3975, 'eval_rouge2': 0.1736, 'eval_rougeL': 0.3599, 'eval_sacrebleu': 8.8603, 'eval_runtime': 11.9007, 'eval_samples_per_second': 182.258, 'eval_steps_per_second': 5.714, 'epoch': 0.65, 'step': 127}, {'loss': 2.1497, 'learning_rate': 0.00039059829059829063, 'epoch': 0.66, 'step': 128}, {'eval_loss': 2.0695862770080566, 'eval_rouge1': 0.3981, 'eval_rouge2': 0.1741, 'eval_rougeL': 0.3603, 'eval_sacrebleu': 8.9092, 'eval_runtime': 11.9852, 'eval_samples_per_second': 180.973, 'eval_steps_per_second': 5.674, 'epoch': 0.66, 'step': 128}, {'loss': 2.2365, 'learning_rate': 0.00038974358974358975, 'epoch': 0.66, 'step': 129}, {'eval_loss': 2.0705065727233887, 'eval_rouge1': 0.3982, 'eval_rouge2': 0.175, 'eval_rougeL': 0.3605, 'eval_sacrebleu': 8.9772, 'eval_runtime': 12.3442, 'eval_samples_per_second': 175.71, 'eval_steps_per_second': 5.509, 'epoch': 0.66, 'step': 129}, {'loss': 2.1742, 'learning_rate': 0.0003888888888888889, 'epoch': 0.67, 'step': 130}, {'eval_loss': 2.0713980197906494, 'eval_rouge1': 0.3982, 'eval_rouge2': 0.1749, 'eval_rougeL': 0.3602, 'eval_sacrebleu': 8.9383, 'eval_runtime': 11.7082, 'eval_samples_per_second': 185.255, 'eval_steps_per_second': 5.808, 'epoch': 0.67, 'step': 130}, {'loss': 2.2758, 'learning_rate': 0.00038803418803418804, 'epoch': 0.67, 'step': 131}, {'eval_loss': 2.0723564624786377, 'eval_rouge1': 0.3971, 'eval_rouge2': 0.1742, 'eval_rougeL': 0.3594, 'eval_sacrebleu': 8.9149, 'eval_runtime': 12.1922, 'eval_samples_per_second': 177.9, 'eval_steps_per_second': 5.577, 'epoch': 0.67, 'step': 131}, {'loss': 2.1506, 'learning_rate': 0.0003871794871794872, 'epoch': 0.68, 'step': 132}, {'eval_loss': 2.073158025741577, 'eval_rouge1': 0.3975, 'eval_rouge2': 0.1742, 'eval_rougeL': 0.359, 'eval_sacrebleu': 8.9373, 'eval_runtime': 11.8631, 'eval_samples_per_second': 182.836, 'eval_steps_per_second': 5.732, 'epoch': 0.68, 'step': 132}, {'loss': 2.1693, 'learning_rate': 0.0003863247863247863, 'epoch': 0.68, 'step': 133}, {'eval_loss': 2.073934316635132, 'eval_rouge1': 0.3963, 'eval_rouge2': 0.1734, 'eval_rougeL': 0.3584, 'eval_sacrebleu': 8.8877, 'eval_runtime': 12.0717, 'eval_samples_per_second': 179.677, 'eval_steps_per_second': 5.633, 'epoch': 0.68, 'step': 133}, {'loss': 2.1847, 'learning_rate': 0.0003854700854700855, 'epoch': 0.69, 'step': 134}, {'eval_loss': 2.074390172958374, 'eval_rouge1': 0.3966, 'eval_rouge2': 0.1735, 'eval_rougeL': 0.3587, 'eval_sacrebleu': 8.8823, 'eval_runtime': 12.0611, 'eval_samples_per_second': 179.834, 'eval_steps_per_second': 5.638, 'epoch': 0.69, 'step': 134}, {'loss': 2.2407, 'learning_rate': 0.00038461538461538467, 'epoch': 0.69, 'step': 135}, {'eval_loss': 2.0748324394226074, 'eval_rouge1': 0.3971, 'eval_rouge2': 0.1737, 'eval_rougeL': 0.359, 'eval_sacrebleu': 8.9059, 'eval_runtime': 11.9265, 'eval_samples_per_second': 181.864, 'eval_steps_per_second': 5.702, 'epoch': 0.69, 'step': 135}, {'loss': 2.2178, 'learning_rate': 0.0003837606837606838, 'epoch': 0.7, 'step': 136}, {'eval_loss': 2.074592113494873, 'eval_rouge1': 0.3976, 'eval_rouge2': 0.1737, 'eval_rougeL': 0.3585, 'eval_sacrebleu': 8.8811, 'eval_runtime': 12.1915, 'eval_samples_per_second': 177.91, 'eval_steps_per_second': 5.578, 'epoch': 0.7, 'step': 136}, {'loss': 2.2052, 'learning_rate': 0.00038290598290598296, 'epoch': 0.7, 'step': 137}, {'eval_loss': 2.0739588737487793, 'eval_rouge1': 0.3974, 'eval_rouge2': 0.1736, 'eval_rougeL': 0.3583, 'eval_sacrebleu': 8.84, 'eval_runtime': 11.9133, 'eval_samples_per_second': 182.065, 'eval_steps_per_second': 5.708, 'epoch': 0.7, 'step': 137}, {'loss': 2.2461, 'learning_rate': 0.000382051282051282, 'epoch': 0.71, 'step': 138}, {'eval_loss': 2.0731399059295654, 'eval_rouge1': 0.398, 'eval_rouge2': 0.1734, 'eval_rougeL': 0.3585, 'eval_sacrebleu': 8.8561, 'eval_runtime': 12.2566, 'eval_samples_per_second': 176.966, 'eval_steps_per_second': 5.548, 'epoch': 0.71, 'step': 138}, {'loss': 2.1249, 'learning_rate': 0.0003811965811965812, 'epoch': 0.71, 'step': 139}, {'eval_loss': 2.071716547012329, 'eval_rouge1': 0.3985, 'eval_rouge2': 0.1737, 'eval_rougeL': 0.359, 'eval_sacrebleu': 8.9089, 'eval_runtime': 12.0086, 'eval_samples_per_second': 180.62, 'eval_steps_per_second': 5.663, 'epoch': 0.71, 'step': 139}, {'loss': 2.1584, 'learning_rate': 0.0003803418803418803, 'epoch': 0.72, 'step': 140}, {'eval_loss': 2.0696401596069336, 'eval_rouge1': 0.399, 'eval_rouge2': 0.1741, 'eval_rougeL': 0.3595, 'eval_sacrebleu': 8.9857, 'eval_runtime': 11.9443, 'eval_samples_per_second': 181.593, 'eval_steps_per_second': 5.693, 'epoch': 0.72, 'step': 140}, {'loss': 2.2104, 'learning_rate': 0.0003794871794871795, 'epoch': 0.72, 'step': 141}, {'eval_loss': 2.0669217109680176, 'eval_rouge1': 0.3985, 'eval_rouge2': 0.1735, 'eval_rougeL': 0.3594, 'eval_sacrebleu': 8.8996, 'eval_runtime': 11.9098, 'eval_samples_per_second': 182.12, 'eval_steps_per_second': 5.71, 'epoch': 0.72, 'step': 141}, {'loss': 2.1973, 'learning_rate': 0.00037863247863247865, 'epoch': 0.73, 'step': 142}, {'eval_loss': 2.0649256706237793, 'eval_rouge1': 0.399, 'eval_rouge2': 0.1731, 'eval_rougeL': 0.3598, 'eval_sacrebleu': 8.9069, 'eval_runtime': 11.9016, 'eval_samples_per_second': 182.245, 'eval_steps_per_second': 5.714, 'epoch': 0.73, 'step': 142}, {'loss': 2.1885, 'learning_rate': 0.00037777777777777777, 'epoch': 0.73, 'step': 143}, {'eval_loss': 2.0634517669677734, 'eval_rouge1': 0.3991, 'eval_rouge2': 0.1736, 'eval_rougeL': 0.3604, 'eval_sacrebleu': 8.9317, 'eval_runtime': 12.191, 'eval_samples_per_second': 177.918, 'eval_steps_per_second': 5.578, 'epoch': 0.73, 'step': 143}, {'loss': 2.3289, 'learning_rate': 0.00037692307692307694, 'epoch': 0.74, 'step': 144}, {'eval_loss': 2.0616941452026367, 'eval_rouge1': 0.4, 'eval_rouge2': 0.1743, 'eval_rougeL': 0.3616, 'eval_sacrebleu': 8.9614, 'eval_runtime': 12.0047, 'eval_samples_per_second': 180.68, 'eval_steps_per_second': 5.664, 'epoch': 0.74, 'step': 144}, {'loss': 2.1704, 'learning_rate': 0.00037606837606837606, 'epoch': 0.74, 'step': 145}, {'eval_loss': 2.060084342956543, 'eval_rouge1': 0.4005, 'eval_rouge2': 0.1751, 'eval_rougeL': 0.3623, 'eval_sacrebleu': 8.9978, 'eval_runtime': 11.9206, 'eval_samples_per_second': 181.954, 'eval_steps_per_second': 5.704, 'epoch': 0.74, 'step': 145}, {'loss': 2.2342, 'learning_rate': 0.00037521367521367523, 'epoch': 0.75, 'step': 146}, {'eval_loss': 2.059126138687134, 'eval_rouge1': 0.4013, 'eval_rouge2': 0.1753, 'eval_rougeL': 0.3628, 'eval_sacrebleu': 9.012, 'eval_runtime': 11.6831, 'eval_samples_per_second': 185.653, 'eval_steps_per_second': 5.82, 'epoch': 0.75, 'step': 146}, {'loss': 2.2324, 'learning_rate': 0.00037435897435897435, 'epoch': 0.75, 'step': 147}, {'eval_loss': 2.058687925338745, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1754, 'eval_rougeL': 0.3631, 'eval_sacrebleu': 9.0654, 'eval_runtime': 11.6429, 'eval_samples_per_second': 186.293, 'eval_steps_per_second': 5.84, 'epoch': 0.75, 'step': 147}, {'loss': 2.1343, 'learning_rate': 0.0003735042735042735, 'epoch': 0.76, 'step': 148}, {'eval_loss': 2.0587387084960938, 'eval_rouge1': 0.4022, 'eval_rouge2': 0.1762, 'eval_rougeL': 0.3641, 'eval_sacrebleu': 9.1018, 'eval_runtime': 11.6679, 'eval_samples_per_second': 185.894, 'eval_steps_per_second': 5.828, 'epoch': 0.76, 'step': 148}, {'loss': 2.1428, 'learning_rate': 0.0003726495726495727, 'epoch': 0.76, 'step': 149}, {'eval_loss': 2.0582284927368164, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1757, 'eval_rougeL': 0.3637, 'eval_sacrebleu': 9.1126, 'eval_runtime': 11.6964, 'eval_samples_per_second': 185.442, 'eval_steps_per_second': 5.814, 'epoch': 0.76, 'step': 149}, {'loss': 2.2286, 'learning_rate': 0.0003717948717948718, 'epoch': 0.77, 'step': 150}, {'eval_loss': 2.057246446609497, 'eval_rouge1': 0.4018, 'eval_rouge2': 0.1764, 'eval_rougeL': 0.3643, 'eval_sacrebleu': 9.1466, 'eval_runtime': 11.977, 'eval_samples_per_second': 181.097, 'eval_steps_per_second': 5.678, 'epoch': 0.77, 'step': 150}, {'loss': 2.2326, 'learning_rate': 0.000370940170940171, 'epoch': 0.77, 'step': 151}, {'eval_loss': 2.055997610092163, 'eval_rouge1': 0.4017, 'eval_rouge2': 0.1763, 'eval_rougeL': 0.3638, 'eval_sacrebleu': 9.1408, 'eval_runtime': 11.614, 'eval_samples_per_second': 186.757, 'eval_steps_per_second': 5.855, 'epoch': 0.77, 'step': 151}, {'loss': 2.1499, 'learning_rate': 0.0003700854700854701, 'epoch': 0.78, 'step': 152}, {'eval_loss': 2.0548713207244873, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1757, 'eval_rougeL': 0.3631, 'eval_sacrebleu': 9.0997, 'eval_runtime': 11.9476, 'eval_samples_per_second': 181.542, 'eval_steps_per_second': 5.692, 'epoch': 0.78, 'step': 152}, {'loss': 2.1546, 'learning_rate': 0.00036923076923076927, 'epoch': 0.78, 'step': 153}, {'eval_loss': 2.054380416870117, 'eval_rouge1': 0.4018, 'eval_rouge2': 0.1764, 'eval_rougeL': 0.3637, 'eval_sacrebleu': 9.1452, 'eval_runtime': 11.6621, 'eval_samples_per_second': 185.987, 'eval_steps_per_second': 5.831, 'epoch': 0.78, 'step': 153}, {'loss': 2.2533, 'learning_rate': 0.0003683760683760684, 'epoch': 0.79, 'step': 154}, {'eval_loss': 2.054189443588257, 'eval_rouge1': 0.4016, 'eval_rouge2': 0.1769, 'eval_rougeL': 0.3635, 'eval_sacrebleu': 9.1517, 'eval_runtime': 11.9466, 'eval_samples_per_second': 181.558, 'eval_steps_per_second': 5.692, 'epoch': 0.79, 'step': 154}, {'loss': 2.1861, 'learning_rate': 0.00036752136752136755, 'epoch': 0.79, 'step': 155}, {'eval_loss': 2.0538082122802734, 'eval_rouge1': 0.4002, 'eval_rouge2': 0.1757, 'eval_rougeL': 0.3618, 'eval_sacrebleu': 9.0982, 'eval_runtime': 11.6904, 'eval_samples_per_second': 185.536, 'eval_steps_per_second': 5.817, 'epoch': 0.79, 'step': 155}, {'loss': 2.1446, 'learning_rate': 0.00036666666666666667, 'epoch': 0.8, 'step': 156}, {'eval_loss': 2.053478956222534, 'eval_rouge1': 0.4009, 'eval_rouge2': 0.1764, 'eval_rougeL': 0.3624, 'eval_sacrebleu': 9.1689, 'eval_runtime': 11.6976, 'eval_samples_per_second': 185.423, 'eval_steps_per_second': 5.813, 'epoch': 0.8, 'step': 156}, {'loss': 2.1885, 'learning_rate': 0.0003658119658119658, 'epoch': 0.8, 'step': 157}, {'eval_loss': 2.052896499633789, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1763, 'eval_rougeL': 0.3627, 'eval_sacrebleu': 9.1785, 'eval_runtime': 11.6622, 'eval_samples_per_second': 185.986, 'eval_steps_per_second': 5.831, 'epoch': 0.8, 'step': 157}, {'loss': 2.2471, 'learning_rate': 0.00036495726495726496, 'epoch': 0.81, 'step': 158}, {'eval_loss': 2.0520122051239014, 'eval_rouge1': 0.4008, 'eval_rouge2': 0.1759, 'eval_rougeL': 0.3619, 'eval_sacrebleu': 9.1875, 'eval_runtime': 11.6764, 'eval_samples_per_second': 185.759, 'eval_steps_per_second': 5.824, 'epoch': 0.81, 'step': 158}, {'loss': 2.0746, 'learning_rate': 0.0003641025641025641, 'epoch': 0.81, 'step': 159}, {'eval_loss': 2.0509982109069824, 'eval_rouge1': 0.4015, 'eval_rouge2': 0.1771, 'eval_rougeL': 0.3628, 'eval_sacrebleu': 9.2057, 'eval_runtime': 11.9919, 'eval_samples_per_second': 180.873, 'eval_steps_per_second': 5.671, 'epoch': 0.81, 'step': 159}, {'loss': 2.1967, 'learning_rate': 0.00036324786324786325, 'epoch': 0.82, 'step': 160}, {'eval_loss': 2.0496790409088135, 'eval_rouge1': 0.4016, 'eval_rouge2': 0.1777, 'eval_rougeL': 0.3634, 'eval_sacrebleu': 9.2317, 'eval_runtime': 11.6621, 'eval_samples_per_second': 185.988, 'eval_steps_per_second': 5.831, 'epoch': 0.82, 'step': 160}, {'loss': 2.1782, 'learning_rate': 0.00036239316239316236, 'epoch': 0.82, 'step': 161}, {'eval_loss': 2.048604726791382, 'eval_rouge1': 0.4015, 'eval_rouge2': 0.1781, 'eval_rougeL': 0.3637, 'eval_sacrebleu': 9.2191, 'eval_runtime': 11.9625, 'eval_samples_per_second': 181.317, 'eval_steps_per_second': 5.684, 'epoch': 0.82, 'step': 161}, {'loss': 2.1202, 'learning_rate': 0.00036153846153846154, 'epoch': 0.83, 'step': 162}, {'eval_loss': 2.0476560592651367, 'eval_rouge1': 0.4011, 'eval_rouge2': 0.1781, 'eval_rougeL': 0.3637, 'eval_sacrebleu': 9.1997, 'eval_runtime': 11.6858, 'eval_samples_per_second': 185.61, 'eval_steps_per_second': 5.819, 'epoch': 0.83, 'step': 162}, {'loss': 2.1708, 'learning_rate': 0.0003606837606837607, 'epoch': 0.83, 'step': 163}, {'eval_loss': 2.0469167232513428, 'eval_rouge1': 0.4007, 'eval_rouge2': 0.1781, 'eval_rougeL': 0.3637, 'eval_sacrebleu': 9.1747, 'eval_runtime': 11.9392, 'eval_samples_per_second': 181.671, 'eval_steps_per_second': 5.696, 'epoch': 0.83, 'step': 163}, {'loss': 2.1885, 'learning_rate': 0.0003598290598290598, 'epoch': 0.84, 'step': 164}, {'eval_loss': 2.0464494228363037, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1783, 'eval_rougeL': 0.3641, 'eval_sacrebleu': 9.1986, 'eval_runtime': 11.6896, 'eval_samples_per_second': 185.549, 'eval_steps_per_second': 5.817, 'epoch': 0.84, 'step': 164}, {'loss': 2.1309, 'learning_rate': 0.000358974358974359, 'epoch': 0.84, 'step': 165}, {'eval_loss': 2.0463902950286865, 'eval_rouge1': 0.401, 'eval_rouge2': 0.1776, 'eval_rougeL': 0.364, 'eval_sacrebleu': 9.1611, 'eval_runtime': 11.6677, 'eval_samples_per_second': 185.898, 'eval_steps_per_second': 5.828, 'epoch': 0.84, 'step': 165}, {'loss': 2.0772, 'learning_rate': 0.0003581196581196581, 'epoch': 0.85, 'step': 166}, {'eval_loss': 2.046433687210083, 'eval_rouge1': 0.4017, 'eval_rouge2': 0.1781, 'eval_rougeL': 0.3647, 'eval_sacrebleu': 9.1889, 'eval_runtime': 11.9588, 'eval_samples_per_second': 181.373, 'eval_steps_per_second': 5.686, 'epoch': 0.85, 'step': 166}, {'loss': 2.1232, 'learning_rate': 0.0003572649572649573, 'epoch': 0.85, 'step': 167}, {'eval_loss': 2.047128200531006, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1778, 'eval_rougeL': 0.365, 'eval_sacrebleu': 9.2106, 'eval_runtime': 11.7148, 'eval_samples_per_second': 185.15, 'eval_steps_per_second': 5.805, 'epoch': 0.85, 'step': 167}, {'loss': 2.1141, 'learning_rate': 0.0003564102564102564, 'epoch': 0.86, 'step': 168}, {'eval_loss': 2.0482819080352783, 'eval_rouge1': 0.4019, 'eval_rouge2': 0.1779, 'eval_rougeL': 0.3654, 'eval_sacrebleu': 9.1691, 'eval_runtime': 12.1807, 'eval_samples_per_second': 178.069, 'eval_steps_per_second': 5.583, 'epoch': 0.86, 'step': 168}, {'loss': 2.2068, 'learning_rate': 0.00035555555555555557, 'epoch': 0.87, 'step': 169}, {'eval_loss': 2.049316644668579, 'eval_rouge1': 0.4019, 'eval_rouge2': 0.1788, 'eval_rougeL': 0.3655, 'eval_sacrebleu': 9.2188, 'eval_runtime': 11.9241, 'eval_samples_per_second': 181.9, 'eval_steps_per_second': 5.703, 'epoch': 0.87, 'step': 169}, {'loss': 2.1556, 'learning_rate': 0.00035470085470085474, 'epoch': 0.87, 'step': 170}, {'eval_loss': 2.050004482269287, 'eval_rouge1': 0.4018, 'eval_rouge2': 0.1785, 'eval_rougeL': 0.365, 'eval_sacrebleu': 9.1655, 'eval_runtime': 12.2306, 'eval_samples_per_second': 177.342, 'eval_steps_per_second': 5.56, 'epoch': 0.87, 'step': 170}, {'loss': 2.2092, 'learning_rate': 0.00035384615384615386, 'epoch': 0.88, 'step': 171}, {'eval_loss': 2.050593614578247, 'eval_rouge1': 0.4017, 'eval_rouge2': 0.1779, 'eval_rougeL': 0.3645, 'eval_sacrebleu': 9.167, 'eval_runtime': 11.9595, 'eval_samples_per_second': 181.362, 'eval_steps_per_second': 5.686, 'epoch': 0.88, 'step': 171}, {'loss': 2.1605, 'learning_rate': 0.00035299145299145303, 'epoch': 0.88, 'step': 172}, {'eval_loss': 2.050748109817505, 'eval_rouge1': 0.4016, 'eval_rouge2': 0.1773, 'eval_rougeL': 0.3646, 'eval_sacrebleu': 9.1203, 'eval_runtime': 11.8944, 'eval_samples_per_second': 182.355, 'eval_steps_per_second': 5.717, 'epoch': 0.88, 'step': 172}, {'loss': 2.0853, 'learning_rate': 0.00035213675213675215, 'epoch': 0.89, 'step': 173}, {'eval_loss': 2.0506465435028076, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1777, 'eval_rougeL': 0.3645, 'eval_sacrebleu': 9.1438, 'eval_runtime': 12.1743, 'eval_samples_per_second': 178.163, 'eval_steps_per_second': 5.586, 'epoch': 0.89, 'step': 173}, {'loss': 2.1756, 'learning_rate': 0.00035128205128205127, 'epoch': 0.89, 'step': 174}, {'eval_loss': 2.050156354904175, 'eval_rouge1': 0.4006, 'eval_rouge2': 0.1777, 'eval_rougeL': 0.3638, 'eval_sacrebleu': 9.1204, 'eval_runtime': 11.8897, 'eval_samples_per_second': 182.427, 'eval_steps_per_second': 5.719, 'epoch': 0.89, 'step': 174}, {'loss': 2.206, 'learning_rate': 0.00035042735042735044, 'epoch': 0.9, 'step': 175}, {'eval_loss': 2.0491349697113037, 'eval_rouge1': 0.4002, 'eval_rouge2': 0.1771, 'eval_rougeL': 0.3633, 'eval_sacrebleu': 9.1063, 'eval_runtime': 12.258, 'eval_samples_per_second': 176.945, 'eval_steps_per_second': 5.547, 'epoch': 0.9, 'step': 175}, {'loss': 2.2128, 'learning_rate': 0.00034957264957264955, 'epoch': 0.9, 'step': 176}, {'eval_loss': 2.047877311706543, 'eval_rouge1': 0.401, 'eval_rouge2': 0.177, 'eval_rougeL': 0.3638, 'eval_sacrebleu': 9.0789, 'eval_runtime': 11.9431, 'eval_samples_per_second': 181.611, 'eval_steps_per_second': 5.694, 'epoch': 0.9, 'step': 176}, {'loss': 2.0939, 'learning_rate': 0.0003487179487179487, 'epoch': 0.91, 'step': 177}, {'eval_loss': 2.0467255115509033, 'eval_rouge1': 0.4013, 'eval_rouge2': 0.1777, 'eval_rougeL': 0.3638, 'eval_sacrebleu': 9.147, 'eval_runtime': 12.2131, 'eval_samples_per_second': 177.596, 'eval_steps_per_second': 5.568, 'epoch': 0.91, 'step': 177}, {'loss': 2.1506, 'learning_rate': 0.00034786324786324784, 'epoch': 0.91, 'step': 178}, {'eval_loss': 2.0454936027526855, 'eval_rouge1': 0.4017, 'eval_rouge2': 0.1777, 'eval_rougeL': 0.3642, 'eval_sacrebleu': 9.1739, 'eval_runtime': 11.8583, 'eval_samples_per_second': 182.91, 'eval_steps_per_second': 5.734, 'epoch': 0.91, 'step': 178}, {'loss': 2.1933, 'learning_rate': 0.000347008547008547, 'epoch': 0.92, 'step': 179}, {'eval_loss': 2.044316291809082, 'eval_rouge1': 0.4021, 'eval_rouge2': 0.178, 'eval_rougeL': 0.3646, 'eval_sacrebleu': 9.1822, 'eval_runtime': 11.9085, 'eval_samples_per_second': 182.138, 'eval_steps_per_second': 5.71, 'epoch': 0.92, 'step': 179}, {'loss': 2.1864, 'learning_rate': 0.00034615384615384613, 'epoch': 0.92, 'step': 180}, {'eval_loss': 2.0436630249023438, 'eval_rouge1': 0.4024, 'eval_rouge2': 0.1778, 'eval_rougeL': 0.3649, 'eval_sacrebleu': 9.1825, 'eval_runtime': 11.9068, 'eval_samples_per_second': 182.164, 'eval_steps_per_second': 5.711, 'epoch': 0.92, 'step': 180}, {'loss': 2.2649, 'learning_rate': 0.0003452991452991453, 'epoch': 0.93, 'step': 181}, {'eval_loss': 2.0430352687835693, 'eval_rouge1': 0.4029, 'eval_rouge2': 0.1781, 'eval_rougeL': 0.3653, 'eval_sacrebleu': 9.1871, 'eval_runtime': 11.9168, 'eval_samples_per_second': 182.012, 'eval_steps_per_second': 5.706, 'epoch': 0.93, 'step': 181}, {'loss': 2.1607, 'learning_rate': 0.0003444444444444445, 'epoch': 0.93, 'step': 182}, {'eval_loss': 2.0421159267425537, 'eval_rouge1': 0.4021, 'eval_rouge2': 0.1782, 'eval_rougeL': 0.3647, 'eval_sacrebleu': 9.1804, 'eval_runtime': 12.2456, 'eval_samples_per_second': 177.125, 'eval_steps_per_second': 5.553, 'epoch': 0.93, 'step': 182}, {'loss': 2.0874, 'learning_rate': 0.0003435897435897436, 'epoch': 0.94, 'step': 183}, {'eval_loss': 2.041489839553833, 'eval_rouge1': 0.4024, 'eval_rouge2': 0.1786, 'eval_rougeL': 0.3649, 'eval_sacrebleu': 9.1948, 'eval_runtime': 11.9047, 'eval_samples_per_second': 182.197, 'eval_steps_per_second': 5.712, 'epoch': 0.94, 'step': 183}, {'loss': 2.1295, 'learning_rate': 0.00034273504273504276, 'epoch': 0.94, 'step': 184}, {'eval_loss': 2.0407400131225586, 'eval_rouge1': 0.4023, 'eval_rouge2': 0.1786, 'eval_rougeL': 0.3646, 'eval_sacrebleu': 9.2077, 'eval_runtime': 12.1626, 'eval_samples_per_second': 178.333, 'eval_steps_per_second': 5.591, 'epoch': 0.94, 'step': 184}, {'loss': 2.1802, 'learning_rate': 0.0003418803418803419, 'epoch': 0.95, 'step': 185}, {'eval_loss': 2.0401055812835693, 'eval_rouge1': 0.4017, 'eval_rouge2': 0.1784, 'eval_rougeL': 0.3642, 'eval_sacrebleu': 9.2128, 'eval_runtime': 11.9189, 'eval_samples_per_second': 181.98, 'eval_steps_per_second': 5.705, 'epoch': 0.95, 'step': 185}, {'loss': 2.1262, 'learning_rate': 0.00034102564102564105, 'epoch': 0.95, 'step': 186}, {'eval_loss': 2.039727210998535, 'eval_rouge1': 0.4014, 'eval_rouge2': 0.1782, 'eval_rougeL': 0.364, 'eval_sacrebleu': 9.2212, 'eval_runtime': 11.8676, 'eval_samples_per_second': 182.767, 'eval_steps_per_second': 5.73, 'epoch': 0.95, 'step': 186}, {'loss': 2.1367, 'learning_rate': 0.00034017094017094017, 'epoch': 0.96, 'step': 187}, {'eval_loss': 2.0392186641693115, 'eval_rouge1': 0.4015, 'eval_rouge2': 0.178, 'eval_rougeL': 0.3643, 'eval_sacrebleu': 9.2689, 'eval_runtime': 11.9713, 'eval_samples_per_second': 181.183, 'eval_steps_per_second': 5.68, 'epoch': 0.96, 'step': 187}, {'loss': 2.1266, 'learning_rate': 0.00033931623931623934, 'epoch': 0.96, 'step': 188}, {'eval_loss': 2.038724422454834, 'eval_rouge1': 0.4023, 'eval_rouge2': 0.1791, 'eval_rougeL': 0.3647, 'eval_sacrebleu': 9.3202, 'eval_runtime': 11.9008, 'eval_samples_per_second': 182.256, 'eval_steps_per_second': 5.714, 'epoch': 0.96, 'step': 188}, {'loss': 2.186, 'learning_rate': 0.0003384615384615385, 'epoch': 0.97, 'step': 189}, {'eval_loss': 2.0380752086639404, 'eval_rouge1': 0.4015, 'eval_rouge2': 0.1783, 'eval_rougeL': 0.3637, 'eval_sacrebleu': 9.3003, 'eval_runtime': 12.2104, 'eval_samples_per_second': 177.635, 'eval_steps_per_second': 5.569, 'epoch': 0.97, 'step': 189}, {'loss': 2.1286, 'learning_rate': 0.00033760683760683763, 'epoch': 0.97, 'step': 190}, {'eval_loss': 2.0374603271484375, 'eval_rouge1': 0.402, 'eval_rouge2': 0.1787, 'eval_rougeL': 0.3642, 'eval_sacrebleu': 9.3414, 'eval_runtime': 11.918, 'eval_samples_per_second': 181.993, 'eval_steps_per_second': 5.706, 'epoch': 0.97, 'step': 190}, {'loss': 2.1665, 'learning_rate': 0.0003367521367521368, 'epoch': 0.98, 'step': 191}, {'eval_loss': 2.0368473529815674, 'eval_rouge1': 0.4022, 'eval_rouge2': 0.1785, 'eval_rougeL': 0.3641, 'eval_sacrebleu': 9.3368, 'eval_runtime': 12.204, 'eval_samples_per_second': 177.728, 'eval_steps_per_second': 5.572, 'epoch': 0.98, 'step': 191}, {'loss': 2.2126, 'learning_rate': 0.00033589743589743586, 'epoch': 0.98, 'step': 192}, {'eval_loss': 2.036388635635376, 'eval_rouge1': 0.4023, 'eval_rouge2': 0.1785, 'eval_rougeL': 0.3643, 'eval_sacrebleu': 9.372, 'eval_runtime': 11.9536, 'eval_samples_per_second': 181.452, 'eval_steps_per_second': 5.689, 'epoch': 0.98, 'step': 192}, {'loss': 2.1811, 'learning_rate': 0.00033504273504273503, 'epoch': 0.99, 'step': 193}, {'eval_loss': 2.035916328430176, 'eval_rouge1': 0.4037, 'eval_rouge2': 0.1799, 'eval_rougeL': 0.3657, 'eval_sacrebleu': 9.4415, 'eval_runtime': 11.9363, 'eval_samples_per_second': 181.714, 'eval_steps_per_second': 5.697, 'epoch': 0.99, 'step': 193}, {'loss': 2.1388, 'learning_rate': 0.00033418803418803415, 'epoch': 0.99, 'step': 194}, {'eval_loss': 2.035717487335205, 'eval_rouge1': 0.4048, 'eval_rouge2': 0.1809, 'eval_rougeL': 0.3672, 'eval_sacrebleu': 9.462, 'eval_runtime': 11.9519, 'eval_samples_per_second': 181.477, 'eval_steps_per_second': 5.689, 'epoch': 0.99, 'step': 194}, {'loss': 2.0979, 'learning_rate': 0.0003333333333333333, 'epoch': 1.0, 'step': 195}, {'eval_loss': 2.0359604358673096, 'eval_rouge1': 0.4053, 'eval_rouge2': 0.1811, 'eval_rougeL': 0.3673, 'eval_sacrebleu': 9.4353, 'eval_runtime': 12.0557, 'eval_samples_per_second': 179.914, 'eval_steps_per_second': 5.64, 'epoch': 1.0, 'step': 195}, {'loss': 2.1149, 'learning_rate': 0.0003324786324786325, 'epoch': 1.0, 'step': 196}, {'eval_loss': 2.036464214324951, 'eval_rouge1': 0.4063, 'eval_rouge2': 0.1821, 'eval_rougeL': 0.3687, 'eval_sacrebleu': 9.4922, 'eval_runtime': 12.2338, 'eval_samples_per_second': 177.295, 'eval_steps_per_second': 5.558, 'epoch': 1.0, 'step': 196}, {'loss': 2.1109, 'learning_rate': 0.0003316239316239316, 'epoch': 1.01, 'step': 197}, {'eval_loss': 2.0368833541870117, 'eval_rouge1': 0.4074, 'eval_rouge2': 0.1827, 'eval_rougeL': 0.3696, 'eval_sacrebleu': 9.5131, 'eval_runtime': 11.9195, 'eval_samples_per_second': 181.971, 'eval_steps_per_second': 5.705, 'epoch': 1.01, 'step': 197}, {'loss': 2.095, 'learning_rate': 0.0003307692307692308, 'epoch': 1.01, 'step': 198}, {'eval_loss': 2.036890983581543, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1825, 'eval_rougeL': 0.369, 'eval_sacrebleu': 9.4997, 'eval_runtime': 12.2129, 'eval_samples_per_second': 177.599, 'eval_steps_per_second': 5.568, 'epoch': 1.01, 'step': 198}, {'loss': 2.0778, 'learning_rate': 0.0003299145299145299, 'epoch': 1.02, 'step': 199}, {'eval_loss': 2.036707878112793, 'eval_rouge1': 0.4071, 'eval_rouge2': 0.1821, 'eval_rougeL': 0.3688, 'eval_sacrebleu': 9.4959, 'eval_runtime': 11.9468, 'eval_samples_per_second': 181.555, 'eval_steps_per_second': 5.692, 'epoch': 1.02, 'step': 199}, {'loss': 2.0182, 'learning_rate': 0.00032905982905982907, 'epoch': 1.02, 'step': 200}, {'eval_loss': 2.0367002487182617, 'eval_rouge1': 0.4076, 'eval_rouge2': 0.1826, 'eval_rougeL': 0.3691, 'eval_sacrebleu': 9.5139, 'eval_runtime': 11.9278, 'eval_samples_per_second': 181.844, 'eval_steps_per_second': 5.701, 'epoch': 1.02, 'step': 200}, {'loss': 2.1261, 'learning_rate': 0.0003282051282051282, 'epoch': 1.03, 'step': 201}, {'eval_loss': 2.036936044692993, 'eval_rouge1': 0.4068, 'eval_rouge2': 0.1813, 'eval_rougeL': 0.3682, 'eval_sacrebleu': 9.4516, 'eval_runtime': 11.9772, 'eval_samples_per_second': 181.095, 'eval_steps_per_second': 5.677, 'epoch': 1.03, 'step': 201}, {'loss': 2.187, 'learning_rate': 0.00032735042735042736, 'epoch': 1.03, 'step': 202}, {'eval_loss': 2.037022829055786, 'eval_rouge1': 0.4066, 'eval_rouge2': 0.1812, 'eval_rougeL': 0.3683, 'eval_sacrebleu': 9.44, 'eval_runtime': 11.6738, 'eval_samples_per_second': 185.8, 'eval_steps_per_second': 5.825, 'epoch': 1.03, 'step': 202}, {'loss': 2.1424, 'learning_rate': 0.00032649572649572653, 'epoch': 1.04, 'step': 203}, {'eval_loss': 2.037188768386841, 'eval_rouge1': 0.4059, 'eval_rouge2': 0.1798, 'eval_rougeL': 0.3671, 'eval_sacrebleu': 9.3949, 'eval_runtime': 11.994, 'eval_samples_per_second': 180.84, 'eval_steps_per_second': 5.669, 'epoch': 1.04, 'step': 203}, {'loss': 2.0891, 'learning_rate': 0.00032564102564102565, 'epoch': 1.04, 'step': 204}, {'eval_loss': 2.037008047103882, 'eval_rouge1': 0.4059, 'eval_rouge2': 0.1803, 'eval_rougeL': 0.3672, 'eval_sacrebleu': 9.4208, 'eval_runtime': 11.7469, 'eval_samples_per_second': 184.644, 'eval_steps_per_second': 5.789, 'epoch': 1.04, 'step': 204}, {'loss': 2.1603, 'learning_rate': 0.0003247863247863248, 'epoch': 1.05, 'step': 205}, {'eval_loss': 2.0372583866119385, 'eval_rouge1': 0.406, 'eval_rouge2': 0.1804, 'eval_rougeL': 0.3676, 'eval_sacrebleu': 9.4507, 'eval_runtime': 12.039, 'eval_samples_per_second': 180.165, 'eval_steps_per_second': 5.648, 'epoch': 1.05, 'step': 205}, {'loss': 2.0252, 'learning_rate': 0.00032393162393162394, 'epoch': 1.05, 'step': 206}, {'eval_loss': 2.0373570919036865, 'eval_rouge1': 0.4061, 'eval_rouge2': 0.1801, 'eval_rougeL': 0.3675, 'eval_sacrebleu': 9.3759, 'eval_runtime': 11.8904, 'eval_samples_per_second': 182.417, 'eval_steps_per_second': 5.719, 'epoch': 1.05, 'step': 206}, {'loss': 2.1147, 'learning_rate': 0.0003230769230769231, 'epoch': 1.06, 'step': 207}, {'eval_loss': 2.037403106689453, 'eval_rouge1': 0.4061, 'eval_rouge2': 0.1805, 'eval_rougeL': 0.3676, 'eval_sacrebleu': 9.4437, 'eval_runtime': 11.9378, 'eval_samples_per_second': 181.691, 'eval_steps_per_second': 5.696, 'epoch': 1.06, 'step': 207}, {'loss': 2.0579, 'learning_rate': 0.0003222222222222222, 'epoch': 1.06, 'step': 208}, {'eval_loss': 2.0372238159179688, 'eval_rouge1': 0.4061, 'eval_rouge2': 0.1807, 'eval_rougeL': 0.3678, 'eval_sacrebleu': 9.4749, 'eval_runtime': 11.9944, 'eval_samples_per_second': 180.834, 'eval_steps_per_second': 5.669, 'epoch': 1.06, 'step': 208}, {'loss': 2.1456, 'learning_rate': 0.0003213675213675214, 'epoch': 1.07, 'step': 209}, {'eval_loss': 2.0369338989257812, 'eval_rouge1': 0.4061, 'eval_rouge2': 0.1805, 'eval_rougeL': 0.3677, 'eval_sacrebleu': 9.4774, 'eval_runtime': 11.928, 'eval_samples_per_second': 181.841, 'eval_steps_per_second': 5.701, 'epoch': 1.07, 'step': 209}, {'loss': 2.0985, 'learning_rate': 0.00032051282051282057, 'epoch': 1.07, 'step': 210}, {'eval_loss': 2.0361313819885254, 'eval_rouge1': 0.4064, 'eval_rouge2': 0.1813, 'eval_rougeL': 0.3683, 'eval_sacrebleu': 9.5056, 'eval_runtime': 12.2395, 'eval_samples_per_second': 177.213, 'eval_steps_per_second': 5.556, 'epoch': 1.07, 'step': 210}, {'loss': 2.2058, 'learning_rate': 0.00031965811965811963, 'epoch': 1.08, 'step': 211}, {'eval_loss': 2.0350093841552734, 'eval_rouge1': 0.4068, 'eval_rouge2': 0.1813, 'eval_rougeL': 0.3686, 'eval_sacrebleu': 9.5035, 'eval_runtime': 11.9452, 'eval_samples_per_second': 181.579, 'eval_steps_per_second': 5.693, 'epoch': 1.08, 'step': 211}, {'loss': 2.1126, 'learning_rate': 0.0003188034188034188, 'epoch': 1.09, 'step': 212}, {'eval_loss': 2.03385591506958, 'eval_rouge1': 0.4077, 'eval_rouge2': 0.1817, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.4995, 'eval_runtime': 12.2538, 'eval_samples_per_second': 177.006, 'eval_steps_per_second': 5.549, 'epoch': 1.09, 'step': 212}, {'loss': 2.0304, 'learning_rate': 0.0003179487179487179, 'epoch': 1.09, 'step': 213}, {'eval_loss': 2.0328896045684814, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1817, 'eval_rougeL': 0.3688, 'eval_sacrebleu': 9.5108, 'eval_runtime': 11.9422, 'eval_samples_per_second': 181.625, 'eval_steps_per_second': 5.694, 'epoch': 1.09, 'step': 213}, {'loss': 2.13, 'learning_rate': 0.0003170940170940171, 'epoch': 1.1, 'step': 214}, {'eval_loss': 2.0318984985351562, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1815, 'eval_rougeL': 0.3688, 'eval_sacrebleu': 9.5211, 'eval_runtime': 12.229, 'eval_samples_per_second': 177.366, 'eval_steps_per_second': 5.561, 'epoch': 1.1, 'step': 214}, {'loss': 1.9952, 'learning_rate': 0.0003162393162393162, 'epoch': 1.1, 'step': 215}, {'eval_loss': 2.0311501026153564, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1813, 'eval_rougeL': 0.3689, 'eval_sacrebleu': 9.5163, 'eval_runtime': 11.9828, 'eval_samples_per_second': 181.009, 'eval_steps_per_second': 5.675, 'epoch': 1.1, 'step': 215}, {'loss': 2.0745, 'learning_rate': 0.0003153846153846154, 'epoch': 1.11, 'step': 216}, {'eval_loss': 2.0304012298583984, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1818, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.5533, 'eval_runtime': 11.9442, 'eval_samples_per_second': 181.594, 'eval_steps_per_second': 5.693, 'epoch': 1.11, 'step': 216}, {'loss': 2.0723, 'learning_rate': 0.00031452991452991455, 'epoch': 1.11, 'step': 217}, {'eval_loss': 2.0300862789154053, 'eval_rouge1': 0.4071, 'eval_rouge2': 0.1818, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.5404, 'eval_runtime': 11.9452, 'eval_samples_per_second': 181.579, 'eval_steps_per_second': 5.693, 'epoch': 1.11, 'step': 217}, {'loss': 2.1267, 'learning_rate': 0.00031367521367521367, 'epoch': 1.12, 'step': 218}, {'eval_loss': 2.0297722816467285, 'eval_rouge1': 0.4073, 'eval_rouge2': 0.1824, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.5665, 'eval_runtime': 11.9371, 'eval_samples_per_second': 181.702, 'eval_steps_per_second': 5.697, 'epoch': 1.12, 'step': 218}, {'loss': 2.021, 'learning_rate': 0.00031282051282051284, 'epoch': 1.12, 'step': 219}, {'eval_loss': 2.029775381088257, 'eval_rouge1': 0.4077, 'eval_rouge2': 0.1826, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.5725, 'eval_runtime': 12.2167, 'eval_samples_per_second': 177.543, 'eval_steps_per_second': 5.566, 'epoch': 1.12, 'step': 219}, {'loss': 2.1059, 'learning_rate': 0.00031196581196581195, 'epoch': 1.13, 'step': 220}, {'eval_loss': 2.029477834701538, 'eval_rouge1': 0.4071, 'eval_rouge2': 0.1827, 'eval_rougeL': 0.3694, 'eval_sacrebleu': 9.5851, 'eval_runtime': 11.9359, 'eval_samples_per_second': 181.721, 'eval_steps_per_second': 5.697, 'epoch': 1.13, 'step': 220}, {'loss': 2.0771, 'learning_rate': 0.0003111111111111111, 'epoch': 1.13, 'step': 221}, {'eval_loss': 2.0291635990142822, 'eval_rouge1': 0.4069, 'eval_rouge2': 0.1822, 'eval_rougeL': 0.3688, 'eval_sacrebleu': 9.5615, 'eval_runtime': 12.2945, 'eval_samples_per_second': 176.421, 'eval_steps_per_second': 5.531, 'epoch': 1.13, 'step': 221}, {'loss': 2.0805, 'learning_rate': 0.0003102564102564103, 'epoch': 1.14, 'step': 222}, {'eval_loss': 2.029109239578247, 'eval_rouge1': 0.4071, 'eval_rouge2': 0.1821, 'eval_rougeL': 0.369, 'eval_sacrebleu': 9.5368, 'eval_runtime': 11.9206, 'eval_samples_per_second': 181.954, 'eval_steps_per_second': 5.704, 'epoch': 1.14, 'step': 222}, {'loss': 2.079, 'learning_rate': 0.0003094017094017094, 'epoch': 1.14, 'step': 223}, {'eval_loss': 2.0288619995117188, 'eval_rouge1': 0.4066, 'eval_rouge2': 0.1822, 'eval_rougeL': 0.3689, 'eval_sacrebleu': 9.5371, 'eval_runtime': 12.1833, 'eval_samples_per_second': 178.031, 'eval_steps_per_second': 5.581, 'epoch': 1.14, 'step': 223}, {'loss': 2.0998, 'learning_rate': 0.0003085470085470086, 'epoch': 1.15, 'step': 224}, {'eval_loss': 2.028686761856079, 'eval_rouge1': 0.4062, 'eval_rouge2': 0.1822, 'eval_rougeL': 0.3691, 'eval_sacrebleu': 9.5527, 'eval_runtime': 11.9462, 'eval_samples_per_second': 181.565, 'eval_steps_per_second': 5.692, 'epoch': 1.15, 'step': 224}, {'loss': 2.0941, 'learning_rate': 0.0003076923076923077, 'epoch': 1.15, 'step': 225}, {'eval_loss': 2.0283937454223633, 'eval_rouge1': 0.4062, 'eval_rouge2': 0.1821, 'eval_rougeL': 0.3691, 'eval_sacrebleu': 9.5229, 'eval_runtime': 11.7011, 'eval_samples_per_second': 185.367, 'eval_steps_per_second': 5.811, 'epoch': 1.15, 'step': 225}, {'loss': 2.0433, 'learning_rate': 0.0003068376068376069, 'epoch': 1.16, 'step': 226}, {'eval_loss': 2.0281410217285156, 'eval_rouge1': 0.4073, 'eval_rouge2': 0.1827, 'eval_rougeL': 0.3698, 'eval_sacrebleu': 9.5364, 'eval_runtime': 12.0042, 'eval_samples_per_second': 180.686, 'eval_steps_per_second': 5.665, 'epoch': 1.16, 'step': 226}, {'loss': 2.117, 'learning_rate': 0.000305982905982906, 'epoch': 1.16, 'step': 227}, {'eval_loss': 2.0279133319854736, 'eval_rouge1': 0.4074, 'eval_rouge2': 0.1828, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.5702, 'eval_runtime': 11.7794, 'eval_samples_per_second': 184.135, 'eval_steps_per_second': 5.773, 'epoch': 1.16, 'step': 227}, {'loss': 2.0417, 'learning_rate': 0.00030512820512820516, 'epoch': 1.17, 'step': 228}, {'eval_loss': 2.0278797149658203, 'eval_rouge1': 0.4072, 'eval_rouge2': 0.1821, 'eval_rougeL': 0.3697, 'eval_sacrebleu': 9.5251, 'eval_runtime': 12.0065, 'eval_samples_per_second': 180.653, 'eval_steps_per_second': 5.664, 'epoch': 1.17, 'step': 228}, {'loss': 2.0755, 'learning_rate': 0.0003042735042735043, 'epoch': 1.17, 'step': 229}, {'eval_loss': 2.028308629989624, 'eval_rouge1': 0.4079, 'eval_rouge2': 0.1824, 'eval_rougeL': 0.3701, 'eval_sacrebleu': 9.5301, 'eval_runtime': 11.856, 'eval_samples_per_second': 182.946, 'eval_steps_per_second': 5.736, 'epoch': 1.17, 'step': 229}, {'loss': 2.1441, 'learning_rate': 0.0003034188034188034, 'epoch': 1.18, 'step': 230}, {'eval_loss': 2.028682231903076, 'eval_rouge1': 0.4078, 'eval_rouge2': 0.1821, 'eval_rougeL': 0.3694, 'eval_sacrebleu': 9.4961, 'eval_runtime': 12.1859, 'eval_samples_per_second': 177.993, 'eval_steps_per_second': 5.58, 'epoch': 1.18, 'step': 230}, {'loss': 2.1156, 'learning_rate': 0.00030256410256410257, 'epoch': 1.18, 'step': 231}, {'eval_loss': 2.0291006565093994, 'eval_rouge1': 0.4067, 'eval_rouge2': 0.1812, 'eval_rougeL': 0.3681, 'eval_sacrebleu': 9.4616, 'eval_runtime': 11.9153, 'eval_samples_per_second': 182.036, 'eval_steps_per_second': 5.707, 'epoch': 1.18, 'step': 231}, {'loss': 2.0872, 'learning_rate': 0.0003017094017094017, 'epoch': 1.19, 'step': 232}, {'eval_loss': 2.029468297958374, 'eval_rouge1': 0.4062, 'eval_rouge2': 0.1813, 'eval_rougeL': 0.3678, 'eval_sacrebleu': 9.4818, 'eval_runtime': 11.9203, 'eval_samples_per_second': 181.958, 'eval_steps_per_second': 5.705, 'epoch': 1.19, 'step': 232}, {'loss': 2.1181, 'learning_rate': 0.00030085470085470086, 'epoch': 1.19, 'step': 233}, {'eval_loss': 2.029317617416382, 'eval_rouge1': 0.4059, 'eval_rouge2': 0.1808, 'eval_rougeL': 0.3671, 'eval_sacrebleu': 9.4636, 'eval_runtime': 12.0052, 'eval_samples_per_second': 180.672, 'eval_steps_per_second': 5.664, 'epoch': 1.19, 'step': 233}, {'loss': 2.0533, 'learning_rate': 0.0003, 'epoch': 1.2, 'step': 234}, {'eval_loss': 2.0294265747070312, 'eval_rouge1': 0.4057, 'eval_rouge2': 0.1805, 'eval_rougeL': 0.3669, 'eval_sacrebleu': 9.4497, 'eval_runtime': 11.7152, 'eval_samples_per_second': 185.145, 'eval_steps_per_second': 5.804, 'epoch': 1.2, 'step': 234}, {'loss': 2.0763, 'learning_rate': 0.00029914529914529915, 'epoch': 1.2, 'step': 235}, {'eval_loss': 2.0296390056610107, 'eval_rouge1': 0.4063, 'eval_rouge2': 0.1811, 'eval_rougeL': 0.3673, 'eval_sacrebleu': 9.4649, 'eval_runtime': 12.0025, 'eval_samples_per_second': 180.712, 'eval_steps_per_second': 5.665, 'epoch': 1.2, 'step': 235}, {'loss': 2.1297, 'learning_rate': 0.0002982905982905983, 'epoch': 1.21, 'step': 236}, {'eval_loss': 2.029762029647827, 'eval_rouge1': 0.4064, 'eval_rouge2': 0.1808, 'eval_rougeL': 0.3672, 'eval_sacrebleu': 9.4756, 'eval_runtime': 11.7377, 'eval_samples_per_second': 184.789, 'eval_steps_per_second': 5.793, 'epoch': 1.21, 'step': 236}, {'loss': 2.0201, 'learning_rate': 0.00029743589743589743, 'epoch': 1.21, 'step': 237}, {'eval_loss': 2.028923273086548, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1814, 'eval_rougeL': 0.3682, 'eval_sacrebleu': 9.5181, 'eval_runtime': 11.9837, 'eval_samples_per_second': 180.996, 'eval_steps_per_second': 5.674, 'epoch': 1.21, 'step': 237}, {'loss': 2.0783, 'learning_rate': 0.0002965811965811966, 'epoch': 1.22, 'step': 238}, {'eval_loss': 2.027998924255371, 'eval_rouge1': 0.4073, 'eval_rouge2': 0.1815, 'eval_rougeL': 0.369, 'eval_sacrebleu': 9.5078, 'eval_runtime': 11.9058, 'eval_samples_per_second': 182.179, 'eval_steps_per_second': 5.711, 'epoch': 1.22, 'step': 238}, {'loss': 1.9958, 'learning_rate': 0.0002957264957264957, 'epoch': 1.22, 'step': 239}, {'eval_loss': 2.027331590652466, 'eval_rouge1': 0.4079, 'eval_rouge2': 0.1813, 'eval_rougeL': 0.3696, 'eval_sacrebleu': 9.4662, 'eval_runtime': 11.9121, 'eval_samples_per_second': 182.084, 'eval_steps_per_second': 5.709, 'epoch': 1.22, 'step': 239}, {'loss': 2.0769, 'learning_rate': 0.0002948717948717949, 'epoch': 1.23, 'step': 240}, {'eval_loss': 2.0267701148986816, 'eval_rouge1': 0.4073, 'eval_rouge2': 0.1809, 'eval_rougeL': 0.3692, 'eval_sacrebleu': 9.4189, 'eval_runtime': 11.9043, 'eval_samples_per_second': 182.203, 'eval_steps_per_second': 5.712, 'epoch': 1.23, 'step': 240}, {'loss': 2.0727, 'learning_rate': 0.000294017094017094, 'epoch': 1.23, 'step': 241}, {'eval_loss': 2.0264461040496826, 'eval_rouge1': 0.4077, 'eval_rouge2': 0.1815, 'eval_rougeL': 0.3692, 'eval_sacrebleu': 9.4084, 'eval_runtime': 11.9316, 'eval_samples_per_second': 181.786, 'eval_steps_per_second': 5.699, 'epoch': 1.23, 'step': 241}, {'loss': 2.0422, 'learning_rate': 0.0002931623931623932, 'epoch': 1.24, 'step': 242}, {'eval_loss': 2.0263943672180176, 'eval_rouge1': 0.4081, 'eval_rouge2': 0.1819, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.4218, 'eval_runtime': 12.226, 'eval_samples_per_second': 177.409, 'eval_steps_per_second': 5.562, 'epoch': 1.24, 'step': 242}, {'loss': 2.1314, 'learning_rate': 0.00029230769230769235, 'epoch': 1.24, 'step': 243}, {'eval_loss': 2.0263257026672363, 'eval_rouge1': 0.4084, 'eval_rouge2': 0.1816, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.3978, 'eval_runtime': 11.9361, 'eval_samples_per_second': 181.718, 'eval_steps_per_second': 5.697, 'epoch': 1.24, 'step': 243}, {'loss': 2.0974, 'learning_rate': 0.00029145299145299147, 'epoch': 1.25, 'step': 244}, {'eval_loss': 2.0258634090423584, 'eval_rouge1': 0.4082, 'eval_rouge2': 0.1814, 'eval_rougeL': 0.3696, 'eval_sacrebleu': 9.4294, 'eval_runtime': 12.2287, 'eval_samples_per_second': 177.369, 'eval_steps_per_second': 5.561, 'epoch': 1.25, 'step': 244}, {'loss': 2.0665, 'learning_rate': 0.00029059829059829064, 'epoch': 1.25, 'step': 245}, {'eval_loss': 2.025599241256714, 'eval_rouge1': 0.408, 'eval_rouge2': 0.182, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.4221, 'eval_runtime': 11.9333, 'eval_samples_per_second': 181.761, 'eval_steps_per_second': 5.698, 'epoch': 1.25, 'step': 245}, {'loss': 2.0128, 'learning_rate': 0.00028974358974358976, 'epoch': 1.26, 'step': 246}, {'eval_loss': 2.025320291519165, 'eval_rouge1': 0.4082, 'eval_rouge2': 0.1817, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.4257, 'eval_runtime': 11.8319, 'eval_samples_per_second': 183.318, 'eval_steps_per_second': 5.747, 'epoch': 1.26, 'step': 246}, {'loss': 2.139, 'learning_rate': 0.0002888888888888889, 'epoch': 1.26, 'step': 247}, {'eval_loss': 2.0247445106506348, 'eval_rouge1': 0.4084, 'eval_rouge2': 0.1827, 'eval_rougeL': 0.3697, 'eval_sacrebleu': 9.5016, 'eval_runtime': 12.0799, 'eval_samples_per_second': 179.554, 'eval_steps_per_second': 5.629, 'epoch': 1.26, 'step': 247}, {'loss': 2.1117, 'learning_rate': 0.000288034188034188, 'epoch': 1.27, 'step': 248}, {'eval_loss': 2.0244667530059814, 'eval_rouge1': 0.4083, 'eval_rouge2': 0.1828, 'eval_rougeL': 0.3698, 'eval_sacrebleu': 9.5163, 'eval_runtime': 11.8684, 'eval_samples_per_second': 182.754, 'eval_steps_per_second': 5.73, 'epoch': 1.27, 'step': 248}, {'loss': 2.1189, 'learning_rate': 0.00028717948717948716, 'epoch': 1.27, 'step': 249}, {'eval_loss': 2.0243477821350098, 'eval_rouge1': 0.4084, 'eval_rouge2': 0.1828, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.5348, 'eval_runtime': 12.2032, 'eval_samples_per_second': 177.741, 'eval_steps_per_second': 5.572, 'epoch': 1.27, 'step': 249}, {'loss': 2.0719, 'learning_rate': 0.00028632478632478634, 'epoch': 1.28, 'step': 250}, {'eval_loss': 2.023932695388794, 'eval_rouge1': 0.4085, 'eval_rouge2': 0.1834, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.5378, 'eval_runtime': 11.9344, 'eval_samples_per_second': 181.743, 'eval_steps_per_second': 5.698, 'epoch': 1.28, 'step': 250}, {'loss': 2.0296, 'learning_rate': 0.00028547008547008545, 'epoch': 1.28, 'step': 251}, {'eval_loss': 2.023707628250122, 'eval_rouge1': 0.4077, 'eval_rouge2': 0.1826, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.4942, 'eval_runtime': 12.1785, 'eval_samples_per_second': 178.1, 'eval_steps_per_second': 5.584, 'epoch': 1.28, 'step': 251}, {'loss': 2.0628, 'learning_rate': 0.0002846153846153846, 'epoch': 1.29, 'step': 252}, {'eval_loss': 2.0240163803100586, 'eval_rouge1': 0.4081, 'eval_rouge2': 0.1828, 'eval_rougeL': 0.3697, 'eval_sacrebleu': 9.4821, 'eval_runtime': 11.9363, 'eval_samples_per_second': 181.715, 'eval_steps_per_second': 5.697, 'epoch': 1.29, 'step': 252}, {'loss': 1.9792, 'learning_rate': 0.00028376068376068374, 'epoch': 1.29, 'step': 253}, {'eval_loss': 2.023857355117798, 'eval_rouge1': 0.4072, 'eval_rouge2': 0.1829, 'eval_rougeL': 0.3692, 'eval_sacrebleu': 9.5216, 'eval_runtime': 12.0248, 'eval_samples_per_second': 180.378, 'eval_steps_per_second': 5.655, 'epoch': 1.29, 'step': 253}, {'loss': 2.0436, 'learning_rate': 0.0002829059829059829, 'epoch': 1.3, 'step': 254}, {'eval_loss': 2.0236964225769043, 'eval_rouge1': 0.407, 'eval_rouge2': 0.1823, 'eval_rougeL': 0.3691, 'eval_sacrebleu': 9.4957, 'eval_runtime': 12.0675, 'eval_samples_per_second': 179.739, 'eval_steps_per_second': 5.635, 'epoch': 1.3, 'step': 254}, {'loss': 2.0966, 'learning_rate': 0.00028205128205128203, 'epoch': 1.31, 'step': 255}, {'eval_loss': 2.0236504077911377, 'eval_rouge1': 0.4077, 'eval_rouge2': 0.183, 'eval_rougeL': 0.3698, 'eval_sacrebleu': 9.5255, 'eval_runtime': 11.9687, 'eval_samples_per_second': 181.223, 'eval_steps_per_second': 5.681, 'epoch': 1.31, 'step': 255}, {'loss': 2.0702, 'learning_rate': 0.0002811965811965812, 'epoch': 1.31, 'step': 256}, {'eval_loss': 2.0232551097869873, 'eval_rouge1': 0.4082, 'eval_rouge2': 0.183, 'eval_rougeL': 0.3699, 'eval_sacrebleu': 9.5268, 'eval_runtime': 12.2928, 'eval_samples_per_second': 176.444, 'eval_steps_per_second': 5.532, 'epoch': 1.31, 'step': 256}, {'loss': 2.1247, 'learning_rate': 0.00028034188034188037, 'epoch': 1.32, 'step': 257}, {'eval_loss': 2.022792100906372, 'eval_rouge1': 0.4085, 'eval_rouge2': 0.1835, 'eval_rougeL': 0.3705, 'eval_sacrebleu': 9.5648, 'eval_runtime': 11.9771, 'eval_samples_per_second': 181.096, 'eval_steps_per_second': 5.678, 'epoch': 1.32, 'step': 257}, {'loss': 2.0812, 'learning_rate': 0.0002794871794871795, 'epoch': 1.32, 'step': 258}, {'eval_loss': 2.022233009338379, 'eval_rouge1': 0.4086, 'eval_rouge2': 0.1835, 'eval_rougeL': 0.3705, 'eval_sacrebleu': 9.5133, 'eval_runtime': 12.233, 'eval_samples_per_second': 177.308, 'eval_steps_per_second': 5.559, 'epoch': 1.32, 'step': 258}, {'loss': 2.0535, 'learning_rate': 0.00027863247863247866, 'epoch': 1.33, 'step': 259}, {'eval_loss': 2.0214266777038574, 'eval_rouge1': 0.4088, 'eval_rouge2': 0.1831, 'eval_rougeL': 0.3705, 'eval_sacrebleu': 9.5027, 'eval_runtime': 11.9629, 'eval_samples_per_second': 181.311, 'eval_steps_per_second': 5.684, 'epoch': 1.33, 'step': 259}, {'loss': 2.0703, 'learning_rate': 0.0002777777777777778, 'epoch': 1.33, 'step': 260}, {'eval_loss': 2.0206797122955322, 'eval_rouge1': 0.4089, 'eval_rouge2': 0.1833, 'eval_rougeL': 0.3706, 'eval_sacrebleu': 9.5317, 'eval_runtime': 12.0195, 'eval_samples_per_second': 180.457, 'eval_steps_per_second': 5.657, 'epoch': 1.33, 'step': 260}, {'loss': 2.1277, 'learning_rate': 0.00027692307692307695, 'epoch': 1.34, 'step': 261}, {'eval_loss': 2.020221471786499, 'eval_rouge1': 0.4085, 'eval_rouge2': 0.183, 'eval_rougeL': 0.3697, 'eval_sacrebleu': 9.5374, 'eval_runtime': 12.0982, 'eval_samples_per_second': 179.283, 'eval_steps_per_second': 5.621, 'epoch': 1.34, 'step': 261}, {'loss': 2.0809, 'learning_rate': 0.00027606837606837607, 'epoch': 1.34, 'step': 262}, {'eval_loss': 2.0199809074401855, 'eval_rouge1': 0.4089, 'eval_rouge2': 0.1833, 'eval_rougeL': 0.3699, 'eval_sacrebleu': 9.5603, 'eval_runtime': 11.9338, 'eval_samples_per_second': 181.752, 'eval_steps_per_second': 5.698, 'epoch': 1.34, 'step': 262}, {'loss': 2.0908, 'learning_rate': 0.00027521367521367524, 'epoch': 1.35, 'step': 263}, {'eval_loss': 2.019810914993286, 'eval_rouge1': 0.4083, 'eval_rouge2': 0.1829, 'eval_rougeL': 0.3694, 'eval_sacrebleu': 9.562, 'eval_runtime': 12.2249, 'eval_samples_per_second': 177.424, 'eval_steps_per_second': 5.562, 'epoch': 1.35, 'step': 263}, {'loss': 2.0434, 'learning_rate': 0.0002743589743589744, 'epoch': 1.35, 'step': 264}, {'eval_loss': 2.0197765827178955, 'eval_rouge1': 0.4083, 'eval_rouge2': 0.1831, 'eval_rougeL': 0.3695, 'eval_sacrebleu': 9.5778, 'eval_runtime': 11.8827, 'eval_samples_per_second': 182.535, 'eval_steps_per_second': 5.723, 'epoch': 1.35, 'step': 264}, {'loss': 2.0596, 'learning_rate': 0.0002735042735042735, 'epoch': 1.36, 'step': 265}, {'eval_loss': 2.0202624797821045, 'eval_rouge1': 0.408, 'eval_rouge2': 0.1829, 'eval_rougeL': 0.3694, 'eval_sacrebleu': 9.5663, 'eval_runtime': 12.0574, 'eval_samples_per_second': 179.89, 'eval_steps_per_second': 5.64, 'epoch': 1.36, 'step': 265}, {'loss': 2.0096, 'learning_rate': 0.00027264957264957264, 'epoch': 1.36, 'step': 266}, {'eval_loss': 2.020847797393799, 'eval_rouge1': 0.408, 'eval_rouge2': 0.1828, 'eval_rougeL': 0.3691, 'eval_sacrebleu': 9.5472, 'eval_runtime': 11.782, 'eval_samples_per_second': 184.095, 'eval_steps_per_second': 5.772, 'epoch': 1.36, 'step': 266}, {'loss': 2.0279, 'learning_rate': 0.00027179487179487176, 'epoch': 1.37, 'step': 267}, {'eval_loss': 2.021409749984741, 'eval_rouge1': 0.4087, 'eval_rouge2': 0.183, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.5422, 'eval_runtime': 11.858, 'eval_samples_per_second': 182.914, 'eval_steps_per_second': 5.735, 'epoch': 1.37, 'step': 267}, {'loss': 2.116, 'learning_rate': 0.00027094017094017093, 'epoch': 1.37, 'step': 268}, {'eval_loss': 2.0216064453125, 'eval_rouge1': 0.4088, 'eval_rouge2': 0.1827, 'eval_rougeL': 0.3697, 'eval_sacrebleu': 9.5036, 'eval_runtime': 11.839, 'eval_samples_per_second': 183.209, 'eval_steps_per_second': 5.744, 'epoch': 1.37, 'step': 268}, {'loss': 2.0991, 'learning_rate': 0.00027008547008547005, 'epoch': 1.38, 'step': 269}, {'eval_loss': 2.021892786026001, 'eval_rouge1': 0.4084, 'eval_rouge2': 0.1822, 'eval_rougeL': 0.3693, 'eval_sacrebleu': 9.495, 'eval_runtime': 11.7704, 'eval_samples_per_second': 184.276, 'eval_steps_per_second': 5.777, 'epoch': 1.38, 'step': 269}, {'loss': 2.0826, 'learning_rate': 0.0002692307692307692, 'epoch': 1.38, 'step': 270}, {'eval_loss': 2.0219545364379883, 'eval_rouge1': 0.4092, 'eval_rouge2': 0.1822, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.5022, 'eval_runtime': 12.0395, 'eval_samples_per_second': 180.157, 'eval_steps_per_second': 5.648, 'epoch': 1.38, 'step': 270}, {'loss': 2.0645, 'learning_rate': 0.0002683760683760684, 'epoch': 1.39, 'step': 271}, {'eval_loss': 2.0221076011657715, 'eval_rouge1': 0.4091, 'eval_rouge2': 0.1823, 'eval_rougeL': 0.3701, 'eval_sacrebleu': 9.4893, 'eval_runtime': 11.7243, 'eval_samples_per_second': 185.0, 'eval_steps_per_second': 5.8, 'epoch': 1.39, 'step': 271}, {'loss': 2.1293, 'learning_rate': 0.0002675213675213675, 'epoch': 1.39, 'step': 272}, {'eval_loss': 2.0218772888183594, 'eval_rouge1': 0.4094, 'eval_rouge2': 0.1826, 'eval_rougeL': 0.37, 'eval_sacrebleu': 9.4678, 'eval_runtime': 12.022, 'eval_samples_per_second': 180.419, 'eval_steps_per_second': 5.656, 'epoch': 1.39, 'step': 272}, {'loss': 2.0907, 'learning_rate': 0.0002666666666666667, 'epoch': 1.4, 'step': 273}, {'eval_loss': 2.0216023921966553, 'eval_rouge1': 0.409, 'eval_rouge2': 0.182, 'eval_rougeL': 0.3696, 'eval_sacrebleu': 9.4558, 'eval_runtime': 11.7368, 'eval_samples_per_second': 184.803, 'eval_steps_per_second': 5.794, 'epoch': 1.4, 'step': 273}, {'loss': 2.0883, 'learning_rate': 0.0002658119658119658, 'epoch': 1.4, 'step': 274}, {'eval_loss': 2.0211520195007324, 'eval_rouge1': 0.4092, 'eval_rouge2': 0.1825, 'eval_rougeL': 0.3701, 'eval_sacrebleu': 9.487, 'eval_runtime': 12.0196, 'eval_samples_per_second': 180.456, 'eval_steps_per_second': 5.657, 'epoch': 1.4, 'step': 274}, {'loss': 2.1218, 'learning_rate': 0.00026495726495726497, 'epoch': 1.41, 'step': 275}, {'eval_loss': 2.020311117172241, 'eval_rouge1': 0.4084, 'eval_rouge2': 0.1824, 'eval_rougeL': 0.3698, 'eval_sacrebleu': 9.4819, 'eval_runtime': 11.9241, 'eval_samples_per_second': 181.901, 'eval_steps_per_second': 5.703, 'epoch': 1.41, 'step': 275}, {'loss': 2.0903, 'learning_rate': 0.00026410256410256414, 'epoch': 1.41, 'step': 276}, {'eval_loss': 2.0197105407714844, 'eval_rouge1': 0.4087, 'eval_rouge2': 0.1834, 'eval_rougeL': 0.3702, 'eval_sacrebleu': 9.5243, 'eval_runtime': 11.9478, 'eval_samples_per_second': 181.54, 'eval_steps_per_second': 5.691, 'epoch': 1.41, 'step': 276}, {'loss': 2.0933, 'learning_rate': 0.00026324786324786326, 'epoch': 1.42, 'step': 277}, {'eval_loss': 2.018983840942383, 'eval_rouge1': 0.4088, 'eval_rouge2': 0.1838, 'eval_rougeL': 0.3702, 'eval_sacrebleu': 9.5081, 'eval_runtime': 11.9838, 'eval_samples_per_second': 180.995, 'eval_steps_per_second': 5.674, 'epoch': 1.42, 'step': 277}, {'loss': 2.0371, 'learning_rate': 0.00026239316239316243, 'epoch': 1.42, 'step': 278}, {'eval_loss': 2.0184504985809326, 'eval_rouge1': 0.4093, 'eval_rouge2': 0.184, 'eval_rougeL': 0.3705, 'eval_sacrebleu': 9.5321, 'eval_runtime': 11.943, 'eval_samples_per_second': 181.612, 'eval_steps_per_second': 5.694, 'epoch': 1.42, 'step': 278}, {'loss': 2.0505, 'learning_rate': 0.00026153846153846154, 'epoch': 1.43, 'step': 279}, {'eval_loss': 2.0180296897888184, 'eval_rouge1': 0.4089, 'eval_rouge2': 0.1838, 'eval_rougeL': 0.3702, 'eval_sacrebleu': 9.5625, 'eval_runtime': 12.2297, 'eval_samples_per_second': 177.355, 'eval_steps_per_second': 5.56, 'epoch': 1.43, 'step': 279}, {'loss': 2.0736, 'learning_rate': 0.0002606837606837607, 'epoch': 1.43, 'step': 280}, {'eval_loss': 2.017695426940918, 'eval_rouge1': 0.4091, 'eval_rouge2': 0.1841, 'eval_rougeL': 0.3705, 'eval_sacrebleu': 9.6073, 'eval_runtime': 11.9272, 'eval_samples_per_second': 181.854, 'eval_steps_per_second': 5.701, 'epoch': 1.43, 'step': 280}, {'loss': 2.1141, 'learning_rate': 0.00025982905982905983, 'epoch': 1.44, 'step': 281}, {'eval_loss': 2.0173566341400146, 'eval_rouge1': 0.4095, 'eval_rouge2': 0.1837, 'eval_rougeL': 0.3709, 'eval_sacrebleu': 9.6023, 'eval_runtime': 12.2351, 'eval_samples_per_second': 177.277, 'eval_steps_per_second': 5.558, 'epoch': 1.44, 'step': 281}, {'loss': 2.0528, 'learning_rate': 0.000258974358974359, 'epoch': 1.44, 'step': 282}, {'eval_loss': 2.016923427581787, 'eval_rouge1': 0.4096, 'eval_rouge2': 0.1842, 'eval_rougeL': 0.3708, 'eval_sacrebleu': 9.6381, 'eval_runtime': 11.7159, 'eval_samples_per_second': 185.133, 'eval_steps_per_second': 5.804, 'epoch': 1.44, 'step': 282}, {'loss': 2.0674, 'learning_rate': 0.0002581196581196582, 'epoch': 1.45, 'step': 283}, {'eval_loss': 2.0161936283111572, 'eval_rouge1': 0.4107, 'eval_rouge2': 0.1851, 'eval_rougeL': 0.3721, 'eval_sacrebleu': 9.6937, 'eval_runtime': 12.0658, 'eval_samples_per_second': 179.765, 'eval_steps_per_second': 5.636, 'epoch': 1.45, 'step': 283}, {'loss': 2.0613, 'learning_rate': 0.00025726495726495724, 'epoch': 1.45, 'step': 284}, {'eval_loss': 2.015598773956299, 'eval_rouge1': 0.4113, 'eval_rouge2': 0.1858, 'eval_rougeL': 0.3727, 'eval_sacrebleu': 9.7468, 'eval_runtime': 11.9483, 'eval_samples_per_second': 181.533, 'eval_steps_per_second': 5.691, 'epoch': 1.45, 'step': 284}, {'loss': 2.0727, 'learning_rate': 0.0002564102564102564, 'epoch': 1.46, 'step': 285}, {'eval_loss': 2.0154457092285156, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1859, 'eval_rougeL': 0.3728, 'eval_sacrebleu': 9.708, 'eval_runtime': 11.9124, 'eval_samples_per_second': 182.08, 'eval_steps_per_second': 5.708, 'epoch': 1.46, 'step': 285}, {'loss': 2.0653, 'learning_rate': 0.00025555555555555553, 'epoch': 1.46, 'step': 286}, {'eval_loss': 2.0152997970581055, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.1858, 'eval_rougeL': 0.3731, 'eval_sacrebleu': 9.7285, 'eval_runtime': 12.2433, 'eval_samples_per_second': 177.157, 'eval_steps_per_second': 5.554, 'epoch': 1.46, 'step': 286}, {'loss': 2.0433, 'learning_rate': 0.0002547008547008547, 'epoch': 1.47, 'step': 287}, {'eval_loss': 2.015207529067993, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.1856, 'eval_rougeL': 0.3733, 'eval_sacrebleu': 9.6933, 'eval_runtime': 11.9373, 'eval_samples_per_second': 181.699, 'eval_steps_per_second': 5.696, 'epoch': 1.47, 'step': 287}, {'loss': 2.1061, 'learning_rate': 0.0002538461538461538, 'epoch': 1.47, 'step': 288}, {'eval_loss': 2.015488624572754, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1855, 'eval_rougeL': 0.3727, 'eval_sacrebleu': 9.6786, 'eval_runtime': 12.2556, 'eval_samples_per_second': 176.981, 'eval_steps_per_second': 5.548, 'epoch': 1.47, 'step': 288}, {'loss': 1.9633, 'learning_rate': 0.000252991452991453, 'epoch': 1.48, 'step': 289}, {'eval_loss': 2.0161802768707275, 'eval_rouge1': 0.4124, 'eval_rouge2': 0.186, 'eval_rougeL': 0.3735, 'eval_sacrebleu': 9.6933, 'eval_runtime': 12.0888, 'eval_samples_per_second': 179.422, 'eval_steps_per_second': 5.625, 'epoch': 1.48, 'step': 289}, {'loss': 2.0067, 'learning_rate': 0.00025213675213675216, 'epoch': 1.48, 'step': 290}, {'eval_loss': 2.0167949199676514, 'eval_rouge1': 0.4126, 'eval_rouge2': 0.1857, 'eval_rougeL': 0.3735, 'eval_sacrebleu': 9.6475, 'eval_runtime': 12.3943, 'eval_samples_per_second': 175.0, 'eval_steps_per_second': 5.486, 'epoch': 1.48, 'step': 290}, {'loss': 2.03, 'learning_rate': 0.0002512820512820513, 'epoch': 1.49, 'step': 291}, {'eval_loss': 2.0172688961029053, 'eval_rouge1': 0.4125, 'eval_rouge2': 0.1855, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.6404, 'eval_runtime': 12.0611, 'eval_samples_per_second': 179.835, 'eval_steps_per_second': 5.638, 'epoch': 1.49, 'step': 291}, {'loss': 2.111, 'learning_rate': 0.00025042735042735045, 'epoch': 1.49, 'step': 292}, {'eval_loss': 2.0175230503082275, 'eval_rouge1': 0.4126, 'eval_rouge2': 0.1857, 'eval_rougeL': 0.3738, 'eval_sacrebleu': 9.6467, 'eval_runtime': 12.0727, 'eval_samples_per_second': 179.661, 'eval_steps_per_second': 5.633, 'epoch': 1.49, 'step': 292}, {'loss': 2.084, 'learning_rate': 0.00024957264957264956, 'epoch': 1.5, 'step': 293}, {'eval_loss': 2.0175769329071045, 'eval_rouge1': 0.4125, 'eval_rouge2': 0.1859, 'eval_rougeL': 0.3737, 'eval_sacrebleu': 9.6274, 'eval_runtime': 12.3362, 'eval_samples_per_second': 175.824, 'eval_steps_per_second': 5.512, 'epoch': 1.5, 'step': 293}, {'loss': 2.0589, 'learning_rate': 0.00024871794871794874, 'epoch': 1.5, 'step': 294}, {'eval_loss': 2.0172479152679443, 'eval_rouge1': 0.4124, 'eval_rouge2': 0.1862, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.6432, 'eval_runtime': 12.0719, 'eval_samples_per_second': 179.674, 'eval_steps_per_second': 5.633, 'epoch': 1.5, 'step': 294}, {'loss': 2.0255, 'learning_rate': 0.00024786324786324785, 'epoch': 1.51, 'step': 295}, {'eval_loss': 2.016845941543579, 'eval_rouge1': 0.4126, 'eval_rouge2': 0.1859, 'eval_rougeL': 0.3737, 'eval_sacrebleu': 9.6586, 'eval_runtime': 12.2246, 'eval_samples_per_second': 177.429, 'eval_steps_per_second': 5.563, 'epoch': 1.51, 'step': 295}, {'loss': 2.0583, 'learning_rate': 0.000247008547008547, 'epoch': 1.52, 'step': 296}, {'eval_loss': 2.0166425704956055, 'eval_rouge1': 0.4118, 'eval_rouge2': 0.1852, 'eval_rougeL': 0.3731, 'eval_sacrebleu': 9.6437, 'eval_runtime': 12.0255, 'eval_samples_per_second': 180.367, 'eval_steps_per_second': 5.655, 'epoch': 1.52, 'step': 296}, {'loss': 2.0978, 'learning_rate': 0.0002461538461538462, 'epoch': 1.52, 'step': 297}, {'eval_loss': 2.0165398120880127, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.185, 'eval_rougeL': 0.373, 'eval_sacrebleu': 9.6796, 'eval_runtime': 12.2466, 'eval_samples_per_second': 177.111, 'eval_steps_per_second': 5.553, 'epoch': 1.52, 'step': 297}, {'loss': 2.0901, 'learning_rate': 0.0002452991452991453, 'epoch': 1.53, 'step': 298}, {'eval_loss': 2.0164129734039307, 'eval_rouge1': 0.4115, 'eval_rouge2': 0.1845, 'eval_rougeL': 0.3728, 'eval_sacrebleu': 9.6398, 'eval_runtime': 11.9616, 'eval_samples_per_second': 181.33, 'eval_steps_per_second': 5.685, 'epoch': 1.53, 'step': 298}, {'loss': 2.0165, 'learning_rate': 0.00024444444444444443, 'epoch': 1.53, 'step': 299}, {'eval_loss': 2.0160622596740723, 'eval_rouge1': 0.412, 'eval_rouge2': 0.1849, 'eval_rougeL': 0.3734, 'eval_sacrebleu': 9.6676, 'eval_runtime': 12.0844, 'eval_samples_per_second': 179.487, 'eval_steps_per_second': 5.627, 'epoch': 1.53, 'step': 299}, {'loss': 2.1039, 'learning_rate': 0.0002435897435897436, 'epoch': 1.54, 'step': 300}, {'eval_loss': 2.0160953998565674, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.1846, 'eval_rougeL': 0.3732, 'eval_sacrebleu': 9.6578, 'eval_runtime': 12.1478, 'eval_samples_per_second': 178.551, 'eval_steps_per_second': 5.598, 'epoch': 1.54, 'step': 300}, {'loss': 2.0932, 'learning_rate': 0.00024273504273504274, 'epoch': 1.54, 'step': 301}, {'eval_loss': 2.0162832736968994, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1846, 'eval_rougeL': 0.3726, 'eval_sacrebleu': 9.6483, 'eval_runtime': 12.0783, 'eval_samples_per_second': 179.578, 'eval_steps_per_second': 5.63, 'epoch': 1.54, 'step': 301}, {'loss': 2.0713, 'learning_rate': 0.0002418803418803419, 'epoch': 1.55, 'step': 302}, {'eval_loss': 2.016477346420288, 'eval_rouge1': 0.4111, 'eval_rouge2': 0.1841, 'eval_rougeL': 0.3722, 'eval_sacrebleu': 9.6128, 'eval_runtime': 12.4063, 'eval_samples_per_second': 174.83, 'eval_steps_per_second': 5.481, 'epoch': 1.55, 'step': 302}, {'loss': 2.1017, 'learning_rate': 0.00024102564102564103, 'epoch': 1.55, 'step': 303}, {'eval_loss': 2.0170400142669678, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.1848, 'eval_rougeL': 0.3732, 'eval_sacrebleu': 9.6253, 'eval_runtime': 12.1951, 'eval_samples_per_second': 177.859, 'eval_steps_per_second': 5.576, 'epoch': 1.55, 'step': 303}, {'loss': 2.0555, 'learning_rate': 0.00024017094017094018, 'epoch': 1.56, 'step': 304}, {'eval_loss': 2.0175650119781494, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.1847, 'eval_rougeL': 0.3729, 'eval_sacrebleu': 9.6089, 'eval_runtime': 12.4475, 'eval_samples_per_second': 174.252, 'eval_steps_per_second': 5.463, 'epoch': 1.56, 'step': 304}, {'loss': 2.0657, 'learning_rate': 0.00023931623931623932, 'epoch': 1.56, 'step': 305}, {'eval_loss': 2.017789840698242, 'eval_rouge1': 0.4123, 'eval_rouge2': 0.1855, 'eval_rougeL': 0.3736, 'eval_sacrebleu': 9.6466, 'eval_runtime': 12.1744, 'eval_samples_per_second': 178.161, 'eval_steps_per_second': 5.585, 'epoch': 1.56, 'step': 305}, {'loss': 2.0143, 'learning_rate': 0.0002384615384615385, 'epoch': 1.57, 'step': 306}, {'eval_loss': 2.017728567123413, 'eval_rouge1': 0.412, 'eval_rouge2': 0.1856, 'eval_rougeL': 0.3735, 'eval_sacrebleu': 9.6494, 'eval_runtime': 12.0664, 'eval_samples_per_second': 179.755, 'eval_steps_per_second': 5.635, 'epoch': 1.57, 'step': 306}, {'loss': 2.0942, 'learning_rate': 0.0002376068376068376, 'epoch': 1.57, 'step': 307}, {'eval_loss': 2.0170199871063232, 'eval_rouge1': 0.4124, 'eval_rouge2': 0.186, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.6857, 'eval_runtime': 11.9478, 'eval_samples_per_second': 181.54, 'eval_steps_per_second': 5.691, 'epoch': 1.57, 'step': 307}, {'loss': 1.9689, 'learning_rate': 0.00023675213675213675, 'epoch': 1.58, 'step': 308}, {'eval_loss': 2.0163822174072266, 'eval_rouge1': 0.4133, 'eval_rouge2': 0.1867, 'eval_rougeL': 0.3747, 'eval_sacrebleu': 9.7078, 'eval_runtime': 11.8916, 'eval_samples_per_second': 182.398, 'eval_steps_per_second': 5.718, 'epoch': 1.58, 'step': 308}, {'loss': 2.1133, 'learning_rate': 0.0002358974358974359, 'epoch': 1.58, 'step': 309}, {'eval_loss': 2.0155367851257324, 'eval_rouge1': 0.4132, 'eval_rouge2': 0.1866, 'eval_rougeL': 0.3745, 'eval_sacrebleu': 9.6962, 'eval_runtime': 12.3027, 'eval_samples_per_second': 176.303, 'eval_steps_per_second': 5.527, 'epoch': 1.58, 'step': 309}, {'loss': 1.9972, 'learning_rate': 0.00023504273504273504, 'epoch': 1.59, 'step': 310}, {'eval_loss': 2.014753580093384, 'eval_rouge1': 0.4126, 'eval_rouge2': 0.1865, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.7203, 'eval_runtime': 11.9281, 'eval_samples_per_second': 181.839, 'eval_steps_per_second': 5.701, 'epoch': 1.59, 'step': 310}, {'loss': 2.0836, 'learning_rate': 0.0002341880341880342, 'epoch': 1.59, 'step': 311}, {'eval_loss': 2.0140275955200195, 'eval_rouge1': 0.4132, 'eval_rouge2': 0.1869, 'eval_rougeL': 0.3746, 'eval_sacrebleu': 9.7435, 'eval_runtime': 12.203, 'eval_samples_per_second': 177.743, 'eval_steps_per_second': 5.572, 'epoch': 1.59, 'step': 311}, {'loss': 2.0985, 'learning_rate': 0.00023333333333333333, 'epoch': 1.6, 'step': 312}, {'eval_loss': 2.013450860977173, 'eval_rouge1': 0.4122, 'eval_rouge2': 0.186, 'eval_rougeL': 0.3738, 'eval_sacrebleu': 9.7234, 'eval_runtime': 11.9441, 'eval_samples_per_second': 181.596, 'eval_steps_per_second': 5.693, 'epoch': 1.6, 'step': 312}, {'loss': 2.0694, 'learning_rate': 0.0002324786324786325, 'epoch': 1.6, 'step': 313}, {'eval_loss': 2.013051986694336, 'eval_rouge1': 0.4124, 'eval_rouge2': 0.1862, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.7161, 'eval_runtime': 11.9026, 'eval_samples_per_second': 182.23, 'eval_steps_per_second': 5.713, 'epoch': 1.6, 'step': 313}, {'loss': 2.0698, 'learning_rate': 0.00023162393162393165, 'epoch': 1.61, 'step': 314}, {'eval_loss': 2.013152837753296, 'eval_rouge1': 0.4121, 'eval_rouge2': 0.1856, 'eval_rougeL': 0.3736, 'eval_sacrebleu': 9.6809, 'eval_runtime': 11.9269, 'eval_samples_per_second': 181.858, 'eval_steps_per_second': 5.701, 'epoch': 1.61, 'step': 314}, {'loss': 2.1032, 'learning_rate': 0.0002307692307692308, 'epoch': 1.61, 'step': 315}, {'eval_loss': 2.013263702392578, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.1853, 'eval_rougeL': 0.3735, 'eval_sacrebleu': 9.673, 'eval_runtime': 11.927, 'eval_samples_per_second': 181.857, 'eval_steps_per_second': 5.701, 'epoch': 1.61, 'step': 315}, {'loss': 1.9916, 'learning_rate': 0.0002299145299145299, 'epoch': 1.62, 'step': 316}, {'eval_loss': 2.0134658813476562, 'eval_rouge1': 0.4121, 'eval_rouge2': 0.1856, 'eval_rougeL': 0.3736, 'eval_sacrebleu': 9.6596, 'eval_runtime': 12.2283, 'eval_samples_per_second': 177.376, 'eval_steps_per_second': 5.561, 'epoch': 1.62, 'step': 316}, {'loss': 2.0983, 'learning_rate': 0.00022905982905982905, 'epoch': 1.62, 'step': 317}, {'eval_loss': 2.013479471206665, 'eval_rouge1': 0.4126, 'eval_rouge2': 0.1859, 'eval_rougeL': 0.3741, 'eval_sacrebleu': 9.6003, 'eval_runtime': 11.9762, 'eval_samples_per_second': 181.109, 'eval_steps_per_second': 5.678, 'epoch': 1.62, 'step': 317}, {'loss': 2.031, 'learning_rate': 0.0002282051282051282, 'epoch': 1.63, 'step': 318}, {'eval_loss': 2.0131213665008545, 'eval_rouge1': 0.4127, 'eval_rouge2': 0.1859, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.5897, 'eval_runtime': 12.2871, 'eval_samples_per_second': 176.526, 'eval_steps_per_second': 5.534, 'epoch': 1.63, 'step': 318}, {'loss': 2.0411, 'learning_rate': 0.00022735042735042734, 'epoch': 1.63, 'step': 319}, {'eval_loss': 2.012702465057373, 'eval_rouge1': 0.4126, 'eval_rouge2': 0.186, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.5856, 'eval_runtime': 12.0588, 'eval_samples_per_second': 179.868, 'eval_steps_per_second': 5.639, 'epoch': 1.63, 'step': 319}, {'loss': 2.0039, 'learning_rate': 0.0002264957264957265, 'epoch': 1.64, 'step': 320}, {'eval_loss': 2.0123720169067383, 'eval_rouge1': 0.4121, 'eval_rouge2': 0.1859, 'eval_rougeL': 0.3735, 'eval_sacrebleu': 9.5445, 'eval_runtime': 11.951, 'eval_samples_per_second': 181.492, 'eval_steps_per_second': 5.69, 'epoch': 1.64, 'step': 320}, {'loss': 2.0342, 'learning_rate': 0.00022564102564102566, 'epoch': 1.64, 'step': 321}, {'eval_loss': 2.011702299118042, 'eval_rouge1': 0.4125, 'eval_rouge2': 0.1867, 'eval_rougeL': 0.3745, 'eval_sacrebleu': 9.6087, 'eval_runtime': 12.0197, 'eval_samples_per_second': 180.454, 'eval_steps_per_second': 5.657, 'epoch': 1.64, 'step': 321}, {'loss': 2.0031, 'learning_rate': 0.0002247863247863248, 'epoch': 1.65, 'step': 322}, {'eval_loss': 2.010918617248535, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.1864, 'eval_rougeL': 0.374, 'eval_sacrebleu': 9.6073, 'eval_runtime': 11.9608, 'eval_samples_per_second': 181.342, 'eval_steps_per_second': 5.685, 'epoch': 1.65, 'step': 322}, {'loss': 2.0601, 'learning_rate': 0.00022393162393162394, 'epoch': 1.65, 'step': 323}, {'eval_loss': 2.010085105895996, 'eval_rouge1': 0.4122, 'eval_rouge2': 0.1862, 'eval_rougeL': 0.3745, 'eval_sacrebleu': 9.614, 'eval_runtime': 12.0274, 'eval_samples_per_second': 180.339, 'eval_steps_per_second': 5.654, 'epoch': 1.65, 'step': 323}, {'loss': 2.0737, 'learning_rate': 0.0002230769230769231, 'epoch': 1.66, 'step': 324}, {'eval_loss': 2.009192705154419, 'eval_rouge1': 0.4118, 'eval_rouge2': 0.186, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.6118, 'eval_runtime': 11.7525, 'eval_samples_per_second': 184.556, 'eval_steps_per_second': 5.786, 'epoch': 1.66, 'step': 324}, {'loss': 2.0182, 'learning_rate': 0.0002222222222222222, 'epoch': 1.66, 'step': 325}, {'eval_loss': 2.008636951446533, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.1861, 'eval_rougeL': 0.3737, 'eval_sacrebleu': 9.6006, 'eval_runtime': 12.0206, 'eval_samples_per_second': 180.44, 'eval_steps_per_second': 5.657, 'epoch': 1.66, 'step': 325}, {'loss': 2.0707, 'learning_rate': 0.00022136752136752135, 'epoch': 1.67, 'step': 326}, {'eval_loss': 2.008369207382202, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1858, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.608, 'eval_runtime': 11.7388, 'eval_samples_per_second': 184.773, 'eval_steps_per_second': 5.793, 'epoch': 1.67, 'step': 326}, {'loss': 1.9876, 'learning_rate': 0.00022051282051282052, 'epoch': 1.67, 'step': 327}, {'eval_loss': 2.0081443786621094, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.186, 'eval_rougeL': 0.374, 'eval_sacrebleu': 9.6536, 'eval_runtime': 11.7436, 'eval_samples_per_second': 184.697, 'eval_steps_per_second': 5.79, 'epoch': 1.67, 'step': 327}, {'loss': 2.0129, 'learning_rate': 0.00021965811965811967, 'epoch': 1.68, 'step': 328}, {'eval_loss': 2.0082619190216064, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.1865, 'eval_rougeL': 0.374, 'eval_sacrebleu': 9.6647, 'eval_runtime': 11.9271, 'eval_samples_per_second': 181.854, 'eval_steps_per_second': 5.701, 'epoch': 1.68, 'step': 328}, {'loss': 2.0302, 'learning_rate': 0.0002188034188034188, 'epoch': 1.68, 'step': 329}, {'eval_loss': 2.0083327293395996, 'eval_rouge1': 0.412, 'eval_rouge2': 0.1869, 'eval_rougeL': 0.3741, 'eval_sacrebleu': 9.6939, 'eval_runtime': 11.9512, 'eval_samples_per_second': 181.488, 'eval_steps_per_second': 5.69, 'epoch': 1.68, 'step': 329}, {'loss': 2.0343, 'learning_rate': 0.00021794871794871795, 'epoch': 1.69, 'step': 330}, {'eval_loss': 2.00860595703125, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.1869, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.6985, 'eval_runtime': 12.2566, 'eval_samples_per_second': 176.966, 'eval_steps_per_second': 5.548, 'epoch': 1.69, 'step': 330}, {'loss': 2.0516, 'learning_rate': 0.0002170940170940171, 'epoch': 1.69, 'step': 331}, {'eval_loss': 2.0089492797851562, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.187, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.7334, 'eval_runtime': 11.9575, 'eval_samples_per_second': 181.392, 'eval_steps_per_second': 5.687, 'epoch': 1.69, 'step': 331}, {'loss': 2.0236, 'learning_rate': 0.00021623931623931624, 'epoch': 1.7, 'step': 332}, {'eval_loss': 2.009319543838501, 'eval_rouge1': 0.4115, 'eval_rouge2': 0.1867, 'eval_rougeL': 0.374, 'eval_sacrebleu': 9.7327, 'eval_runtime': 12.3083, 'eval_samples_per_second': 176.222, 'eval_steps_per_second': 5.525, 'epoch': 1.7, 'step': 332}, {'loss': 2.0247, 'learning_rate': 0.00021538461538461541, 'epoch': 1.7, 'step': 333}, {'eval_loss': 2.009676456451416, 'eval_rouge1': 0.4115, 'eval_rouge2': 0.1866, 'eval_rougeL': 0.3738, 'eval_sacrebleu': 9.7182, 'eval_runtime': 12.0731, 'eval_samples_per_second': 179.656, 'eval_steps_per_second': 5.632, 'epoch': 1.7, 'step': 333}, {'loss': 2.1005, 'learning_rate': 0.00021452991452991453, 'epoch': 1.71, 'step': 334}, {'eval_loss': 2.0101332664489746, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1867, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.7171, 'eval_runtime': 12.2416, 'eval_samples_per_second': 177.183, 'eval_steps_per_second': 5.555, 'epoch': 1.71, 'step': 334}, {'loss': 2.0838, 'learning_rate': 0.00021367521367521368, 'epoch': 1.71, 'step': 335}, {'eval_loss': 2.0108537673950195, 'eval_rouge1': 0.4115, 'eval_rouge2': 0.1866, 'eval_rougeL': 0.3734, 'eval_sacrebleu': 9.6903, 'eval_runtime': 11.9496, 'eval_samples_per_second': 181.513, 'eval_steps_per_second': 5.691, 'epoch': 1.71, 'step': 335}, {'loss': 2.0339, 'learning_rate': 0.00021282051282051282, 'epoch': 1.72, 'step': 336}, {'eval_loss': 2.01131534576416, 'eval_rouge1': 0.4119, 'eval_rouge2': 0.187, 'eval_rougeL': 0.3737, 'eval_sacrebleu': 9.7006, 'eval_runtime': 11.9459, 'eval_samples_per_second': 181.569, 'eval_steps_per_second': 5.692, 'epoch': 1.72, 'step': 336}, {'loss': 2.0692, 'learning_rate': 0.00021196581196581196, 'epoch': 1.72, 'step': 337}, {'eval_loss': 2.0115232467651367, 'eval_rouge1': 0.4118, 'eval_rouge2': 0.1869, 'eval_rougeL': 0.3736, 'eval_sacrebleu': 9.7165, 'eval_runtime': 12.0051, 'eval_samples_per_second': 180.674, 'eval_steps_per_second': 5.664, 'epoch': 1.72, 'step': 337}, {'loss': 2.0531, 'learning_rate': 0.0002111111111111111, 'epoch': 1.73, 'step': 338}, {'eval_loss': 2.0112245082855225, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1871, 'eval_rougeL': 0.3737, 'eval_sacrebleu': 9.7172, 'eval_runtime': 11.9009, 'eval_samples_per_second': 182.256, 'eval_steps_per_second': 5.714, 'epoch': 1.73, 'step': 338}, {'loss': 2.0125, 'learning_rate': 0.00021025641025641025, 'epoch': 1.74, 'step': 339}, {'eval_loss': 2.0106842517852783, 'eval_rouge1': 0.4121, 'eval_rouge2': 0.1869, 'eval_rougeL': 0.3741, 'eval_sacrebleu': 9.712, 'eval_runtime': 12.2904, 'eval_samples_per_second': 176.479, 'eval_steps_per_second': 5.533, 'epoch': 1.74, 'step': 339}, {'loss': 2.0784, 'learning_rate': 0.00020940170940170942, 'epoch': 1.74, 'step': 340}, {'eval_loss': 2.010175943374634, 'eval_rouge1': 0.4125, 'eval_rouge2': 0.1871, 'eval_rougeL': 0.3743, 'eval_sacrebleu': 9.7144, 'eval_runtime': 12.0019, 'eval_samples_per_second': 180.721, 'eval_steps_per_second': 5.666, 'epoch': 1.74, 'step': 340}, {'loss': 2.0536, 'learning_rate': 0.00020854700854700857, 'epoch': 1.75, 'step': 341}, {'eval_loss': 2.00956130027771, 'eval_rouge1': 0.413, 'eval_rouge2': 0.1871, 'eval_rougeL': 0.3745, 'eval_sacrebleu': 9.6983, 'eval_runtime': 12.2462, 'eval_samples_per_second': 177.117, 'eval_steps_per_second': 5.553, 'epoch': 1.75, 'step': 341}, {'loss': 2.1015, 'learning_rate': 0.0002076923076923077, 'epoch': 1.75, 'step': 342}, {'eval_loss': 2.0087177753448486, 'eval_rouge1': 0.413, 'eval_rouge2': 0.1872, 'eval_rougeL': 0.3747, 'eval_sacrebleu': 9.7282, 'eval_runtime': 11.9807, 'eval_samples_per_second': 181.041, 'eval_steps_per_second': 5.676, 'epoch': 1.75, 'step': 342}, {'loss': 1.9754, 'learning_rate': 0.00020683760683760683, 'epoch': 1.76, 'step': 343}, {'eval_loss': 2.008082628250122, 'eval_rouge1': 0.4137, 'eval_rouge2': 0.188, 'eval_rougeL': 0.3756, 'eval_sacrebleu': 9.7848, 'eval_runtime': 12.2434, 'eval_samples_per_second': 177.156, 'eval_steps_per_second': 5.554, 'epoch': 1.76, 'step': 343}, {'loss': 1.9643, 'learning_rate': 0.00020598290598290597, 'epoch': 1.76, 'step': 344}, {'eval_loss': 2.007499933242798, 'eval_rouge1': 0.4136, 'eval_rouge2': 0.1885, 'eval_rougeL': 0.3758, 'eval_sacrebleu': 9.7947, 'eval_runtime': 11.9455, 'eval_samples_per_second': 181.574, 'eval_steps_per_second': 5.693, 'epoch': 1.76, 'step': 344}, {'loss': 2.0712, 'learning_rate': 0.00020512820512820512, 'epoch': 1.77, 'step': 345}, {'eval_loss': 2.007044792175293, 'eval_rouge1': 0.4134, 'eval_rouge2': 0.1884, 'eval_rougeL': 0.3752, 'eval_sacrebleu': 9.8108, 'eval_runtime': 11.9567, 'eval_samples_per_second': 181.405, 'eval_steps_per_second': 5.687, 'epoch': 1.77, 'step': 345}, {'loss': 2.0623, 'learning_rate': 0.00020427350427350426, 'epoch': 1.77, 'step': 346}, {'eval_loss': 2.0067138671875, 'eval_rouge1': 0.4134, 'eval_rouge2': 0.188, 'eval_rougeL': 0.3749, 'eval_sacrebleu': 9.7814, 'eval_runtime': 12.4826, 'eval_samples_per_second': 173.762, 'eval_steps_per_second': 5.448, 'epoch': 1.77, 'step': 346}, {'loss': 2.0299, 'learning_rate': 0.00020341880341880343, 'epoch': 1.78, 'step': 347}, {'eval_loss': 2.0067923069000244, 'eval_rouge1': 0.4133, 'eval_rouge2': 0.1878, 'eval_rougeL': 0.3749, 'eval_sacrebleu': 9.7689, 'eval_runtime': 12.0156, 'eval_samples_per_second': 180.515, 'eval_steps_per_second': 5.659, 'epoch': 1.78, 'step': 347}, {'loss': 1.96, 'learning_rate': 0.00020256410256410258, 'epoch': 1.78, 'step': 348}, {'eval_loss': 2.0071232318878174, 'eval_rouge1': 0.4133, 'eval_rouge2': 0.1877, 'eval_rougeL': 0.375, 'eval_sacrebleu': 9.7626, 'eval_runtime': 12.5577, 'eval_samples_per_second': 172.723, 'eval_steps_per_second': 5.415, 'epoch': 1.78, 'step': 348}, {'loss': 2.025, 'learning_rate': 0.00020170940170940172, 'epoch': 1.79, 'step': 349}, {'eval_loss': 2.0072743892669678, 'eval_rouge1': 0.4141, 'eval_rouge2': 0.1886, 'eval_rougeL': 0.3756, 'eval_sacrebleu': 9.834, 'eval_runtime': 12.1732, 'eval_samples_per_second': 178.178, 'eval_steps_per_second': 5.586, 'epoch': 1.79, 'step': 349}, {'loss': 2.0185, 'learning_rate': 0.00020085470085470087, 'epoch': 1.79, 'step': 350}, {'eval_loss': 2.0072083473205566, 'eval_rouge1': 0.4133, 'eval_rouge2': 0.188, 'eval_rougeL': 0.3748, 'eval_sacrebleu': 9.7882, 'eval_runtime': 12.3486, 'eval_samples_per_second': 175.648, 'eval_steps_per_second': 5.507, 'epoch': 1.79, 'step': 350}, {'loss': 2.017, 'learning_rate': 0.0002, 'epoch': 1.8, 'step': 351}, {'eval_loss': 2.006641387939453, 'eval_rouge1': 0.4143, 'eval_rouge2': 0.1889, 'eval_rougeL': 0.3759, 'eval_sacrebleu': 9.8056, 'eval_runtime': 12.0105, 'eval_samples_per_second': 180.592, 'eval_steps_per_second': 5.662, 'epoch': 1.8, 'step': 351}, {'loss': 2.0158, 'learning_rate': 0.00019914529914529913, 'epoch': 1.8, 'step': 352}, {'eval_loss': 2.005812883377075, 'eval_rouge1': 0.4141, 'eval_rouge2': 0.1884, 'eval_rougeL': 0.3757, 'eval_sacrebleu': 9.7957, 'eval_runtime': 11.9981, 'eval_samples_per_second': 180.779, 'eval_steps_per_second': 5.668, 'epoch': 1.8, 'step': 352}, {'loss': 1.9678, 'learning_rate': 0.00019829059829059827, 'epoch': 1.81, 'step': 353}, {'eval_loss': 2.0051803588867188, 'eval_rouge1': 0.4141, 'eval_rouge2': 0.1884, 'eval_rougeL': 0.3759, 'eval_sacrebleu': 9.8284, 'eval_runtime': 12.2996, 'eval_samples_per_second': 176.347, 'eval_steps_per_second': 5.529, 'epoch': 1.81, 'step': 353}, {'loss': 1.9785, 'learning_rate': 0.00019743589743589744, 'epoch': 1.81, 'step': 354}, {'eval_loss': 2.004650592803955, 'eval_rouge1': 0.4142, 'eval_rouge2': 0.1883, 'eval_rougeL': 0.376, 'eval_sacrebleu': 9.8446, 'eval_runtime': 12.0166, 'eval_samples_per_second': 180.501, 'eval_steps_per_second': 5.659, 'epoch': 1.81, 'step': 354}, {'loss': 2.0791, 'learning_rate': 0.00019658119658119659, 'epoch': 1.82, 'step': 355}, {'eval_loss': 2.0039889812469482, 'eval_rouge1': 0.4138, 'eval_rouge2': 0.1884, 'eval_rougeL': 0.3757, 'eval_sacrebleu': 9.8738, 'eval_runtime': 12.3617, 'eval_samples_per_second': 175.461, 'eval_steps_per_second': 5.501, 'epoch': 1.82, 'step': 355}, {'loss': 1.9397, 'learning_rate': 0.00019572649572649573, 'epoch': 1.82, 'step': 356}, {'eval_loss': 2.0032100677490234, 'eval_rouge1': 0.4138, 'eval_rouge2': 0.1885, 'eval_rougeL': 0.3758, 'eval_sacrebleu': 9.8838, 'eval_runtime': 12.1224, 'eval_samples_per_second': 178.926, 'eval_steps_per_second': 5.609, 'epoch': 1.82, 'step': 356}, {'loss': 2.0118, 'learning_rate': 0.00019487179487179487, 'epoch': 1.83, 'step': 357}, {'eval_loss': 2.0026493072509766, 'eval_rouge1': 0.4143, 'eval_rouge2': 0.1885, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 9.9108, 'eval_runtime': 12.3694, 'eval_samples_per_second': 175.352, 'eval_steps_per_second': 5.497, 'epoch': 1.83, 'step': 357}, {'loss': 2.0903, 'learning_rate': 0.00019401709401709402, 'epoch': 1.83, 'step': 358}, {'eval_loss': 2.002161741256714, 'eval_rouge1': 0.4141, 'eval_rouge2': 0.1883, 'eval_rougeL': 0.3758, 'eval_sacrebleu': 9.8711, 'eval_runtime': 12.1756, 'eval_samples_per_second': 178.144, 'eval_steps_per_second': 5.585, 'epoch': 1.83, 'step': 358}, {'loss': 2.1021, 'learning_rate': 0.00019316239316239316, 'epoch': 1.84, 'step': 359}, {'eval_loss': 2.0019853115081787, 'eval_rouge1': 0.4135, 'eval_rouge2': 0.1886, 'eval_rougeL': 0.3759, 'eval_sacrebleu': 9.905, 'eval_runtime': 12.019, 'eval_samples_per_second': 180.464, 'eval_steps_per_second': 5.658, 'epoch': 1.84, 'step': 359}, {'loss': 2.0502, 'learning_rate': 0.00019230769230769233, 'epoch': 1.84, 'step': 360}, {'eval_loss': 2.001755952835083, 'eval_rouge1': 0.4137, 'eval_rouge2': 0.1888, 'eval_rougeL': 0.3761, 'eval_sacrebleu': 9.9047, 'eval_runtime': 12.1594, 'eval_samples_per_second': 178.381, 'eval_steps_per_second': 5.592, 'epoch': 1.84, 'step': 360}, {'loss': 2.0218, 'learning_rate': 0.00019145299145299148, 'epoch': 1.85, 'step': 361}, {'eval_loss': 2.001688003540039, 'eval_rouge1': 0.4142, 'eval_rouge2': 0.1888, 'eval_rougeL': 0.3767, 'eval_sacrebleu': 9.9118, 'eval_runtime': 12.0528, 'eval_samples_per_second': 179.958, 'eval_steps_per_second': 5.642, 'epoch': 1.85, 'step': 361}, {'loss': 2.0059, 'learning_rate': 0.0001905982905982906, 'epoch': 1.85, 'step': 362}, {'eval_loss': 2.001878023147583, 'eval_rouge1': 0.4143, 'eval_rouge2': 0.1887, 'eval_rougeL': 0.3768, 'eval_sacrebleu': 9.9133, 'eval_runtime': 12.3012, 'eval_samples_per_second': 176.324, 'eval_steps_per_second': 5.528, 'epoch': 1.85, 'step': 362}, {'loss': 1.9605, 'learning_rate': 0.00018974358974358974, 'epoch': 1.86, 'step': 363}, {'eval_loss': 2.002270460128784, 'eval_rouge1': 0.4142, 'eval_rouge2': 0.1884, 'eval_rougeL': 0.3767, 'eval_sacrebleu': 9.8884, 'eval_runtime': 12.0197, 'eval_samples_per_second': 180.453, 'eval_steps_per_second': 5.657, 'epoch': 1.86, 'step': 363}, {'loss': 2.084, 'learning_rate': 0.00018888888888888888, 'epoch': 1.86, 'step': 364}, {'eval_loss': 2.002722978591919, 'eval_rouge1': 0.414, 'eval_rouge2': 0.1889, 'eval_rougeL': 0.3764, 'eval_sacrebleu': 9.8942, 'eval_runtime': 12.2891, 'eval_samples_per_second': 176.498, 'eval_steps_per_second': 5.533, 'epoch': 1.86, 'step': 364}, {'loss': 2.0116, 'learning_rate': 0.00018803418803418803, 'epoch': 1.87, 'step': 365}, {'eval_loss': 2.0033159255981445, 'eval_rouge1': 0.4138, 'eval_rouge2': 0.1888, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 9.8848, 'eval_runtime': 12.1331, 'eval_samples_per_second': 178.767, 'eval_steps_per_second': 5.604, 'epoch': 1.87, 'step': 365}, {'loss': 2.013, 'learning_rate': 0.00018717948717948717, 'epoch': 1.87, 'step': 366}, {'eval_loss': 2.003716468811035, 'eval_rouge1': 0.4135, 'eval_rouge2': 0.1887, 'eval_rougeL': 0.3757, 'eval_sacrebleu': 9.8744, 'eval_runtime': 11.9749, 'eval_samples_per_second': 181.129, 'eval_steps_per_second': 5.679, 'epoch': 1.87, 'step': 366}, {'loss': 2.0101, 'learning_rate': 0.00018632478632478634, 'epoch': 1.88, 'step': 367}, {'eval_loss': 2.003833293914795, 'eval_rouge1': 0.4137, 'eval_rouge2': 0.1885, 'eval_rougeL': 0.3756, 'eval_sacrebleu': 9.8433, 'eval_runtime': 11.77, 'eval_samples_per_second': 184.282, 'eval_steps_per_second': 5.777, 'epoch': 1.88, 'step': 367}, {'loss': 2.1318, 'learning_rate': 0.0001854700854700855, 'epoch': 1.88, 'step': 368}, {'eval_loss': 2.00396990776062, 'eval_rouge1': 0.4138, 'eval_rouge2': 0.1888, 'eval_rougeL': 0.3758, 'eval_sacrebleu': 9.8644, 'eval_runtime': 11.7446, 'eval_samples_per_second': 184.681, 'eval_steps_per_second': 5.79, 'epoch': 1.88, 'step': 368}, {'loss': 2.0124, 'learning_rate': 0.00018461538461538463, 'epoch': 1.89, 'step': 369}, {'eval_loss': 2.003636598587036, 'eval_rouge1': 0.4139, 'eval_rouge2': 0.1887, 'eval_rougeL': 0.3759, 'eval_sacrebleu': 9.87, 'eval_runtime': 12.111, 'eval_samples_per_second': 179.093, 'eval_steps_per_second': 5.615, 'epoch': 1.89, 'step': 369}, {'loss': 2.1059, 'learning_rate': 0.00018376068376068378, 'epoch': 1.89, 'step': 370}, {'eval_loss': 2.0034046173095703, 'eval_rouge1': 0.413, 'eval_rouge2': 0.188, 'eval_rougeL': 0.375, 'eval_sacrebleu': 9.8212, 'eval_runtime': 11.8672, 'eval_samples_per_second': 182.772, 'eval_steps_per_second': 5.73, 'epoch': 1.89, 'step': 370}, {'loss': 2.0832, 'learning_rate': 0.0001829059829059829, 'epoch': 1.9, 'step': 371}, {'eval_loss': 2.0031182765960693, 'eval_rouge1': 0.4125, 'eval_rouge2': 0.1879, 'eval_rougeL': 0.3746, 'eval_sacrebleu': 9.8257, 'eval_runtime': 12.325, 'eval_samples_per_second': 175.984, 'eval_steps_per_second': 5.517, 'epoch': 1.9, 'step': 371}, {'loss': 2.0243, 'learning_rate': 0.00018205128205128204, 'epoch': 1.9, 'step': 372}, {'eval_loss': 2.0028975009918213, 'eval_rouge1': 0.4122, 'eval_rouge2': 0.1877, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.8094, 'eval_runtime': 11.9977, 'eval_samples_per_second': 180.785, 'eval_steps_per_second': 5.668, 'epoch': 1.9, 'step': 372}, {'loss': 2.0096, 'learning_rate': 0.00018119658119658118, 'epoch': 1.91, 'step': 373}, {'eval_loss': 2.0027167797088623, 'eval_rouge1': 0.4117, 'eval_rouge2': 0.1874, 'eval_rougeL': 0.3738, 'eval_sacrebleu': 9.8217, 'eval_runtime': 11.998, 'eval_samples_per_second': 180.781, 'eval_steps_per_second': 5.668, 'epoch': 1.91, 'step': 373}, {'loss': 2.0088, 'learning_rate': 0.00018034188034188035, 'epoch': 1.91, 'step': 374}, {'eval_loss': 2.0025641918182373, 'eval_rouge1': 0.4115, 'eval_rouge2': 0.1874, 'eval_rougeL': 0.3739, 'eval_sacrebleu': 9.8393, 'eval_runtime': 12.0053, 'eval_samples_per_second': 180.671, 'eval_steps_per_second': 5.664, 'epoch': 1.91, 'step': 374}, {'loss': 1.9903, 'learning_rate': 0.0001794871794871795, 'epoch': 1.92, 'step': 375}, {'eval_loss': 2.002328634262085, 'eval_rouge1': 0.4114, 'eval_rouge2': 0.1874, 'eval_rougeL': 0.3735, 'eval_sacrebleu': 9.8537, 'eval_runtime': 11.942, 'eval_samples_per_second': 181.629, 'eval_steps_per_second': 5.694, 'epoch': 1.92, 'step': 375}, {'loss': 2.0838, 'learning_rate': 0.00017863247863247864, 'epoch': 1.92, 'step': 376}, {'eval_loss': 2.0024046897888184, 'eval_rouge1': 0.4112, 'eval_rouge2': 0.1869, 'eval_rougeL': 0.3733, 'eval_sacrebleu': 9.8361, 'eval_runtime': 12.3011, 'eval_samples_per_second': 176.326, 'eval_steps_per_second': 5.528, 'epoch': 1.92, 'step': 376}, {'loss': 2.0866, 'learning_rate': 0.00017777777777777779, 'epoch': 1.93, 'step': 377}, {'eval_loss': 2.002419948577881, 'eval_rouge1': 0.4109, 'eval_rouge2': 0.1871, 'eval_rougeL': 0.3733, 'eval_sacrebleu': 9.8465, 'eval_runtime': 11.941, 'eval_samples_per_second': 181.643, 'eval_steps_per_second': 5.695, 'epoch': 1.93, 'step': 377}, {'loss': 2.001, 'learning_rate': 0.00017692307692307693, 'epoch': 1.93, 'step': 378}, {'eval_loss': 2.002436637878418, 'eval_rouge1': 0.4113, 'eval_rouge2': 0.1871, 'eval_rougeL': 0.3734, 'eval_sacrebleu': 9.8274, 'eval_runtime': 12.2769, 'eval_samples_per_second': 176.674, 'eval_steps_per_second': 5.539, 'epoch': 1.93, 'step': 378}, {'loss': 2.0322, 'learning_rate': 0.00017606837606837607, 'epoch': 1.94, 'step': 379}, {'eval_loss': 2.002443790435791, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1875, 'eval_rougeL': 0.3738, 'eval_sacrebleu': 9.8526, 'eval_runtime': 11.9833, 'eval_samples_per_second': 181.001, 'eval_steps_per_second': 5.675, 'epoch': 1.94, 'step': 379}, {'loss': 2.0308, 'learning_rate': 0.00017521367521367522, 'epoch': 1.94, 'step': 380}, {'eval_loss': 2.0025811195373535, 'eval_rouge1': 0.4116, 'eval_rouge2': 0.1875, 'eval_rougeL': 0.3737, 'eval_sacrebleu': 9.8168, 'eval_runtime': 11.9493, 'eval_samples_per_second': 181.517, 'eval_steps_per_second': 5.691, 'epoch': 1.94, 'step': 380}, {'loss': 2.0358, 'learning_rate': 0.00017435897435897436, 'epoch': 1.95, 'step': 381}, {'eval_loss': 2.002528190612793, 'eval_rouge1': 0.4118, 'eval_rouge2': 0.1872, 'eval_rougeL': 0.3738, 'eval_sacrebleu': 9.8116, 'eval_runtime': 11.9747, 'eval_samples_per_second': 181.132, 'eval_steps_per_second': 5.679, 'epoch': 1.95, 'step': 381}, {'loss': 1.9996, 'learning_rate': 0.0001735042735042735, 'epoch': 1.96, 'step': 382}, {'eval_loss': 2.0027225017547607, 'eval_rouge1': 0.412, 'eval_rouge2': 0.188, 'eval_rougeL': 0.3741, 'eval_sacrebleu': 9.8373, 'eval_runtime': 11.9959, 'eval_samples_per_second': 180.812, 'eval_steps_per_second': 5.669, 'epoch': 1.96, 'step': 382}, {'loss': 2.0772, 'learning_rate': 0.00017264957264957265, 'epoch': 1.96, 'step': 383}, {'eval_loss': 2.0028061866760254, 'eval_rouge1': 0.4125, 'eval_rouge2': 0.1883, 'eval_rougeL': 0.3744, 'eval_sacrebleu': 9.8403, 'eval_runtime': 12.3454, 'eval_samples_per_second': 175.693, 'eval_steps_per_second': 5.508, 'epoch': 1.96, 'step': 383}, {'loss': 2.0627, 'learning_rate': 0.0001717948717948718, 'epoch': 1.97, 'step': 384}, {'eval_loss': 2.0029900074005127, 'eval_rouge1': 0.413, 'eval_rouge2': 0.1885, 'eval_rougeL': 0.3747, 'eval_sacrebleu': 9.8566, 'eval_runtime': 12.0065, 'eval_samples_per_second': 180.653, 'eval_steps_per_second': 5.664, 'epoch': 1.97, 'step': 384}, {'loss': 2.0737, 'learning_rate': 0.00017094017094017094, 'epoch': 1.97, 'step': 385}, {'eval_loss': 2.003089189529419, 'eval_rouge1': 0.4132, 'eval_rouge2': 0.1886, 'eval_rougeL': 0.3748, 'eval_sacrebleu': 9.8763, 'eval_runtime': 12.2438, 'eval_samples_per_second': 177.151, 'eval_steps_per_second': 5.554, 'epoch': 1.97, 'step': 385}, {'loss': 2.0463, 'learning_rate': 0.00017008547008547008, 'epoch': 1.98, 'step': 386}, {'eval_loss': 2.003303050994873, 'eval_rouge1': 0.4127, 'eval_rouge2': 0.1884, 'eval_rougeL': 0.374, 'eval_sacrebleu': 9.8344, 'eval_runtime': 11.9985, 'eval_samples_per_second': 180.773, 'eval_steps_per_second': 5.667, 'epoch': 1.98, 'step': 386}, {'loss': 2.0455, 'learning_rate': 0.00016923076923076926, 'epoch': 1.98, 'step': 387}, {'eval_loss': 2.003264904022217, 'eval_rouge1': 0.4128, 'eval_rouge2': 0.1882, 'eval_rougeL': 0.3742, 'eval_sacrebleu': 9.8416, 'eval_runtime': 12.0102, 'eval_samples_per_second': 180.596, 'eval_steps_per_second': 5.662, 'epoch': 1.98, 'step': 387}, {'loss': 2.009, 'learning_rate': 0.0001683760683760684, 'epoch': 1.99, 'step': 388}, {'eval_loss': 2.002660036087036, 'eval_rouge1': 0.4131, 'eval_rouge2': 0.1886, 'eval_rougeL': 0.3743, 'eval_sacrebleu': 9.881, 'eval_runtime': 12.0202, 'eval_samples_per_second': 180.447, 'eval_steps_per_second': 5.657, 'epoch': 1.99, 'step': 388}, {'loss': 1.9738, 'learning_rate': 0.00016752136752136752, 'epoch': 1.99, 'step': 389}, {'eval_loss': 2.0017361640930176, 'eval_rouge1': 0.4138, 'eval_rouge2': 0.1893, 'eval_rougeL': 0.3752, 'eval_sacrebleu': 9.9134, 'eval_runtime': 12.0017, 'eval_samples_per_second': 180.724, 'eval_steps_per_second': 5.666, 'epoch': 1.99, 'step': 389}, {'loss': 2.0458, 'learning_rate': 0.00016666666666666666, 'epoch': 2.0, 'step': 390}, {'eval_loss': 2.0008857250213623, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1897, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 9.9496, 'eval_runtime': 12.349, 'eval_samples_per_second': 175.642, 'eval_steps_per_second': 5.507, 'epoch': 2.0, 'step': 390}, {'loss': 2.0486, 'learning_rate': 0.0001658119658119658, 'epoch': 2.0, 'step': 391}, {'eval_loss': 1.9998725652694702, 'eval_rouge1': 0.4146, 'eval_rouge2': 0.1898, 'eval_rougeL': 0.3761, 'eval_sacrebleu': 9.9417, 'eval_runtime': 11.9612, 'eval_samples_per_second': 181.337, 'eval_steps_per_second': 5.685, 'epoch': 2.0, 'step': 391}, {'loss': 2.0291, 'learning_rate': 0.00016495726495726495, 'epoch': 2.01, 'step': 392}, {'eval_loss': 1.9990864992141724, 'eval_rouge1': 0.4144, 'eval_rouge2': 0.19, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 9.948, 'eval_runtime': 12.3197, 'eval_samples_per_second': 176.059, 'eval_steps_per_second': 5.52, 'epoch': 2.01, 'step': 392}, {'loss': 1.9807, 'learning_rate': 0.0001641025641025641, 'epoch': 2.01, 'step': 393}, {'eval_loss': 1.9985871315002441, 'eval_rouge1': 0.4146, 'eval_rouge2': 0.1899, 'eval_rougeL': 0.3761, 'eval_sacrebleu': 9.9481, 'eval_runtime': 11.973, 'eval_samples_per_second': 181.158, 'eval_steps_per_second': 5.679, 'epoch': 2.01, 'step': 393}, {'loss': 1.9529, 'learning_rate': 0.00016324786324786327, 'epoch': 2.02, 'step': 394}, {'eval_loss': 1.9984056949615479, 'eval_rouge1': 0.4149, 'eval_rouge2': 0.19, 'eval_rougeL': 0.3767, 'eval_sacrebleu': 9.9437, 'eval_runtime': 12.2661, 'eval_samples_per_second': 176.828, 'eval_steps_per_second': 5.544, 'epoch': 2.02, 'step': 394}, {'loss': 1.9909, 'learning_rate': 0.0001623931623931624, 'epoch': 2.02, 'step': 395}, {'eval_loss': 1.9982296228408813, 'eval_rouge1': 0.4151, 'eval_rouge2': 0.1895, 'eval_rougeL': 0.377, 'eval_sacrebleu': 9.929, 'eval_runtime': 11.9532, 'eval_samples_per_second': 181.458, 'eval_steps_per_second': 5.689, 'epoch': 2.02, 'step': 395}, {'loss': 1.9887, 'learning_rate': 0.00016153846153846155, 'epoch': 2.03, 'step': 396}, {'eval_loss': 1.9983066320419312, 'eval_rouge1': 0.4159, 'eval_rouge2': 0.1904, 'eval_rougeL': 0.378, 'eval_sacrebleu': 9.934, 'eval_runtime': 12.0375, 'eval_samples_per_second': 180.187, 'eval_steps_per_second': 5.649, 'epoch': 2.03, 'step': 396}, {'loss': 2.0721, 'learning_rate': 0.0001606837606837607, 'epoch': 2.03, 'step': 397}, {'eval_loss': 1.9985095262527466, 'eval_rouge1': 0.4162, 'eval_rouge2': 0.1904, 'eval_rougeL': 0.3779, 'eval_sacrebleu': 9.9202, 'eval_runtime': 12.0245, 'eval_samples_per_second': 180.381, 'eval_steps_per_second': 5.655, 'epoch': 2.03, 'step': 397}, {'loss': 1.9982, 'learning_rate': 0.00015982905982905981, 'epoch': 2.04, 'step': 398}, {'eval_loss': 1.9988744258880615, 'eval_rouge1': 0.4164, 'eval_rouge2': 0.1906, 'eval_rougeL': 0.378, 'eval_sacrebleu': 9.9238, 'eval_runtime': 12.003, 'eval_samples_per_second': 180.704, 'eval_steps_per_second': 5.665, 'epoch': 2.04, 'step': 398}, {'loss': 1.9823, 'learning_rate': 0.00015897435897435896, 'epoch': 2.04, 'step': 399}, {'eval_loss': 1.9992948770523071, 'eval_rouge1': 0.4165, 'eval_rouge2': 0.1906, 'eval_rougeL': 0.3778, 'eval_sacrebleu': 9.9526, 'eval_runtime': 12.2303, 'eval_samples_per_second': 177.347, 'eval_steps_per_second': 5.56, 'epoch': 2.04, 'step': 399}, {'loss': 2.0209, 'learning_rate': 0.0001581196581196581, 'epoch': 2.05, 'step': 400}, {'eval_loss': 1.9996832609176636, 'eval_rouge1': 0.4166, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.378, 'eval_sacrebleu': 9.94, 'eval_runtime': 11.8482, 'eval_samples_per_second': 183.066, 'eval_steps_per_second': 5.739, 'epoch': 2.05, 'step': 400}, {'loss': 1.967, 'learning_rate': 0.00015726495726495727, 'epoch': 2.05, 'step': 401}, {'eval_loss': 2.0002939701080322, 'eval_rouge1': 0.416, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3777, 'eval_sacrebleu': 9.9064, 'eval_runtime': 12.1289, 'eval_samples_per_second': 178.83, 'eval_steps_per_second': 5.606, 'epoch': 2.05, 'step': 401}, {'loss': 1.914, 'learning_rate': 0.00015641025641025642, 'epoch': 2.06, 'step': 402}, {'eval_loss': 2.000849962234497, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1901, 'eval_rougeL': 0.3769, 'eval_sacrebleu': 9.8666, 'eval_runtime': 11.99, 'eval_samples_per_second': 180.901, 'eval_steps_per_second': 5.671, 'epoch': 2.06, 'step': 402}, {'loss': 2.0585, 'learning_rate': 0.00015555555555555556, 'epoch': 2.06, 'step': 403}, {'eval_loss': 2.0013773441314697, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1903, 'eval_rougeL': 0.3771, 'eval_sacrebleu': 9.8878, 'eval_runtime': 12.2807, 'eval_samples_per_second': 176.618, 'eval_steps_per_second': 5.537, 'epoch': 2.06, 'step': 403}, {'loss': 1.9474, 'learning_rate': 0.0001547008547008547, 'epoch': 2.07, 'step': 404}, {'eval_loss': 2.001887798309326, 'eval_rouge1': 0.4154, 'eval_rouge2': 0.1902, 'eval_rougeL': 0.3768, 'eval_sacrebleu': 9.8938, 'eval_runtime': 11.9873, 'eval_samples_per_second': 180.942, 'eval_steps_per_second': 5.673, 'epoch': 2.07, 'step': 404}, {'loss': 1.965, 'learning_rate': 0.00015384615384615385, 'epoch': 2.07, 'step': 405}, {'eval_loss': 2.0021634101867676, 'eval_rouge1': 0.4151, 'eval_rouge2': 0.1903, 'eval_rougeL': 0.3767, 'eval_sacrebleu': 9.9017, 'eval_runtime': 12.2832, 'eval_samples_per_second': 176.583, 'eval_steps_per_second': 5.536, 'epoch': 2.07, 'step': 405}, {'loss': 2.0317, 'learning_rate': 0.000152991452991453, 'epoch': 2.08, 'step': 406}, {'eval_loss': 2.002593517303467, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1901, 'eval_rougeL': 0.3765, 'eval_sacrebleu': 9.8967, 'eval_runtime': 11.8409, 'eval_samples_per_second': 183.178, 'eval_steps_per_second': 5.743, 'epoch': 2.08, 'step': 406}, {'loss': 1.9474, 'learning_rate': 0.00015213675213675214, 'epoch': 2.08, 'step': 407}, {'eval_loss': 2.0029566287994385, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1899, 'eval_rougeL': 0.3763, 'eval_sacrebleu': 9.8913, 'eval_runtime': 11.8898, 'eval_samples_per_second': 182.425, 'eval_steps_per_second': 5.719, 'epoch': 2.08, 'step': 407}, {'loss': 2.0319, 'learning_rate': 0.00015128205128205128, 'epoch': 2.09, 'step': 408}, {'eval_loss': 2.0029525756835938, 'eval_rouge1': 0.4143, 'eval_rouge2': 0.1893, 'eval_rougeL': 0.3757, 'eval_sacrebleu': 9.8922, 'eval_runtime': 12.1087, 'eval_samples_per_second': 179.128, 'eval_steps_per_second': 5.616, 'epoch': 2.09, 'step': 408}, {'loss': 1.9365, 'learning_rate': 0.00015042735042735043, 'epoch': 2.09, 'step': 409}, {'eval_loss': 2.0030109882354736, 'eval_rouge1': 0.4144, 'eval_rouge2': 0.1893, 'eval_rougeL': 0.3758, 'eval_sacrebleu': 9.8923, 'eval_runtime': 11.8065, 'eval_samples_per_second': 183.712, 'eval_steps_per_second': 5.76, 'epoch': 2.09, 'step': 409}, {'loss': 1.9616, 'learning_rate': 0.00014957264957264957, 'epoch': 2.1, 'step': 410}, {'eval_loss': 2.0030019283294678, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1893, 'eval_rougeL': 0.3761, 'eval_sacrebleu': 9.9028, 'eval_runtime': 12.2103, 'eval_samples_per_second': 177.638, 'eval_steps_per_second': 5.569, 'epoch': 2.1, 'step': 410}, {'loss': 1.9855, 'learning_rate': 0.00014871794871794872, 'epoch': 2.1, 'step': 411}, {'eval_loss': 2.0027709007263184, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1892, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 9.8982, 'eval_runtime': 12.0712, 'eval_samples_per_second': 179.684, 'eval_steps_per_second': 5.633, 'epoch': 2.1, 'step': 411}, {'loss': 1.984, 'learning_rate': 0.00014786324786324786, 'epoch': 2.11, 'step': 412}, {'eval_loss': 2.0026652812957764, 'eval_rouge1': 0.4143, 'eval_rouge2': 0.189, 'eval_rougeL': 0.3758, 'eval_sacrebleu': 9.8702, 'eval_runtime': 12.0539, 'eval_samples_per_second': 179.942, 'eval_steps_per_second': 5.641, 'epoch': 2.11, 'step': 412}, {'loss': 2.0488, 'learning_rate': 0.000147008547008547, 'epoch': 2.11, 'step': 413}, {'eval_loss': 2.002394914627075, 'eval_rouge1': 0.4146, 'eval_rouge2': 0.1895, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 9.9151, 'eval_runtime': 12.0008, 'eval_samples_per_second': 180.738, 'eval_steps_per_second': 5.666, 'epoch': 2.11, 'step': 413}, {'loss': 2.0388, 'learning_rate': 0.00014615384615384618, 'epoch': 2.12, 'step': 414}, {'eval_loss': 2.0021474361419678, 'eval_rouge1': 0.4141, 'eval_rouge2': 0.1892, 'eval_rougeL': 0.3757, 'eval_sacrebleu': 9.884, 'eval_runtime': 12.023, 'eval_samples_per_second': 180.404, 'eval_steps_per_second': 5.656, 'epoch': 2.12, 'step': 414}, {'loss': 2.0701, 'learning_rate': 0.00014529914529914532, 'epoch': 2.12, 'step': 415}, {'eval_loss': 2.0017762184143066, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1896, 'eval_rougeL': 0.376, 'eval_sacrebleu': 9.9035, 'eval_runtime': 12.3341, 'eval_samples_per_second': 175.854, 'eval_steps_per_second': 5.513, 'epoch': 2.12, 'step': 415}, {'loss': 1.9428, 'learning_rate': 0.00014444444444444444, 'epoch': 2.13, 'step': 416}, {'eval_loss': 2.0017337799072266, 'eval_rouge1': 0.415, 'eval_rouge2': 0.1901, 'eval_rougeL': 0.3763, 'eval_sacrebleu': 9.9627, 'eval_runtime': 12.0108, 'eval_samples_per_second': 180.587, 'eval_steps_per_second': 5.662, 'epoch': 2.13, 'step': 416}, {'loss': 1.9786, 'learning_rate': 0.00014358974358974358, 'epoch': 2.13, 'step': 417}, {'eval_loss': 2.001696825027466, 'eval_rouge1': 0.4151, 'eval_rouge2': 0.1905, 'eval_rougeL': 0.3768, 'eval_sacrebleu': 9.9862, 'eval_runtime': 12.3591, 'eval_samples_per_second': 175.498, 'eval_steps_per_second': 5.502, 'epoch': 2.13, 'step': 417}, {'loss': 1.9582, 'learning_rate': 0.00014273504273504273, 'epoch': 2.14, 'step': 418}, {'eval_loss': 2.0018537044525146, 'eval_rouge1': 0.4144, 'eval_rouge2': 0.1902, 'eval_rougeL': 0.3761, 'eval_sacrebleu': 9.9672, 'eval_runtime': 11.9084, 'eval_samples_per_second': 182.141, 'eval_steps_per_second': 5.71, 'epoch': 2.14, 'step': 418}, {'loss': 1.9847, 'learning_rate': 0.00014188034188034187, 'epoch': 2.14, 'step': 419}, {'eval_loss': 2.0021045207977295, 'eval_rouge1': 0.4146, 'eval_rouge2': 0.1904, 'eval_rougeL': 0.376, 'eval_sacrebleu': 9.9713, 'eval_runtime': 12.2126, 'eval_samples_per_second': 177.603, 'eval_steps_per_second': 5.568, 'epoch': 2.14, 'step': 419}, {'loss': 1.9983, 'learning_rate': 0.00014102564102564101, 'epoch': 2.15, 'step': 420}, {'eval_loss': 2.002244710922241, 'eval_rouge1': 0.4147, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3762, 'eval_sacrebleu': 10.0014, 'eval_runtime': 11.8839, 'eval_samples_per_second': 182.516, 'eval_steps_per_second': 5.722, 'epoch': 2.15, 'step': 420}, {'loss': 2.015, 'learning_rate': 0.00014017094017094019, 'epoch': 2.15, 'step': 421}, {'eval_loss': 2.002274990081787, 'eval_rouge1': 0.415, 'eval_rouge2': 0.1909, 'eval_rougeL': 0.3764, 'eval_sacrebleu': 10.0074, 'eval_runtime': 11.7728, 'eval_samples_per_second': 184.239, 'eval_steps_per_second': 5.776, 'epoch': 2.15, 'step': 421}, {'loss': 1.9311, 'learning_rate': 0.00013931623931623933, 'epoch': 2.16, 'step': 422}, {'eval_loss': 2.0022003650665283, 'eval_rouge1': 0.4155, 'eval_rouge2': 0.191, 'eval_rougeL': 0.3765, 'eval_sacrebleu': 10.0047, 'eval_runtime': 11.7974, 'eval_samples_per_second': 183.855, 'eval_steps_per_second': 5.764, 'epoch': 2.16, 'step': 422}, {'loss': 2.0185, 'learning_rate': 0.00013846153846153847, 'epoch': 2.17, 'step': 423}, {'eval_loss': 2.001939296722412, 'eval_rouge1': 0.4161, 'eval_rouge2': 0.1913, 'eval_rougeL': 0.377, 'eval_sacrebleu': 10.0271, 'eval_runtime': 11.8009, 'eval_samples_per_second': 183.8, 'eval_steps_per_second': 5.762, 'epoch': 2.17, 'step': 423}, {'loss': 2.0296, 'learning_rate': 0.00013760683760683762, 'epoch': 2.17, 'step': 424}, {'eval_loss': 2.0016565322875977, 'eval_rouge1': 0.4155, 'eval_rouge2': 0.1911, 'eval_rougeL': 0.3764, 'eval_sacrebleu': 9.991, 'eval_runtime': 12.1767, 'eval_samples_per_second': 178.127, 'eval_steps_per_second': 5.584, 'epoch': 2.17, 'step': 424}, {'loss': 1.9846, 'learning_rate': 0.00013675213675213676, 'epoch': 2.18, 'step': 425}, {'eval_loss': 2.0011513233184814, 'eval_rouge1': 0.4153, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3761, 'eval_sacrebleu': 9.9566, 'eval_runtime': 11.7602, 'eval_samples_per_second': 184.435, 'eval_steps_per_second': 5.782, 'epoch': 2.18, 'step': 425}, {'loss': 1.9453, 'learning_rate': 0.00013589743589743588, 'epoch': 2.18, 'step': 426}, {'eval_loss': 2.0003299713134766, 'eval_rouge1': 0.4154, 'eval_rouge2': 0.1911, 'eval_rougeL': 0.3764, 'eval_sacrebleu': 9.998, 'eval_runtime': 12.0771, 'eval_samples_per_second': 179.596, 'eval_steps_per_second': 5.63, 'epoch': 2.18, 'step': 426}, {'loss': 1.9755, 'learning_rate': 0.00013504273504273502, 'epoch': 2.19, 'step': 427}, {'eval_loss': 1.9995933771133423, 'eval_rouge1': 0.4153, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3765, 'eval_sacrebleu': 10.0084, 'eval_runtime': 12.0358, 'eval_samples_per_second': 180.212, 'eval_steps_per_second': 5.65, 'epoch': 2.19, 'step': 427}, {'loss': 1.9718, 'learning_rate': 0.0001341880341880342, 'epoch': 2.19, 'step': 428}, {'eval_loss': 1.9988993406295776, 'eval_rouge1': 0.4153, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3765, 'eval_sacrebleu': 10.001, 'eval_runtime': 12.3336, 'eval_samples_per_second': 175.862, 'eval_steps_per_second': 5.513, 'epoch': 2.19, 'step': 428}, {'loss': 1.9537, 'learning_rate': 0.00013333333333333334, 'epoch': 2.2, 'step': 429}, {'eval_loss': 1.998231053352356, 'eval_rouge1': 0.4154, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3769, 'eval_sacrebleu': 10.0013, 'eval_runtime': 12.0529, 'eval_samples_per_second': 179.956, 'eval_steps_per_second': 5.642, 'epoch': 2.2, 'step': 429}, {'loss': 1.8793, 'learning_rate': 0.00013247863247863248, 'epoch': 2.2, 'step': 430}, {'eval_loss': 1.9977303743362427, 'eval_rouge1': 0.4158, 'eval_rouge2': 0.1906, 'eval_rougeL': 0.3771, 'eval_sacrebleu': 9.9912, 'eval_runtime': 12.318, 'eval_samples_per_second': 176.084, 'eval_steps_per_second': 5.52, 'epoch': 2.2, 'step': 430}, {'loss': 1.9811, 'learning_rate': 0.00013162393162393163, 'epoch': 2.21, 'step': 431}, {'eval_loss': 1.9969221353530884, 'eval_rouge1': 0.4159, 'eval_rouge2': 0.1902, 'eval_rougeL': 0.3773, 'eval_sacrebleu': 9.9515, 'eval_runtime': 12.0525, 'eval_samples_per_second': 179.963, 'eval_steps_per_second': 5.642, 'epoch': 2.21, 'step': 431}, {'loss': 1.9851, 'learning_rate': 0.00013076923076923077, 'epoch': 2.21, 'step': 432}, {'eval_loss': 1.9962257146835327, 'eval_rouge1': 0.4162, 'eval_rouge2': 0.1905, 'eval_rougeL': 0.3775, 'eval_sacrebleu': 9.9634, 'eval_runtime': 12.0483, 'eval_samples_per_second': 180.026, 'eval_steps_per_second': 5.644, 'epoch': 2.21, 'step': 432}, {'loss': 2.0247, 'learning_rate': 0.00012991452991452992, 'epoch': 2.22, 'step': 433}, {'eval_loss': 1.9955158233642578, 'eval_rouge1': 0.416, 'eval_rouge2': 0.1904, 'eval_rougeL': 0.3776, 'eval_sacrebleu': 9.9681, 'eval_runtime': 12.31, 'eval_samples_per_second': 176.198, 'eval_steps_per_second': 5.524, 'epoch': 2.22, 'step': 433}, {'loss': 1.9785, 'learning_rate': 0.0001290598290598291, 'epoch': 2.22, 'step': 434}, {'eval_loss': 1.9949649572372437, 'eval_rouge1': 0.4164, 'eval_rouge2': 0.191, 'eval_rougeL': 0.3779, 'eval_sacrebleu': 9.9914, 'eval_runtime': 12.0082, 'eval_samples_per_second': 180.627, 'eval_steps_per_second': 5.663, 'epoch': 2.22, 'step': 434}, {'loss': 1.982, 'learning_rate': 0.0001282051282051282, 'epoch': 2.23, 'step': 435}, {'eval_loss': 1.9945595264434814, 'eval_rouge1': 0.4165, 'eval_rouge2': 0.1909, 'eval_rougeL': 0.3779, 'eval_sacrebleu': 9.9957, 'eval_runtime': 12.2831, 'eval_samples_per_second': 176.584, 'eval_steps_per_second': 5.536, 'epoch': 2.23, 'step': 435}, {'loss': 1.9593, 'learning_rate': 0.00012735042735042735, 'epoch': 2.23, 'step': 436}, {'eval_loss': 1.994292140007019, 'eval_rouge1': 0.4167, 'eval_rouge2': 0.1912, 'eval_rougeL': 0.3782, 'eval_sacrebleu': 10.0012, 'eval_runtime': 12.0813, 'eval_samples_per_second': 179.534, 'eval_steps_per_second': 5.629, 'epoch': 2.23, 'step': 436}, {'loss': 1.9633, 'learning_rate': 0.0001264957264957265, 'epoch': 2.24, 'step': 437}, {'eval_loss': 1.9940818548202515, 'eval_rouge1': 0.4167, 'eval_rouge2': 0.1914, 'eval_rougeL': 0.3783, 'eval_sacrebleu': 10.0091, 'eval_runtime': 11.9822, 'eval_samples_per_second': 181.019, 'eval_steps_per_second': 5.675, 'epoch': 2.24, 'step': 437}, {'loss': 2.0066, 'learning_rate': 0.00012564102564102564, 'epoch': 2.24, 'step': 438}, {'eval_loss': 1.9939420223236084, 'eval_rouge1': 0.4167, 'eval_rouge2': 0.1913, 'eval_rougeL': 0.3783, 'eval_sacrebleu': 10.0078, 'eval_runtime': 11.9657, 'eval_samples_per_second': 181.268, 'eval_steps_per_second': 5.683, 'epoch': 2.24, 'step': 438}, {'loss': 1.9892, 'learning_rate': 0.00012478632478632478, 'epoch': 2.25, 'step': 439}, {'eval_loss': 1.9937934875488281, 'eval_rouge1': 0.417, 'eval_rouge2': 0.1915, 'eval_rougeL': 0.3787, 'eval_sacrebleu': 10.0246, 'eval_runtime': 12.0115, 'eval_samples_per_second': 180.577, 'eval_steps_per_second': 5.661, 'epoch': 2.25, 'step': 439}, {'loss': 2.0045, 'learning_rate': 0.00012393162393162393, 'epoch': 2.25, 'step': 440}, {'eval_loss': 1.993657112121582, 'eval_rouge1': 0.4168, 'eval_rouge2': 0.1914, 'eval_rougeL': 0.3786, 'eval_sacrebleu': 10.0184, 'eval_runtime': 12.2908, 'eval_samples_per_second': 176.473, 'eval_steps_per_second': 5.533, 'epoch': 2.25, 'step': 440}, {'loss': 2.0399, 'learning_rate': 0.0001230769230769231, 'epoch': 2.26, 'step': 441}, {'eval_loss': 1.9935544729232788, 'eval_rouge1': 0.4168, 'eval_rouge2': 0.1915, 'eval_rougeL': 0.3784, 'eval_sacrebleu': 10.0271, 'eval_runtime': 11.974, 'eval_samples_per_second': 181.143, 'eval_steps_per_second': 5.679, 'epoch': 2.26, 'step': 441}, {'loss': 2.0196, 'learning_rate': 0.00012222222222222221, 'epoch': 2.26, 'step': 442}, {'eval_loss': 1.9934693574905396, 'eval_rouge1': 0.4168, 'eval_rouge2': 0.1915, 'eval_rougeL': 0.3787, 'eval_sacrebleu': 10.0421, 'eval_runtime': 12.2783, 'eval_samples_per_second': 176.653, 'eval_steps_per_second': 5.538, 'epoch': 2.26, 'step': 442}, {'loss': 1.9467, 'learning_rate': 0.00012136752136752137, 'epoch': 2.27, 'step': 443}, {'eval_loss': 1.993445873260498, 'eval_rouge1': 0.4167, 'eval_rouge2': 0.1911, 'eval_rougeL': 0.3785, 'eval_sacrebleu': 10.0128, 'eval_runtime': 12.0191, 'eval_samples_per_second': 180.463, 'eval_steps_per_second': 5.658, 'epoch': 2.27, 'step': 443}, {'loss': 2.0229, 'learning_rate': 0.00012051282051282052, 'epoch': 2.27, 'step': 444}, {'eval_loss': 1.9934778213500977, 'eval_rouge1': 0.4161, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.378, 'eval_sacrebleu': 9.9794, 'eval_runtime': 12.2486, 'eval_samples_per_second': 177.082, 'eval_steps_per_second': 5.552, 'epoch': 2.27, 'step': 444}, {'loss': 1.9823, 'learning_rate': 0.00011965811965811966, 'epoch': 2.28, 'step': 445}, {'eval_loss': 1.9934653043746948, 'eval_rouge1': 0.4156, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3778, 'eval_sacrebleu': 9.9822, 'eval_runtime': 11.7783, 'eval_samples_per_second': 184.152, 'eval_steps_per_second': 5.773, 'epoch': 2.28, 'step': 445}, {'loss': 1.9521, 'learning_rate': 0.0001188034188034188, 'epoch': 2.28, 'step': 446}, {'eval_loss': 1.9933878183364868, 'eval_rouge1': 0.4152, 'eval_rouge2': 0.1906, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 9.9815, 'eval_runtime': 11.9428, 'eval_samples_per_second': 181.616, 'eval_steps_per_second': 5.694, 'epoch': 2.28, 'step': 446}, {'loss': 1.9732, 'learning_rate': 0.00011794871794871795, 'epoch': 2.29, 'step': 447}, {'eval_loss': 1.9933041334152222, 'eval_rouge1': 0.4155, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3775, 'eval_sacrebleu': 10.01, 'eval_runtime': 11.9125, 'eval_samples_per_second': 182.078, 'eval_steps_per_second': 5.708, 'epoch': 2.29, 'step': 447}, {'loss': 2.0199, 'learning_rate': 0.0001170940170940171, 'epoch': 2.29, 'step': 448}, {'eval_loss': 1.993316411972046, 'eval_rouge1': 0.4153, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3773, 'eval_sacrebleu': 10.006, 'eval_runtime': 11.9397, 'eval_samples_per_second': 181.663, 'eval_steps_per_second': 5.695, 'epoch': 2.29, 'step': 448}, {'loss': 1.9855, 'learning_rate': 0.00011623931623931625, 'epoch': 2.3, 'step': 449}, {'eval_loss': 1.9933513402938843, 'eval_rouge1': 0.4155, 'eval_rouge2': 0.1911, 'eval_rougeL': 0.3776, 'eval_sacrebleu': 10.0375, 'eval_runtime': 12.2584, 'eval_samples_per_second': 176.94, 'eval_steps_per_second': 5.547, 'epoch': 2.3, 'step': 449}, {'loss': 2.0053, 'learning_rate': 0.0001153846153846154, 'epoch': 2.3, 'step': 450}, {'eval_loss': 1.993372917175293, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1914, 'eval_rougeL': 0.3779, 'eval_sacrebleu': 10.0459, 'eval_runtime': 12.1006, 'eval_samples_per_second': 179.248, 'eval_steps_per_second': 5.62, 'epoch': 2.3, 'step': 450}, {'loss': 1.9717, 'learning_rate': 0.00011452991452991453, 'epoch': 2.31, 'step': 451}, {'eval_loss': 1.9933305978775024, 'eval_rouge1': 0.416, 'eval_rouge2': 0.1916, 'eval_rougeL': 0.3781, 'eval_sacrebleu': 10.064, 'eval_runtime': 12.2954, 'eval_samples_per_second': 176.407, 'eval_steps_per_second': 5.531, 'epoch': 2.31, 'step': 451}, {'loss': 2.0315, 'learning_rate': 0.00011367521367521367, 'epoch': 2.31, 'step': 452}, {'eval_loss': 1.9933292865753174, 'eval_rouge1': 0.4158, 'eval_rouge2': 0.1913, 'eval_rougeL': 0.3781, 'eval_sacrebleu': 10.0515, 'eval_runtime': 12.0243, 'eval_samples_per_second': 180.385, 'eval_steps_per_second': 5.655, 'epoch': 2.31, 'step': 452}, {'loss': 1.9204, 'learning_rate': 0.00011282051282051283, 'epoch': 2.32, 'step': 453}, {'eval_loss': 1.993594765663147, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1913, 'eval_rougeL': 0.378, 'eval_sacrebleu': 10.0829, 'eval_runtime': 12.0825, 'eval_samples_per_second': 179.516, 'eval_steps_per_second': 5.628, 'epoch': 2.32, 'step': 453}, {'loss': 2.0014, 'learning_rate': 0.00011196581196581197, 'epoch': 2.32, 'step': 454}, {'eval_loss': 1.993815541267395, 'eval_rouge1': 0.4158, 'eval_rouge2': 0.1916, 'eval_rougeL': 0.3779, 'eval_sacrebleu': 10.0707, 'eval_runtime': 11.7463, 'eval_samples_per_second': 184.654, 'eval_steps_per_second': 5.789, 'epoch': 2.32, 'step': 454}, {'loss': 2.0305, 'learning_rate': 0.0001111111111111111, 'epoch': 2.33, 'step': 455}, {'eval_loss': 1.994208574295044, 'eval_rouge1': 0.4161, 'eval_rouge2': 0.1917, 'eval_rougeL': 0.3781, 'eval_sacrebleu': 10.0495, 'eval_runtime': 12.043, 'eval_samples_per_second': 180.104, 'eval_steps_per_second': 5.646, 'epoch': 2.33, 'step': 455}, {'loss': 2.0254, 'learning_rate': 0.00011025641025641026, 'epoch': 2.33, 'step': 456}, {'eval_loss': 1.9944087266921997, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.191, 'eval_rougeL': 0.3776, 'eval_sacrebleu': 10.0168, 'eval_runtime': 11.7863, 'eval_samples_per_second': 184.027, 'eval_steps_per_second': 5.769, 'epoch': 2.33, 'step': 456}, {'loss': 2.0298, 'learning_rate': 0.0001094017094017094, 'epoch': 2.34, 'step': 457}, {'eval_loss': 1.9945642948150635, 'eval_rouge1': 0.4158, 'eval_rouge2': 0.1912, 'eval_rougeL': 0.3779, 'eval_sacrebleu': 10.0363, 'eval_runtime': 11.9161, 'eval_samples_per_second': 182.023, 'eval_steps_per_second': 5.707, 'epoch': 2.34, 'step': 457}, {'loss': 1.9719, 'learning_rate': 0.00010854700854700855, 'epoch': 2.34, 'step': 458}, {'eval_loss': 1.9947398900985718, 'eval_rouge1': 0.4159, 'eval_rouge2': 0.1912, 'eval_rougeL': 0.378, 'eval_sacrebleu': 10.0445, 'eval_runtime': 12.0689, 'eval_samples_per_second': 179.717, 'eval_steps_per_second': 5.634, 'epoch': 2.34, 'step': 458}, {'loss': 2.0022, 'learning_rate': 0.00010769230769230771, 'epoch': 2.35, 'step': 459}, {'eval_loss': 1.9949826002120972, 'eval_rouge1': 0.4156, 'eval_rouge2': 0.1909, 'eval_rougeL': 0.3775, 'eval_sacrebleu': 10.0215, 'eval_runtime': 11.7705, 'eval_samples_per_second': 184.274, 'eval_steps_per_second': 5.777, 'epoch': 2.35, 'step': 459}, {'loss': 1.9391, 'learning_rate': 0.00010683760683760684, 'epoch': 2.35, 'step': 460}, {'eval_loss': 1.995212435722351, 'eval_rouge1': 0.4151, 'eval_rouge2': 0.1905, 'eval_rougeL': 0.3771, 'eval_sacrebleu': 10.0053, 'eval_runtime': 12.0567, 'eval_samples_per_second': 179.9, 'eval_steps_per_second': 5.64, 'epoch': 2.35, 'step': 460}, {'loss': 1.9545, 'learning_rate': 0.00010598290598290598, 'epoch': 2.36, 'step': 461}, {'eval_loss': 1.9953999519348145, 'eval_rouge1': 0.4153, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 10.0218, 'eval_runtime': 11.7882, 'eval_samples_per_second': 183.998, 'eval_steps_per_second': 5.768, 'epoch': 2.36, 'step': 461}, {'loss': 2.0625, 'learning_rate': 0.00010512820512820513, 'epoch': 2.36, 'step': 462}, {'eval_loss': 1.995404839515686, 'eval_rouge1': 0.4152, 'eval_rouge2': 0.1909, 'eval_rougeL': 0.3773, 'eval_sacrebleu': 10.0288, 'eval_runtime': 11.8069, 'eval_samples_per_second': 183.706, 'eval_steps_per_second': 5.759, 'epoch': 2.36, 'step': 462}, {'loss': 1.9932, 'learning_rate': 0.00010427350427350428, 'epoch': 2.37, 'step': 463}, {'eval_loss': 1.9954612255096436, 'eval_rouge1': 0.4152, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3773, 'eval_sacrebleu': 10.0214, 'eval_runtime': 11.8091, 'eval_samples_per_second': 183.672, 'eval_steps_per_second': 5.758, 'epoch': 2.37, 'step': 463}, {'loss': 1.994, 'learning_rate': 0.00010341880341880341, 'epoch': 2.37, 'step': 464}, {'eval_loss': 1.9955157041549683, 'eval_rouge1': 0.4152, 'eval_rouge2': 0.191, 'eval_rougeL': 0.3773, 'eval_sacrebleu': 10.0328, 'eval_runtime': 11.7748, 'eval_samples_per_second': 184.206, 'eval_steps_per_second': 5.775, 'epoch': 2.37, 'step': 464}, {'loss': 2.0229, 'learning_rate': 0.00010256410256410256, 'epoch': 2.38, 'step': 465}, {'eval_loss': 1.9954813718795776, 'eval_rouge1': 0.4153, 'eval_rouge2': 0.191, 'eval_rougeL': 0.3773, 'eval_sacrebleu': 10.0489, 'eval_runtime': 12.0915, 'eval_samples_per_second': 179.383, 'eval_steps_per_second': 5.624, 'epoch': 2.38, 'step': 465}, {'loss': 1.9864, 'learning_rate': 0.00010170940170940172, 'epoch': 2.39, 'step': 466}, {'eval_loss': 1.9954161643981934, 'eval_rouge1': 0.4155, 'eval_rouge2': 0.1912, 'eval_rougeL': 0.3776, 'eval_sacrebleu': 10.054, 'eval_runtime': 11.9959, 'eval_samples_per_second': 180.812, 'eval_steps_per_second': 5.669, 'epoch': 2.39, 'step': 466}, {'loss': 2.0828, 'learning_rate': 0.00010085470085470086, 'epoch': 2.39, 'step': 467}, {'eval_loss': 1.995320200920105, 'eval_rouge1': 0.4158, 'eval_rouge2': 0.191, 'eval_rougeL': 0.3776, 'eval_sacrebleu': 10.0527, 'eval_runtime': 12.2982, 'eval_samples_per_second': 176.367, 'eval_steps_per_second': 5.529, 'epoch': 2.39, 'step': 467}, {'loss': 2.0061, 'learning_rate': 0.0001, 'epoch': 2.4, 'step': 468}, {'eval_loss': 1.9953398704528809, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 10.031, 'eval_runtime': 12.0101, 'eval_samples_per_second': 180.598, 'eval_steps_per_second': 5.662, 'epoch': 2.4, 'step': 468}, {'loss': 2.0085, 'learning_rate': 9.914529914529914e-05, 'epoch': 2.4, 'step': 469}, {'eval_loss': 1.9955500364303589, 'eval_rouge1': 0.4159, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 10.0118, 'eval_runtime': 12.3075, 'eval_samples_per_second': 176.234, 'eval_steps_per_second': 5.525, 'epoch': 2.4, 'step': 469}, {'loss': 2.0099, 'learning_rate': 9.829059829059829e-05, 'epoch': 2.41, 'step': 470}, {'eval_loss': 1.995678186416626, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 10.0159, 'eval_runtime': 12.0187, 'eval_samples_per_second': 180.468, 'eval_steps_per_second': 5.658, 'epoch': 2.41, 'step': 470}, {'loss': 2.0483, 'learning_rate': 9.743589743589744e-05, 'epoch': 2.41, 'step': 471}, {'eval_loss': 1.9956358671188354, 'eval_rouge1': 0.4156, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 9.9972, 'eval_runtime': 11.9972, 'eval_samples_per_second': 180.792, 'eval_steps_per_second': 5.668, 'epoch': 2.41, 'step': 471}, {'loss': 1.9645, 'learning_rate': 9.658119658119658e-05, 'epoch': 2.42, 'step': 472}, {'eval_loss': 1.9955241680145264, 'eval_rouge1': 0.4156, 'eval_rouge2': 0.1909, 'eval_rougeL': 0.3775, 'eval_sacrebleu': 10.0102, 'eval_runtime': 12.0787, 'eval_samples_per_second': 179.572, 'eval_steps_per_second': 5.63, 'epoch': 2.42, 'step': 472}, {'loss': 1.9846, 'learning_rate': 9.572649572649574e-05, 'epoch': 2.42, 'step': 473}, {'eval_loss': 1.9955692291259766, 'eval_rouge1': 0.4154, 'eval_rouge2': 0.1907, 'eval_rougeL': 0.3774, 'eval_sacrebleu': 9.9987, 'eval_runtime': 12.0198, 'eval_samples_per_second': 180.453, 'eval_steps_per_second': 5.657, 'epoch': 2.42, 'step': 473}, {'loss': 1.9929, 'learning_rate': 9.487179487179487e-05, 'epoch': 2.43, 'step': 474}, {'eval_loss': 1.9955689907073975, 'eval_rouge1': 0.4159, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3776, 'eval_sacrebleu': 10.0017, 'eval_runtime': 12.3865, 'eval_samples_per_second': 175.11, 'eval_steps_per_second': 5.49, 'epoch': 2.43, 'step': 474}, {'loss': 1.9604, 'learning_rate': 9.401709401709401e-05, 'epoch': 2.43, 'step': 475}, {'eval_loss': 1.9953396320343018, 'eval_rouge1': 0.4157, 'eval_rouge2': 0.1908, 'eval_rougeL': 0.3775, 'eval_sacrebleu': 9.9951, 'eval_runtime': 11.9557, 'eval_samples_per_second': 181.42, 'eval_steps_per_second': 5.688, 'epoch': 2.43, 'step': 475}, {'loss': 2.0273, 'learning_rate': 9.316239316239317e-05, 'epoch': 2.44, 'step': 476}, {'eval_loss': 1.994955062866211, 'eval_rouge1': 0.4163, 'eval_rouge2': 0.1914, 'eval_rougeL': 0.378, 'eval_sacrebleu': 10.04, 'eval_runtime': 12.287, 'eval_samples_per_second': 176.528, 'eval_steps_per_second': 5.534, 'epoch': 2.44, 'step': 476}, {'loss': 1.9454, 'learning_rate': 9.230769230769232e-05, 'epoch': 2.44, 'step': 477}, {'eval_loss': 1.9946624040603638, 'eval_rouge1': 0.4158, 'eval_rouge2': 0.1912, 'eval_rougeL': 0.3778, 'eval_sacrebleu': 10.0111, 'eval_runtime': 12.0047, 'eval_samples_per_second': 180.679, 'eval_steps_per_second': 5.664, 'epoch': 2.44, 'step': 477}, {'loss': 1.9682, 'learning_rate': 9.145299145299145e-05, 'epoch': 2.45, 'step': 478}, {'eval_loss': 1.994376540184021, 'eval_rouge1': 0.416, 'eval_rouge2': 0.1915, 'eval_rougeL': 0.3781, 'eval_sacrebleu': 10.0237, 'eval_runtime': 12.305, 'eval_samples_per_second': 176.27, 'eval_steps_per_second': 5.526, 'epoch': 2.45, 'step': 478}, {'loss': 2.0534, 'learning_rate': 9.059829059829059e-05, 'epoch': 2.45, 'step': 479}, {'eval_loss': 1.9940615892410278, 'eval_rouge1': 0.4162, 'eval_rouge2': 0.1916, 'eval_rougeL': 0.3781, 'eval_sacrebleu': 10.0143, 'eval_runtime': 12.0395, 'eval_samples_per_second': 180.157, 'eval_steps_per_second': 5.648, 'epoch': 2.45, 'step': 479}, {'loss': 2.0274, 'learning_rate': 8.974358974358975e-05, 'epoch': 2.46, 'step': 480}, {'eval_loss': 1.9937716722488403, 'eval_rouge1': 0.4162, 'eval_rouge2': 0.1918, 'eval_rougeL': 0.3782, 'eval_sacrebleu': 10.0247, 'eval_runtime': 12.1802, 'eval_samples_per_second': 178.076, 'eval_steps_per_second': 5.583, 'epoch': 2.46, 'step': 480}, {'loss': 1.9425, 'learning_rate': 8.888888888888889e-05, 'epoch': 2.46, 'step': 481}, {'eval_loss': 1.9934533834457397, 'eval_rouge1': 0.4165, 'eval_rouge2': 0.192, 'eval_rougeL': 0.3784, 'eval_sacrebleu': 10.0234, 'eval_runtime': 12.5458, 'eval_samples_per_second': 172.887, 'eval_steps_per_second': 5.42, 'epoch': 2.46, 'step': 481}, {'loss': 2.0413, 'learning_rate': 8.803418803418804e-05, 'epoch': 2.47, 'step': 482}, {'eval_loss': 1.9931505918502808, 'eval_rouge1': 0.4166, 'eval_rouge2': 0.1919, 'eval_rougeL': 0.3786, 'eval_sacrebleu': 10.0341, 'eval_runtime': 12.0661, 'eval_samples_per_second': 179.76, 'eval_steps_per_second': 5.636, 'epoch': 2.47, 'step': 482}, {'loss': 1.9828, 'learning_rate': 8.717948717948718e-05, 'epoch': 2.47, 'step': 483}, {'eval_loss': 1.9929051399230957, 'eval_rouge1': 0.4169, 'eval_rouge2': 0.1917, 'eval_rougeL': 0.3785, 'eval_sacrebleu': 10.034, 'eval_runtime': 12.3353, 'eval_samples_per_second': 175.837, 'eval_steps_per_second': 5.513, 'epoch': 2.47, 'step': 483}, {'loss': 2.0086, 'learning_rate': 8.632478632478633e-05, 'epoch': 2.48, 'step': 484}, {'eval_loss': 1.9927043914794922, 'eval_rouge1': 0.4168, 'eval_rouge2': 0.1916, 'eval_rougeL': 0.3784, 'eval_sacrebleu': 10.0226, 'eval_runtime': 12.0097, 'eval_samples_per_second': 180.604, 'eval_steps_per_second': 5.662, 'epoch': 2.48, 'step': 484}, {'loss': 1.9524, 'learning_rate': 8.547008547008547e-05, 'epoch': 2.48, 'step': 485}, {'eval_loss': 1.9925434589385986, 'eval_rouge1': 0.4165, 'eval_rouge2': 0.1915, 'eval_rougeL': 0.3783, 'eval_sacrebleu': 10.0291, 'eval_runtime': 12.2957, 'eval_samples_per_second': 176.403, 'eval_steps_per_second': 5.53, 'epoch': 2.48, 'step': 485}, {'loss': 1.9874, 'learning_rate': 8.461538461538463e-05, 'epoch': 2.49, 'step': 486}, {'eval_loss': 1.992368221282959, 'eval_rouge1': 0.4165, 'eval_rouge2': 0.1915, 'eval_rougeL': 0.3784, 'eval_sacrebleu': 10.0634, 'eval_runtime': 12.0282, 'eval_samples_per_second': 180.327, 'eval_steps_per_second': 5.653, 'epoch': 2.49, 'step': 486}, {'loss': 1.9907, 'learning_rate': 8.376068376068376e-05, 'epoch': 2.49, 'step': 487}, {'eval_loss': 1.9923522472381592, 'eval_rouge1': 0.4165, 'eval_rouge2': 0.1914, 'eval_rougeL': 0.3786, 'eval_sacrebleu': 10.0587, 'eval_runtime': 12.0653, 'eval_samples_per_second': 179.772, 'eval_steps_per_second': 5.636, 'epoch': 2.49, 'step': 487}, {'loss': 1.9742, 'learning_rate': 8.29059829059829e-05, 'epoch': 2.5, 'step': 488}, {'eval_loss': 1.9923511743545532, 'eval_rouge1': 0.4173, 'eval_rouge2': 0.192, 'eval_rougeL': 0.3793, 'eval_sacrebleu': 10.0846, 'eval_runtime': 12.3277, 'eval_samples_per_second': 175.945, 'eval_steps_per_second': 5.516, 'epoch': 2.5, 'step': 488}, {'loss': 1.9584, 'learning_rate': 8.205128205128205e-05, 'epoch': 2.5, 'step': 489}, {'eval_loss': 1.992384672164917, 'eval_rouge1': 0.4177, 'eval_rouge2': 0.192, 'eval_rougeL': 0.3795, 'eval_sacrebleu': 10.0958, 'eval_runtime': 12.0502, 'eval_samples_per_second': 179.997, 'eval_steps_per_second': 5.643, 'epoch': 2.5, 'step': 489}, {'loss': 1.9975, 'learning_rate': 8.11965811965812e-05, 'epoch': 2.51, 'step': 490}, {'eval_loss': 1.9924246072769165, 'eval_rouge1': 0.4174, 'eval_rouge2': 0.1918, 'eval_rougeL': 0.3794, 'eval_sacrebleu': 10.0896, 'eval_runtime': 12.3918, 'eval_samples_per_second': 175.035, 'eval_steps_per_second': 5.488, 'epoch': 2.51, 'step': 490}, {'loss': 1.9895, 'learning_rate': 8.034188034188035e-05, 'epoch': 2.51, 'step': 491}, {'eval_loss': 1.9924067258834839, 'eval_rouge1': 0.4175, 'eval_rouge2': 0.1921, 'eval_rougeL': 0.3796, 'eval_sacrebleu': 10.0953, 'eval_runtime': 11.96, 'eval_samples_per_second': 181.354, 'eval_steps_per_second': 5.686, 'epoch': 2.51, 'step': 491}, {'loss': 2.0146, 'learning_rate': 7.948717948717948e-05, 'epoch': 2.52, 'step': 492}, {'eval_loss': 1.9923484325408936, 'eval_rouge1': 0.417, 'eval_rouge2': 0.1916, 'eval_rougeL': 0.379, 'eval_sacrebleu': 10.0458, 'eval_runtime': 12.2922, 'eval_samples_per_second': 176.454, 'eval_steps_per_second': 5.532, 'epoch': 2.52, 'step': 492}, {'loss': 1.8847, 'learning_rate': 7.863247863247864e-05, 'epoch': 2.52, 'step': 493}, {'eval_loss': 1.9923189878463745, 'eval_rouge1': 0.417, 'eval_rouge2': 0.1917, 'eval_rougeL': 0.3791, 'eval_sacrebleu': 10.0653, 'eval_runtime': 12.0192, 'eval_samples_per_second': 180.461, 'eval_steps_per_second': 5.658, 'epoch': 2.52, 'step': 493}, {'loss': 1.9465, 'learning_rate': 7.777777777777778e-05, 'epoch': 2.53, 'step': 494}, {'eval_loss': 1.9922500848770142, 'eval_rouge1': 0.4174, 'eval_rouge2': 0.1921, 'eval_rougeL': 0.3796, 'eval_sacrebleu': 10.0814, 'eval_runtime': 12.058, 'eval_samples_per_second': 179.881, 'eval_steps_per_second': 5.639, 'epoch': 2.53, 'step': 494}, {'loss': 2.0078, 'learning_rate': 7.692307692307693e-05, 'epoch': 2.53, 'step': 495}, {'eval_loss': 1.992245078086853, 'eval_rouge1': 0.4177, 'eval_rouge2': 0.1921, 'eval_rougeL': 0.3797, 'eval_sacrebleu': 10.0793, 'eval_runtime': 12.1218, 'eval_samples_per_second': 178.934, 'eval_steps_per_second': 5.61, 'epoch': 2.53, 'step': 495}, {'loss': 1.9973, 'learning_rate': 7.606837606837607e-05, 'epoch': 2.54, 'step': 496}, {'eval_loss': 1.9923486709594727, 'eval_rouge1': 0.4178, 'eval_rouge2': 0.192, 'eval_rougeL': 0.3798, 'eval_sacrebleu': 10.0635, 'eval_runtime': 12.0548, 'eval_samples_per_second': 179.928, 'eval_steps_per_second': 5.641, 'epoch': 2.54, 'step': 496}, {'loss': 2.0172, 'learning_rate': 7.521367521367521e-05, 'epoch': 2.54, 'step': 497}, {'eval_loss': 1.9923319816589355, 'eval_rouge1': 0.4174, 'eval_rouge2': 0.1917, 'eval_rougeL': 0.3794, 'eval_sacrebleu': 10.0331, 'eval_runtime': 12.3858, 'eval_samples_per_second': 175.12, 'eval_steps_per_second': 5.49, 'epoch': 2.54, 'step': 497}, {'loss': 1.9582, 'learning_rate': 7.435897435897436e-05, 'epoch': 2.55, 'step': 498}, {'eval_loss': 1.9922786951065063, 'eval_rouge1': 0.4175, 'eval_rouge2': 0.1919, 'eval_rougeL': 0.3795, 'eval_sacrebleu': 10.0479, 'eval_runtime': 12.0565, 'eval_samples_per_second': 179.903, 'eval_steps_per_second': 5.64, 'epoch': 2.55, 'step': 498}, {'loss': 1.9668, 'learning_rate': 7.35042735042735e-05, 'epoch': 2.55, 'step': 499}, {'eval_loss': 1.9923421144485474, 'eval_rouge1': 0.4171, 'eval_rouge2': 0.1919, 'eval_rougeL': 0.3792, 'eval_sacrebleu': 10.0387, 'eval_runtime': 12.4101, 'eval_samples_per_second': 174.777, 'eval_steps_per_second': 5.479, 'epoch': 2.55, 'step': 499}, {'loss': 2.0014, 'learning_rate': 7.264957264957266e-05, 'epoch': 2.56, 'step': 500}, {'eval_loss': 1.9923362731933594, 'eval_rouge1': 0.4169, 'eval_rouge2': 0.1919, 'eval_rougeL': 0.379, 'eval_sacrebleu': 10.0464, 'eval_runtime': 12.0912, 'eval_samples_per_second': 179.386, 'eval_steps_per_second': 5.624, 'epoch': 2.56, 'step': 500}, {'loss': 1.9595, 'learning_rate': 7.179487179487179e-05, 'epoch': 2.56, 'step': 501}, {'eval_loss': 1.9923027753829956, 'eval_rouge1': 0.4168, 'eval_rouge2': 0.1917, 'eval_rougeL': 0.3788, 'eval_sacrebleu': 10.0419, 'eval_runtime': 12.2961, 'eval_samples_per_second': 176.398, 'eval_steps_per_second': 5.53, 'epoch': 2.56, 'step': 501}, {'train_runtime': 6544.8561, 'train_samples_per_second': 22.919, 'train_steps_per_second': 0.089, 'total_flos': 3718156493783040.0, 'train_loss': 2.1482737673494867, 'epoch': 2.56, 'step': 501}, {'eval_loss': 1.9923362731933594, 'eval_rouge1': 0.4169, 'eval_rouge2': 0.1919, 'eval_rougeL': 0.379, 'eval_sacrebleu': 10.0464, 'eval_runtime': 11.8494, 'eval_samples_per_second': 183.048, 'eval_steps_per_second': 5.739, 'epoch': 2.56, 'step': 501}]\n"
     ]
    }
   ],
   "source": [
    "l = trainer.state.log_history\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log_history.pkl', 'wb') as f:\n",
    "    pickle.dump(l, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(fine_tuned_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(model, tokenizer, example):\n",
    "    \"\"\"print out the source, target and predicted raw text.\"\"\"\n",
    "    source = example[config.source_lang]\n",
    "    target = example[config.target_lang]\n",
    "    input_ids = tokenizer(source)[\"input_ids\"]\n",
    "    input_ids = torch.LongTensor(input_ids).view(1, -1).to(model.device)\n",
    "    generated_ids = model.generate(input_ids, max_new_tokens=20)\n",
    "    prediction = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print('source: ', source)\n",
    "    print('target: ', target)\n",
    "    print('prediction: ', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "target:  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "prediction:  I re-examined the session of the European Parliament on Friday 17 December, and I\n"
     ]
    }
   ],
   "source": [
    "example = dataset_dict['train'][1]\n",
    "generate_translation(model, tokenizer, example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
